{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "da2fdc70f44e4be791bd8900a536fc0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_806bc93b806d4be996504eac75dd40a8",
              "IPY_MODEL_d0fca20e108147b3a3b46517ec1b7451",
              "IPY_MODEL_7978aafefa8a48cb96ca1933b3401186"
            ],
            "layout": "IPY_MODEL_765d3635b77d4863be58da2fe9adefcc"
          }
        },
        "806bc93b806d4be996504eac75dd40a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fc5d3409167439fad04c7334327233e",
            "placeholder": "​",
            "style": "IPY_MODEL_a261d6527efd4fbf8bddb33044aebf7b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d0fca20e108147b3a3b46517ec1b7451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_297f07d083d94d95bfeb421ef398a5b1",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dca8592a81a247d59d30f11327f1fc59",
            "value": 48
          }
        },
        "7978aafefa8a48cb96ca1933b3401186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_921b72a5cd1244bebe90ae3b20177214",
            "placeholder": "​",
            "style": "IPY_MODEL_0f9d35f20f7347d1b0967667d99756f3",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.10kB/s]"
          }
        },
        "765d3635b77d4863be58da2fe9adefcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fc5d3409167439fad04c7334327233e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a261d6527efd4fbf8bddb33044aebf7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "297f07d083d94d95bfeb421ef398a5b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dca8592a81a247d59d30f11327f1fc59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "921b72a5cd1244bebe90ae3b20177214": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f9d35f20f7347d1b0967667d99756f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32a0452efc1c446f962791dc1d6fd2de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdca01f9f502488fa83b558bdb1596b6",
              "IPY_MODEL_6ea6f739edd043649faa4a1d25363350",
              "IPY_MODEL_e0d3f26a01f64467a05b96de50d093af"
            ],
            "layout": "IPY_MODEL_ec9d680d7396498f9446705bc45f17e4"
          }
        },
        "cdca01f9f502488fa83b558bdb1596b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bce13983255d4a8d851f2022e5250236",
            "placeholder": "​",
            "style": "IPY_MODEL_47f3f33fc1004c4199f2f4aa0e201905",
            "value": "vocab.txt: 100%"
          }
        },
        "6ea6f739edd043649faa4a1d25363350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_377e7c0523574e62b78c3abcaea22a24",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b9716cd0f4e47c28f3c343df1721177",
            "value": 231508
          }
        },
        "e0d3f26a01f64467a05b96de50d093af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd245f550ab34463a95314cf0724919a",
            "placeholder": "​",
            "style": "IPY_MODEL_0dd20031ad4a4a75b5faf01d572287c5",
            "value": " 232k/232k [00:00&lt;00:00, 540kB/s]"
          }
        },
        "ec9d680d7396498f9446705bc45f17e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bce13983255d4a8d851f2022e5250236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47f3f33fc1004c4199f2f4aa0e201905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "377e7c0523574e62b78c3abcaea22a24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b9716cd0f4e47c28f3c343df1721177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd245f550ab34463a95314cf0724919a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dd20031ad4a4a75b5faf01d572287c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cc06ce056874bdf85ce0820e5e763f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eee5e2c81a2047858c375fda82d734e7",
              "IPY_MODEL_bc6b762b499a40cabd15110af0e97b2f",
              "IPY_MODEL_711243fb6b8041528da26c2f43194788"
            ],
            "layout": "IPY_MODEL_5b7828bfe33044a9b0aa34af11d0f713"
          }
        },
        "eee5e2c81a2047858c375fda82d734e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_726565023c47438ca71c84350db201d8",
            "placeholder": "​",
            "style": "IPY_MODEL_496c007fd54b4b899c79682ff31a51d2",
            "value": "tokenizer.json: 100%"
          }
        },
        "bc6b762b499a40cabd15110af0e97b2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dcab25f425841bdb9ee989e4283937a",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1d03ae490cd440699c3e6ed14741c22",
            "value": 466062
          }
        },
        "711243fb6b8041528da26c2f43194788": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e10a32e32eb403ca0380091b5f035d6",
            "placeholder": "​",
            "style": "IPY_MODEL_cf2e35d60ef74e17802bca941201fa01",
            "value": " 466k/466k [00:00&lt;00:00, 9.33MB/s]"
          }
        },
        "5b7828bfe33044a9b0aa34af11d0f713": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "726565023c47438ca71c84350db201d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "496c007fd54b4b899c79682ff31a51d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dcab25f425841bdb9ee989e4283937a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1d03ae490cd440699c3e6ed14741c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e10a32e32eb403ca0380091b5f035d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf2e35d60ef74e17802bca941201fa01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66246bc3516b4d6385c0f54f019df3b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18f460ee0d88491295b98cc9f166687f",
              "IPY_MODEL_3bbd19758777475785b1f01c1453014d",
              "IPY_MODEL_54f0ea6a74934a979b11e81aaa0a7aad"
            ],
            "layout": "IPY_MODEL_964de26aaf7c4427b1eab9b266ab63a9"
          }
        },
        "18f460ee0d88491295b98cc9f166687f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da0afd853c2f4e9795809d57e5f02bca",
            "placeholder": "​",
            "style": "IPY_MODEL_331e4823e4984b27847728d327776523",
            "value": "config.json: 100%"
          }
        },
        "3bbd19758777475785b1f01c1453014d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed95cb12c5d94c519f6cb842113d7a9c",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47027ef194734961bc60ddecb8c7da45",
            "value": 570
          }
        },
        "54f0ea6a74934a979b11e81aaa0a7aad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55c412e68df941a384c102caf13afcd4",
            "placeholder": "​",
            "style": "IPY_MODEL_e114206877b24573b13a794f3d38302b",
            "value": " 570/570 [00:00&lt;00:00, 69.4kB/s]"
          }
        },
        "964de26aaf7c4427b1eab9b266ab63a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da0afd853c2f4e9795809d57e5f02bca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "331e4823e4984b27847728d327776523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed95cb12c5d94c519f6cb842113d7a9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47027ef194734961bc60ddecb8c7da45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55c412e68df941a384c102caf13afcd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e114206877b24573b13a794f3d38302b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8677a8c685794a0dae148e0900cbd493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ca489dfafe242e98bee65cb3cac37e1",
              "IPY_MODEL_c3f0465d93bd4d4dae4574a6ceba94f0",
              "IPY_MODEL_ae5688950ce34737bbc717ce51d264ea"
            ],
            "layout": "IPY_MODEL_4492c087914c424596af9f8e26b04bcd"
          }
        },
        "2ca489dfafe242e98bee65cb3cac37e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50075fc1340740b4aad722ef640eaa38",
            "placeholder": "​",
            "style": "IPY_MODEL_81075d4983b64e459064f7c154dc7ebd",
            "value": "model.safetensors: 100%"
          }
        },
        "c3f0465d93bd4d4dae4574a6ceba94f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d048b4d2a18348fb8afc5ba59e54e2ad",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11f4a3d3301044b9a52148bc418c5d4f",
            "value": 440449768
          }
        },
        "ae5688950ce34737bbc717ce51d264ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0118978c5edc439aafd3132c5f83b329",
            "placeholder": "​",
            "style": "IPY_MODEL_8a8ba6f241754a5e80a03ed5604084ee",
            "value": " 440M/440M [00:01&lt;00:00, 276MB/s]"
          }
        },
        "4492c087914c424596af9f8e26b04bcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50075fc1340740b4aad722ef640eaa38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81075d4983b64e459064f7c154dc7ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d048b4d2a18348fb8afc5ba59e54e2ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11f4a3d3301044b9a52148bc418c5d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0118978c5edc439aafd3132c5f83b329": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a8ba6f241754a5e80a03ed5604084ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlbyRTh3KhDm",
        "outputId": "b0900d70-3e30-47ed-abe2-e0037ad08439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
        "from torch.ao.quantization.qconfig import float_qparams_weight_only_qconfig\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import pandas as pd\n",
        "from torch.optim import AdamW\n",
        "from torchinfo import summary\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "import wandb\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch.quantization as quantization\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "4J7kuUsqKkun",
        "outputId": "7c650217-3292-493b-85b5-76d773f0d5a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhl6151\u001b[0m (\u001b[33mhl6151-new-york-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing for the raw data\n",
        "def load_news_data(data_file):\n",
        "\n",
        "    df = pd.read_json(data_file, lines=True)\n",
        "    df.head()\n",
        "\n",
        "    df['category'] = df['category'].map(lambda x: \"WORLDPOST\" if x == \"THE WORLDPOST\" else x)\n",
        "\n",
        "    df['headline'] = df['headline'].apply(lambda x: str(x).lower())\n",
        "    df['short_description'] = df['short_description'].apply(lambda x: str(x).lower())\n",
        "\n",
        "    df['text'] = df['headline'] + \" \" + df['short_description']\n",
        "    encoder = LabelEncoder()\n",
        "    df['label'] = encoder.fit_transform(df['category'])\n",
        "    print(f\"The dataset contains {df['category'].nunique()} unique categories.\")\n",
        "\n",
        "    return df['text'].tolist(), df['label'].tolist(), encoder.classes_.tolist()"
      ],
      "metadata": {
        "id": "xD6aRdGgK2xS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3U5Lvv6LjSM",
        "outputId": "b1a7912a-b44f-43c8-a02f-5fe683d4dbb0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = \"/content/drive/MyDrive/News_Category_Dataset_v2.json\"\n",
        "texts, labels, label_names = load_news_data(data_file)\n",
        "\n",
        "# The relationship between the actual label and their number label\n",
        "for idx, name in enumerate(label_names):\n",
        "    print(f\"{idx} → {name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_69ZnT9LmzF",
        "outputId": "9ebeef82-6aa2-44ae-ae02-e3ea4a1a1a60"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset contains 40 unique categories.\n",
            "0 → ARTS\n",
            "1 → ARTS & CULTURE\n",
            "2 → BLACK VOICES\n",
            "3 → BUSINESS\n",
            "4 → COLLEGE\n",
            "5 → COMEDY\n",
            "6 → CRIME\n",
            "7 → CULTURE & ARTS\n",
            "8 → DIVORCE\n",
            "9 → EDUCATION\n",
            "10 → ENTERTAINMENT\n",
            "11 → ENVIRONMENT\n",
            "12 → FIFTY\n",
            "13 → FOOD & DRINK\n",
            "14 → GOOD NEWS\n",
            "15 → GREEN\n",
            "16 → HEALTHY LIVING\n",
            "17 → HOME & LIVING\n",
            "18 → IMPACT\n",
            "19 → LATINO VOICES\n",
            "20 → MEDIA\n",
            "21 → MONEY\n",
            "22 → PARENTING\n",
            "23 → PARENTS\n",
            "24 → POLITICS\n",
            "25 → QUEER VOICES\n",
            "26 → RELIGION\n",
            "27 → SCIENCE\n",
            "28 → SPORTS\n",
            "29 → STYLE\n",
            "30 → STYLE & BEAUTY\n",
            "31 → TASTE\n",
            "32 → TECH\n",
            "33 → TRAVEL\n",
            "34 → WEDDINGS\n",
            "35 → WEIRD NEWS\n",
            "36 → WELLNESS\n",
            "37 → WOMEN\n",
            "38 → WORLD NEWS\n",
            "39 → WORLDPOST\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select parameters and model for model training\n",
        "bert_model_name = 'bert-base-uncased'\n",
        "num_classes = len(label_names)\n",
        "max_length = 256\n",
        "batch_size = 32\n",
        "num_epochs = 8\n",
        "learning_rate = 2e-5"
      ],
      "metadata": {
        "id": "w2oS76z7Lsnc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb initialization\n",
        "wandb.init(project=\"News classification\", name=\"LoRA and AMP\", config={\n",
        "    \"Model_name\": bert_model_name,\n",
        "    \"Epoch\": num_epochs,\n",
        "    \"Batch_size\": batch_size,\n",
        "    \"Learning_rate\": learning_rate,\n",
        "    \"Max_length\": max_length\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "SpfEG6RIL63q",
        "outputId": "4f92a2b2-2812-42c2-81a2-ee21d5dccaaf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">v3</strong> at: <a href='https://wandb.ai/hl6151-new-york-university/News%20classification/runs/uko1h9w2' target=\"_blank\">https://wandb.ai/hl6151-new-york-university/News%20classification/runs/uko1h9w2</a><br> View project at: <a href='https://wandb.ai/hl6151-new-york-university/News%20classification' target=\"_blank\">https://wandb.ai/hl6151-new-york-university/News%20classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250508_025553-uko1h9w2/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250508_025557-mqdmu9nb</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/hl6151-new-york-university/News%20classification/runs/mqdmu9nb' target=\"_blank\">LoRA and AMP</a></strong> to <a href='https://wandb.ai/hl6151-new-york-university/News%20classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/hl6151-new-york-university/News%20classification' target=\"_blank\">https://wandb.ai/hl6151-new-york-university/News%20classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/hl6151-new-york-university/News%20classification/runs/mqdmu9nb' target=\"_blank\">https://wandb.ai/hl6151-new-york-university/News%20classification/runs/mqdmu9nb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/hl6151-new-york-university/News%20classification/runs/mqdmu9nb?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7b9b27f36e90>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        \"\"\"\n",
        "        Dataset for text classification tasks.\n",
        "\n",
        "        Args:\n",
        "            texts (List[str]): List of input texts.\n",
        "            labels (List[int]): List of corresponding labels.\n",
        "            tokenizer: Tokenizer instance (e.g., from HuggingFace Transformers).\n",
        "            max_length (int): Maximum sequence length after tokenization.\n",
        "        \"\"\"\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            int: Total number of samples in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Retrieves the tokenized representation and label for a given index.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the sample.\n",
        "\n",
        "        Returns:\n",
        "            dict: Dictionary with 'input_ids', 'attention_mask', and 'label'.\n",
        "        \"\"\"\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Tokenize the text with padding and truncation\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            return_tensors='pt',\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),           # Token IDs (1D tensor)\n",
        "            'attention_mask': encoding['attention_mask'].flatten(), # Attention mask (1D tensor)\n",
        "            'label': torch.tensor(label)                            # Target label (scalar tensor)\n",
        "        }"
      ],
      "metadata": {
        "id": "3lEpNMhNL9Bs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Without mixed precision\n",
        "# Add wandb already\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "def train_original(model, dataloader, optimizer, scheduler, device, epoch=None):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    with profile(\n",
        "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA] if device.type == \"cuda\" else [ProfilerActivity.CPU],\n",
        "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=2, repeat=1),\n",
        "        on_trace_ready=torch.profiler.tensorboard_trace_handler(f\"./log_train_profiler\"),\n",
        "        record_shapes=True,\n",
        "        profile_memory=True,\n",
        "        with_stack=True\n",
        "    ) as profiler:\n",
        "\n",
        "        for step, batch in enumerate(tqdm(dataloader, desc=f\"Training Epoch {epoch if epoch is not None else ''}\")):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with record_function(\"forward_pass\"):\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.logits\n",
        "                loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "\n",
        "            with record_function(\"backward_pass\"):\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            scheduler.step()\n",
        "            profiler.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            wandb.log({\"train/loss_batch\": loss.item()})\n",
        "\n",
        "    print(profiler.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"cpu_time_total\", row_limit=20))\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"Average training loss: {avg_loss:.4f}\")\n",
        "    wandb.log({\"train/loss_epoch\": avg_loss})\n"
      ],
      "metadata": {
        "id": "n3dDQWjtL_Af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use Mixed Precision\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "from torch.cuda.amp import GradScaler\n",
        "\n",
        "scaler = torch.amp.GradScaler('cuda')\n",
        "\n",
        "def train(model, dataloader, optimizer, scheduler, device, epoch=None):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    with profile(\n",
        "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA] if device.type == \"cuda\" else [ProfilerActivity.CPU],\n",
        "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=2, repeat=1),\n",
        "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./log'),\n",
        "        record_shapes=True,\n",
        "        profile_memory=True,\n",
        "        with_stack=True\n",
        "    ) as profiler:\n",
        "\n",
        "        for step, batch in enumerate(tqdm(dataloader, desc=f\"Training Epoch {epoch if epoch is not None else ''}\")):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                with record_function(\"forward_pass\"):\n",
        "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                    logits = outputs.logits\n",
        "                    loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "\n",
        "            with record_function(\"backward_pass\"):\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "\n",
        "            scheduler.step()\n",
        "            profiler.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            wandb.log({\"train/loss_batch\": loss.item()})\n",
        "\n",
        "    print(profiler.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"cpu_time_total\", row_limit=20))\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"Average training loss: {avg_loss:.4f}\")\n",
        "    wandb.log({\"train/loss_epoch\": avg_loss})\n"
      ],
      "metadata": {
        "id": "w8rl5vMzMBd-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add wandb to track loss and metrics for evaluation function\n",
        "def evaluate(model, data_loader, device, epoch=None):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the validation or test set and log metrics using Weights & Biases (wandb).\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): Trained model to evaluate.\n",
        "        data_loader (DataLoader): DataLoader for validation/test dataset.\n",
        "        device (torch.device): Device to run evaluation on ('cuda' or 'cpu').\n",
        "        epoch (int, optional): Current epoch number (optional for logging).\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float, float]: accuracy, macro F1 score, weighted F1 score\n",
        "    \"\"\"\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    predictions = []\n",
        "    actual_labels = []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
        "        for batch in data_loader:\n",
        "            # Move batch to device\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Get predicted class by choosing the max logit\n",
        "            _, preds = torch.max(logits, dim=1)\n",
        "\n",
        "            # Store predictions and true labels for metric computation\n",
        "            predictions.extend(preds.cpu().tolist())\n",
        "            actual_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "    # Compute evaluation metrics\n",
        "    acc = accuracy_score(actual_labels, predictions)\n",
        "    macro_f1 = f1_score(actual_labels, predictions, average='macro')\n",
        "    weighted_f1 = f1_score(actual_labels, predictions, average='weighted')\n",
        "\n",
        "    # Log metrics to Weights & Biases\n",
        "    wandb.log({\n",
        "        \"eval/accuracy\": acc,\n",
        "        \"eval/macro_f1\": macro_f1,\n",
        "        \"eval/weighted_f1\": weighted_f1\n",
        "    })\n",
        "\n",
        "    return acc, macro_f1, weighted_f1\n"
      ],
      "metadata": {
        "id": "rlqTEFuOMDyr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.profiler import profile, record_function, ProfilerActivity, schedule, tensorboard_trace_handler\n",
        "import time\n",
        "def predict_news_category(text, model, tokenizer, device, encoder, max_length=128):\n",
        "    model.eval()\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=max_length\n",
        "    )\n",
        "    input_ids = inputs[\"input_ids\"].to(device)\n",
        "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
        "\n",
        "    with profile(\n",
        "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA] if device.type == \"cuda\" else [ProfilerActivity.CPU],\n",
        "        schedule=schedule(wait=1, warmup=1, active=5, repeat=1),  # only log 5 times!!\n",
        "        record_shapes=True,\n",
        "        profile_memory=True,\n",
        "        with_stack=True,\n",
        "        on_trace_ready=tensorboard_trace_handler(\"./log_predict_base_warmup\")\n",
        "    ) as profiler:\n",
        "        for i in range(7):\n",
        "            with torch.no_grad():\n",
        "                with record_function(f\"model_inference_{i}\"):\n",
        "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                    logits = outputs.logits\n",
        "                    _, predicted_label = torch.max(logits, dim=1)\n",
        "            profiler.step()\n",
        "\n",
        "    print(profiler.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"cpu_time_total\", row_limit=20))\n",
        "\n",
        "    predicted_category = encoder.inverse_transform(predicted_label.cpu().numpy())[0]\n",
        "    return predicted_category"
      ],
      "metadata": {
        "id": "biA-5HzsMISO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.amp import autocast\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "def predict_news_category_amp(text, model, tokenizer, device, encoder, max_length=128):\n",
        "    \"\"\"\n",
        "    Predict news category using AMP with torch.profiler to measure performance.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=max_length\n",
        "    )\n",
        "    input_ids = inputs[\"input_ids\"].to(device)\n",
        "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
        "\n",
        "    with profile(\n",
        "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA] if device.type == \"cuda\" else [ProfilerActivity.CPU],\n",
        "        schedule=schedule(wait=1, warmup=1, active=5, repeat=1),\n",
        "        record_shapes=True,\n",
        "        profile_memory=True,\n",
        "        with_stack=True,\n",
        "        on_trace_ready=torch.profiler.tensorboard_trace_handler(\"./log_amp_predict\")\n",
        "    ) as profiler:\n",
        "        for i in range(7):\n",
        "            with torch.no_grad():\n",
        "                with record_function(\"inference\"):\n",
        "                    with torch.amp.autocast('cuda'):\n",
        "                        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                        logits = outputs.logits\n",
        "                        _, predicted_label = torch.max(logits, dim=1)\n",
        "            profiler.step()\n",
        "\n",
        "    print(profiler.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"cpu_time_total\", row_limit=20))\n",
        "    predicted_category = encoder.inverse_transform(predicted_label.cpu().numpy())[0]\n",
        "    return predicted_category"
      ],
      "metadata": {
        "id": "2H6-J_GhMKEI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zMFNDupwML8Y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained tokenizer for BERT\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
        "\n",
        "# Create datasheet\n",
        "train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n",
        "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
        "\n",
        "# Wrap training dataset in a DataLoader for batching and shuffling\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "xvHlFRmOMO3w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "da2fdc70f44e4be791bd8900a536fc0e",
            "806bc93b806d4be996504eac75dd40a8",
            "d0fca20e108147b3a3b46517ec1b7451",
            "7978aafefa8a48cb96ca1933b3401186",
            "765d3635b77d4863be58da2fe9adefcc",
            "6fc5d3409167439fad04c7334327233e",
            "a261d6527efd4fbf8bddb33044aebf7b",
            "297f07d083d94d95bfeb421ef398a5b1",
            "dca8592a81a247d59d30f11327f1fc59",
            "921b72a5cd1244bebe90ae3b20177214",
            "0f9d35f20f7347d1b0967667d99756f3",
            "32a0452efc1c446f962791dc1d6fd2de",
            "cdca01f9f502488fa83b558bdb1596b6",
            "6ea6f739edd043649faa4a1d25363350",
            "e0d3f26a01f64467a05b96de50d093af",
            "ec9d680d7396498f9446705bc45f17e4",
            "bce13983255d4a8d851f2022e5250236",
            "47f3f33fc1004c4199f2f4aa0e201905",
            "377e7c0523574e62b78c3abcaea22a24",
            "1b9716cd0f4e47c28f3c343df1721177",
            "fd245f550ab34463a95314cf0724919a",
            "0dd20031ad4a4a75b5faf01d572287c5",
            "7cc06ce056874bdf85ce0820e5e763f4",
            "eee5e2c81a2047858c375fda82d734e7",
            "bc6b762b499a40cabd15110af0e97b2f",
            "711243fb6b8041528da26c2f43194788",
            "5b7828bfe33044a9b0aa34af11d0f713",
            "726565023c47438ca71c84350db201d8",
            "496c007fd54b4b899c79682ff31a51d2",
            "0dcab25f425841bdb9ee989e4283937a",
            "e1d03ae490cd440699c3e6ed14741c22",
            "2e10a32e32eb403ca0380091b5f035d6",
            "cf2e35d60ef74e17802bca941201fa01",
            "66246bc3516b4d6385c0f54f019df3b0",
            "18f460ee0d88491295b98cc9f166687f",
            "3bbd19758777475785b1f01c1453014d",
            "54f0ea6a74934a979b11e81aaa0a7aad",
            "964de26aaf7c4427b1eab9b266ab63a9",
            "da0afd853c2f4e9795809d57e5f02bca",
            "331e4823e4984b27847728d327776523",
            "ed95cb12c5d94c519f6cb842113d7a9c",
            "47027ef194734961bc60ddecb8c7da45",
            "55c412e68df941a384c102caf13afcd4",
            "e114206877b24573b13a794f3d38302b"
          ]
        },
        "outputId": "307fc1bf-46a8-4cbb-903d-346d6272a05e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da2fdc70f44e4be791bd8900a536fc0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32a0452efc1c446f962791dc1d6fd2de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cc06ce056874bdf85ce0820e5e763f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66246bc3516b4d6385c0f54f019df3b0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the available device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pre-trained model from hugging face\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    bert_model_name,\n",
        "    num_labels=num_classes\n",
        ")\n",
        "\n",
        "# LoRA configuration, only train part of parameters\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    r=8,                          # percentage of parameter compress\n",
        "    lora_alpha=32,                # scale factor, control update speed\n",
        "    lora_dropout=0.0,             # dropout\n",
        "    bias=\"lora_only\"              # only trains the bias for LoRA layer\n",
        ")\n",
        "\n",
        "model = get_peft_model(base_model, lora_config).to(device)\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "8677a8c685794a0dae148e0900cbd493",
            "2ca489dfafe242e98bee65cb3cac37e1",
            "c3f0465d93bd4d4dae4574a6ceba94f0",
            "ae5688950ce34737bbc717ce51d264ea",
            "4492c087914c424596af9f8e26b04bcd",
            "50075fc1340740b4aad722ef640eaa38",
            "81075d4983b64e459064f7c154dc7ebd",
            "d048b4d2a18348fb8afc5ba59e54e2ad",
            "11f4a3d3301044b9a52148bc418c5d4f",
            "0118978c5edc439aafd3132c5f83b329",
            "8a8ba6f241754a5e80a03ed5604084ee"
          ]
        },
        "id": "P1yFYL1QMQm1",
        "outputId": "57cf05bf-6c96-40d8-d154-9069ca10e9b9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8677a8c685794a0dae148e0900cbd493"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "total_steps = len(train_dataloader) * num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
      ],
      "metadata": {
        "id": "5qXUWSU8MS0M"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 128\n",
        "\n",
        "input_data = {\n",
        "    \"input_ids\": torch.zeros((batch_size, seq_len), dtype=torch.long).to(device),\n",
        "    \"attention_mask\": torch.ones((batch_size, seq_len), dtype=torch.long).to(device)\n",
        "}\n",
        "\n",
        "summary(model, input_data=input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdaklfn2MWHe",
        "outputId": "1bff4a8e-ef44-4028-b4d7-49997b618145"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=============================================================================================================================\n",
              "Layer (type:depth-idx)                                                      Output Shape              Param #\n",
              "=============================================================================================================================\n",
              "PeftModelForSequenceClassification                                          [32, 40]                  --\n",
              "├─LoraModel: 1-1                                                            [32, 40]                  --\n",
              "│    └─BertForSequenceClassification: 2-1                                   --                        --\n",
              "│    │    └─BertModel: 3-1                                                  [32, 768]                 109,777,152\n",
              "│    │    └─Dropout: 3-2                                                    [32, 768]                 --\n",
              "│    │    └─ModulesToSaveWrapper: 3-3                                       [32, 40]                  61,520\n",
              "=============================================================================================================================\n",
              "Total params: 109,838,672\n",
              "Trainable params: 344,104\n",
              "Non-trainable params: 109,494,568\n",
              "Total mult-adds (Units.GIGABYTES): 3.50\n",
              "=============================================================================================================================\n",
              "Input size (MB): 0.07\n",
              "Forward/backward pass size (MB): 4008.65\n",
              "Params size (MB): 439.23\n",
              "Estimated Total Size (MB): 4447.95\n",
              "============================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "print(batch.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vC_3yJwMXmv",
        "outputId": "8d350c35-3ef1-4a4c-ddec-34c92bb03a9f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'attention_mask', 'label'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if \"bias\" in name:\n",
        "        print(f\"{name}: requires_grad={param.requires_grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WDxjketMZFq",
        "outputId": "f0844283-d958-4c3b-e2c7-402c9d6fdd83"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base_model.model.bert.embeddings.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.0.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.0.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.0.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.0.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.0.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.0.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.0.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.0.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.1.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.1.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.1.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.1.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.1.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.1.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.1.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.1.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.2.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.2.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.2.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.2.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.2.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.2.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.2.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.2.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.3.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.3.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.3.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.3.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.3.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.3.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.3.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.3.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.4.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.4.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.4.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.4.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.4.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.4.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.4.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.4.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.5.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.5.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.5.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.5.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.5.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.5.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.5.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.5.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.6.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.6.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.6.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.6.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.6.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.6.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.6.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.6.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.7.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.7.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.7.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.7.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.7.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.7.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.7.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.7.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.8.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.8.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.8.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.8.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.8.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.8.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.8.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.8.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.9.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.9.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.9.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.9.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.9.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.9.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.9.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.9.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.10.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.10.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.10.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.10.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.10.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.10.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.10.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.10.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.11.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.11.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.11.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.11.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.11.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.11.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.11.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.11.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.pooler.dense.bias: requires_grad=False\n",
            "base_model.model.classifier.original_module.bias: requires_grad=False\n",
            "base_model.model.classifier.modules_to_save.default.bias: requires_grad=True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LoRA and Mixed Precision\n",
        "for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "        train(model, train_dataloader, optimizer, scheduler, device)\n",
        "        accuracy, macro_f1, weighted_f1 = evaluate(model, val_dataloader, device)\n",
        "        print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Macro F1: {macro_f1:.4f}\")\n",
        "        print(f\"Weighted F1: {weighted_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GSYMk2cMbwL",
        "outputId": "1a7e14c3-60b8-4566-e573-abf8cb740729"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch : 100%|██████████| 5022/5022 [07:09<00:00, 11.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us     191.825ms       190.52%     191.825ms      95.913ms           0 b           0 b           0 b           0 b             2  \n",
            "                                          backward_pass         0.00%       0.000us         0.00%       0.000us       0.000us     102.660ms       101.96%     102.660ms      51.330ms           0 b           0 b           0 b           0 b             2  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us      93.499ms        92.86%      93.499ms      46.749ms           0 b           0 b           0 b           0 b             2  \n",
            "                                          ProfilerStep*         1.40%       6.570ms        84.07%     393.555ms     196.777ms       0.000us         0.00%      43.491ms      21.745ms     128.25 Kb    -128.25 Kb           0 b    -378.00 Kb             2  \n",
            "                                           forward_pass         6.44%      30.148ms        20.67%      96.753ms      48.377ms       0.000us         0.00%      43.111ms      21.556ms         768 b         384 b       4.70 Gb      -5.35 Gb             2  \n",
            "                                           aten::linear         1.08%       5.076ms        15.11%      70.741ms     144.961us       0.000us         0.00%      42.099ms      86.269us           0 b           0 b       7.13 Gb      -1.14 Gb           488  \n",
            "                                               aten::mm         2.87%      13.428ms         4.00%      18.724ms      43.748us      21.049ms        20.91%      21.049ms      49.181us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.40%       1.863ms         2.70%      12.631ms      86.511us       0.000us         0.00%      17.248ms     118.137us           0 b           0 b    -425.43 Mb      -2.88 Gb           146  \n",
            "                                            aten::addmm         1.72%       8.039ms         2.37%      11.079ms      74.860us      16.331ms        16.22%      16.331ms     110.342us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                         AddmmBackward0         0.20%     935.076us         1.80%       8.408ms      57.592us       0.000us         0.00%      15.915ms     109.004us           0 b           0 b       2.46 Gb           0 b           146  \n",
            "ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      15.841ms        15.73%      15.841ms     114.788us           0 b           0 b           0 b           0 b           138  \n",
            "                                            aten::copy_         1.85%       8.659ms         3.77%      17.645ms      19.096us      14.540ms        14.44%      14.540ms      15.735us           0 b           0 b           0 b           0 b           924  \n",
            "                                               aten::to         0.42%       1.965ms         7.37%      34.525ms      28.115us       0.000us         0.00%      14.411ms      11.736us           0 b           0 b       5.89 Gb           0 b          1228  \n",
            "                                         aten::_to_copy         1.57%       7.367ms         6.96%      32.560ms      35.545us       0.000us         0.00%      14.411ms      15.733us           0 b           0 b       5.89 Gb           0 b           916  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         0.66%       3.071ms         3.63%      17.008ms      59.468us       0.000us         0.00%      13.898ms      48.595us           0 b           0 b      -1.57 Gb      -4.71 Gb           286  \n",
            "                     aten::scaled_dot_product_attention         0.12%     552.474us         1.57%       7.333ms     152.768us       0.000us         0.00%      13.022ms     271.297us         768 b           0 b     690.00 Mb           0 b            48  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.13%     601.658us         1.03%       4.837ms     201.562us       0.000us         0.00%      12.831ms     534.614us        -384 b        -384 b    -705.00 Mb      -1.51 Gb            24  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.07%     342.694us         0.90%       4.236ms     176.492us       0.000us         0.00%      12.831ms     534.614us           0 b           0 b     840.00 Mb     -24.00 Mb            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.13%     629.540us         0.83%       3.893ms     162.214us       0.000us         0.00%      12.831ms     534.614us           0 b           0 b     864.00 Mb           0 b            24  \n",
            "                    aten::_efficient_attention_backward         0.19%     869.902us         0.57%       2.649ms     110.366us      12.393ms        12.31%      12.831ms     534.614us           0 b           0 b     864.00 Mb    -585.56 Mb            24  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 468.140ms\n",
            "Self CUDA time total: 100.685ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                    aten::empty_strided         2.02%       9.436ms         2.02%       9.436ms       8.065us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       6.79 Gb       6.79 Gb          1170  \n",
            "                                            aten::empty         1.12%       5.246ms         1.12%       5.246ms       6.260us       0.000us         0.00%       0.000us       0.000us     384.51 Kb     384.51 Kb       4.82 Gb       4.82 Gb           838  \n",
            "                                               aten::mm         2.87%      13.428ms         4.00%      18.724ms      43.748us      21.049ms        20.91%      21.049ms      49.181us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "                                            aten::addmm         1.72%       8.039ms         2.37%      11.079ms      74.860us      16.331ms        16.22%      16.331ms     110.342us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                              aten::add         0.39%       1.823ms         0.58%       2.697ms      27.515us       4.272ms         4.24%       4.272ms      43.589us           0 b           0 b       1.73 Gb       1.73 Gb            98  \n",
            "                                              aten::mul         0.50%       2.334ms         0.72%       3.383ms      33.831us       1.749ms         1.74%       1.749ms      17.489us           0 b           0 b       1.13 Gb       1.13 Gb           100  \n",
            "                                             aten::gelu         0.11%     531.644us         0.17%     785.550us      32.731us       2.158ms         2.14%       2.158ms      89.918us           0 b           0 b       1.12 Gb       1.12 Gb            24  \n",
            "                                    aten::gelu_backward         0.09%     412.240us         0.14%     651.393us      27.141us       2.983ms         2.96%       2.983ms     124.282us           0 b           0 b       1.12 Gb       1.12 Gb            24  \n",
            "                                          aten::resize_         0.01%      42.984us         0.01%      42.984us       5.373us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      97.50 Mb      97.50 Mb             8  \n",
            "                                              aten::sub         0.01%      51.262us         0.02%      77.683us      38.841us      16.416us         0.02%      16.416us       8.208us           0 b           0 b      16.00 Mb      16.00 Mb             2  \n",
            "                                           Buffer Flush         0.03%     118.890us         0.03%     118.890us      59.445us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      12.00 Mb      12.00 Mb             2  \n",
            "                                             aten::tanh         0.01%      53.482us         0.02%      76.503us      38.252us       6.400us         0.01%       6.400us       3.200us           0 b           0 b      96.00 Kb      96.00 Kb             2  \n",
            "                                    aten::tanh_backward         0.01%      33.113us         0.01%      57.077us      28.538us       5.186us         0.01%       5.186us       2.593us           0 b           0 b      96.00 Kb      96.00 Kb             2  \n",
            "                                              aten::sum         0.27%       1.259ms         0.47%       2.184ms      43.685us       1.333ms         1.32%       1.333ms      26.669us           0 b           0 b      73.00 Kb      73.00 Kb            50  \n",
            "                                               aten::eq         0.01%      66.559us         0.02%      91.525us      45.763us       6.752us         0.01%       6.752us       3.376us           0 b           0 b      16.00 Kb      16.00 Kb             2  \n",
            "                                aten::nll_loss_backward         0.01%      38.529us         0.02%     104.261us      52.130us       5.792us         0.01%      10.336us       5.168us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                     aten::_log_softmax         0.02%      87.263us         0.03%     124.825us      62.413us       6.336us         0.01%       6.336us       3.168us           0 b           0 b       5.00 Kb       5.00 Kb             2  \n",
            "                       aten::_log_softmax_backward_data         0.01%      33.530us         0.01%      51.449us      25.725us       6.144us         0.01%       6.144us       3.072us           0 b           0 b       5.00 Kb       5.00 Kb             2  \n",
            "                                 aten::nll_loss_forward         0.01%      51.578us         0.02%      71.815us      35.907us       6.624us         0.01%       6.624us       3.312us           0 b           0 b       2.00 Kb       2.00 Kb             2  \n",
            "                                              aten::all         0.01%      57.204us         0.02%      80.217us      40.109us      13.311us         0.01%      13.311us       6.656us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 468.140ms\n",
            "Self CUDA time total: 100.685ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         1.40%       6.570ms        84.07%     393.555ms     196.777ms       0.000us         0.00%      43.491ms      21.745ms     128.25 Kb    -128.25 Kb           0 b    -378.00 Kb             2  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        38.89%     182.078ms        39.69%     185.822ms      92.911ms       0.000us         0.00%       0.000us       0.000us     256.50 Kb    -384.50 Kb           0 b           0 b             2  \n",
            "                                          backward_pass        19.79%      92.629ms        22.01%     103.047ms      51.524ms       0.000us         0.00%     336.519us     168.260us        -768 b        -768 b      -4.70 Gb      -4.71 Gb             2  \n",
            "                                           forward_pass         6.44%      30.148ms        20.67%      96.753ms      48.377ms       0.000us         0.00%      43.111ms      21.556ms         768 b         384 b       4.70 Gb      -5.35 Gb             2  \n",
            "                                           aten::linear         1.08%       5.076ms        15.11%      70.741ms     144.961us       0.000us         0.00%      42.099ms      86.269us           0 b           0 b       7.13 Gb      -1.14 Gb           488  \n",
            "                                               aten::to         0.42%       1.965ms         7.37%      34.525ms      28.115us       0.000us         0.00%      14.411ms      11.736us           0 b           0 b       5.89 Gb           0 b          1228  \n",
            "                                         aten::_to_copy         1.57%       7.367ms         6.96%      32.560ms      35.545us       0.000us         0.00%      14.411ms      15.733us           0 b           0 b       5.89 Gb           0 b           916  \n",
            "                                       cudaLaunchKernel         4.54%      21.234ms         4.54%      21.234ms       9.429us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          2252  \n",
            "                                               aten::mm         2.87%      13.428ms         4.00%      18.724ms      43.748us      21.049ms        20.91%      21.049ms      49.181us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "                                            aten::copy_         1.85%       8.659ms         3.77%      17.645ms      19.096us      14.540ms        14.44%      14.540ms      15.735us           0 b           0 b           0 b           0 b           924  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         0.66%       3.071ms         3.63%      17.008ms      59.468us       0.000us         0.00%      13.898ms      48.595us           0 b           0 b      -1.57 Gb      -4.71 Gb           286  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.40%       1.863ms         2.70%      12.631ms      86.511us       0.000us         0.00%      17.248ms     118.137us           0 b           0 b    -425.43 Mb      -2.88 Gb           146  \n",
            "       autograd::engine::evaluate_function: MmBackward0         0.34%       1.597ms         2.66%      12.476ms     129.956us       0.000us         0.00%       3.630ms      37.812us           0 b           0 b    -629.95 Mb      -1.14 Gb            96  \n",
            "                                        ToCopyBackward0         0.18%     826.377us         2.51%      11.740ms      41.048us       0.000us         0.00%       6.173ms      21.585us           0 b           0 b       3.14 Gb           0 b           286  \n",
            "                                            aten::addmm         1.72%       8.039ms         2.37%      11.079ms      74.860us      16.331ms        16.22%      16.331ms     110.342us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                            MmBackward0         0.24%       1.141ms         2.32%      10.879ms     113.321us       0.000us         0.00%       3.630ms      37.812us           0 b           0 b     535.12 Mb           0 b            96  \n",
            "                                    aten::empty_strided         2.02%       9.436ms         2.02%       9.436ms       8.065us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       6.79 Gb       6.79 Gb          1170  \n",
            "                              Optimizer.step#AdamW.step         1.10%       5.127ms         1.94%       9.091ms       4.545ms       0.000us         0.00%     253.602us     126.801us           0 b          -8 b           0 b      -2.63 Mb             2  \n",
            "     autograd::engine::evaluate_function: ViewBackward0         1.11%       5.193ms         1.90%       8.908ms      19.116us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           466  \n",
            "                                         AddmmBackward0         0.20%     935.076us         1.80%       8.408ms      57.592us       0.000us         0.00%      15.915ms     109.004us           0 b           0 b       2.46 Gb           0 b           146  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 468.140ms\n",
            "Self CUDA time total: 100.685ms\n",
            "\n",
            "Average training loss: 2.3599\n",
            "Validation Accuracy: 0.5191\n",
            "Macro F1: 0.2263\n",
            "Weighted F1: 0.4326\n",
            "Epoch 2/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch : 100%|██████████| 5022/5022 [07:15<00:00, 11.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us     163.032ms       191.11%     163.032ms      81.516ms           0 b           0 b           0 b           0 b             2  \n",
            "                                          backward_pass         0.00%       0.000us         0.00%       0.000us       0.000us     102.644ms       120.32%     102.644ms      51.322ms           0 b           0 b           0 b           0 b             2  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us      91.884ms       107.71%      91.884ms      45.942ms           0 b           0 b           0 b           0 b             2  \n",
            "                                          ProfilerStep*         0.80%       3.483ms        83.37%     361.751ms     180.876ms       0.000us         0.00%      36.445ms      18.223ms     128.25 Kb    -128.25 Kb           0 b    -378.00 Kb             2  \n",
            "                                           forward_pass         6.30%      27.356ms        21.66%      93.979ms      46.989ms       0.000us         0.00%      36.140ms      18.070ms         768 b         384 b       4.70 Gb      -5.35 Gb             2  \n",
            "                                           aten::linear         1.18%       5.126ms        16.45%      71.396ms     146.303us       0.000us         0.00%      34.068ms      69.811us           0 b           0 b       7.13 Gb      -1.14 Gb           488  \n",
            "                                               aten::mm         3.14%      13.618ms         4.38%      19.014ms      44.424us      16.550ms        19.40%      16.550ms      38.669us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.44%       1.896ms         2.97%      12.867ms      88.131us       0.000us         0.00%      13.526ms      92.642us           0 b           0 b    -425.43 Mb      -2.88 Gb           146  \n",
            "                                            aten::copy_         2.01%       8.713ms         4.09%      17.758ms      19.219us      13.091ms        15.35%      13.091ms      14.167us           0 b           0 b           0 b           0 b           924  \n",
            "                                               aten::to         0.46%       2.010ms         8.04%      34.890ms      28.412us       0.000us         0.00%      12.974ms      10.565us           0 b           0 b       5.89 Gb           0 b          1228  \n",
            "                                         aten::_to_copy         1.67%       7.256ms         7.58%      32.880ms      35.895us       0.000us         0.00%      12.974ms      14.163us           0 b           0 b       5.89 Gb           0 b           916  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         0.71%       3.093ms         3.94%      17.108ms      59.817us       0.000us         0.00%      12.854ms      44.944us           0 b           0 b      -1.57 Gb      -4.71 Gb           286  \n",
            "                                            aten::addmm         1.87%       8.113ms         2.58%      11.194ms      75.634us      12.800ms        15.00%      12.800ms      86.483us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                         AddmmBackward0         0.22%     966.490us         1.99%       8.640ms      59.178us       0.000us         0.00%      12.467ms      85.390us           0 b           0 b       2.46 Gb           0 b           146  \n",
            "ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      12.409ms        14.55%      12.409ms      89.923us           0 b           0 b           0 b           0 b           138  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.14%     619.921us         1.08%       4.675ms     194.790us       0.000us         0.00%      10.364ms     431.850us        -384 b        -384 b    -705.00 Mb      -1.51 Gb            24  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.06%     245.292us         0.93%       4.055ms     168.960us       0.000us         0.00%      10.364ms     431.850us           0 b           0 b     840.00 Mb     -24.00 Mb            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.14%     624.323us         0.88%       3.810ms     158.739us       0.000us         0.00%      10.364ms     431.850us           0 b           0 b     864.00 Mb           0 b            24  \n",
            "                    aten::_efficient_attention_backward         0.20%     849.452us         0.59%       2.577ms     107.389us       9.942ms        11.65%      10.364ms     431.850us           0 b           0 b     864.00 Mb    -585.56 Mb            24  \n",
            "                     aten::scaled_dot_product_attention         0.13%     558.315us         1.66%       7.214ms     150.297us       0.000us         0.00%      10.318ms     214.954us         768 b           0 b     690.00 Mb           0 b            48  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 433.892ms\n",
            "Self CUDA time total: 85.306ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                    aten::empty_strided         2.25%       9.755ms         2.25%       9.755ms       8.338us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       6.79 Gb       6.79 Gb          1170  \n",
            "                                            aten::empty         1.18%       5.129ms         1.18%       5.129ms       6.121us       0.000us         0.00%       0.000us       0.000us     384.51 Kb     384.51 Kb       4.82 Gb       4.82 Gb           838  \n",
            "                                               aten::mm         3.14%      13.618ms         4.38%      19.014ms      44.424us      16.550ms        19.40%      16.550ms      38.669us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "                                            aten::addmm         1.87%       8.113ms         2.58%      11.194ms      75.634us      12.800ms        15.00%      12.800ms      86.483us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                              aten::add         0.43%       1.858ms         0.62%       2.699ms      27.545us       3.979ms         4.66%       3.979ms      40.602us           0 b           0 b       1.73 Gb       1.73 Gb            98  \n",
            "                                              aten::mul         0.53%       2.311ms         0.77%       3.360ms      33.601us       1.596ms         1.87%       1.596ms      15.962us           0 b           0 b       1.13 Gb       1.13 Gb           100  \n",
            "                                             aten::gelu         0.12%     515.996us         0.18%     780.726us      32.530us       1.952ms         2.29%       1.952ms      81.334us           0 b           0 b       1.12 Gb       1.12 Gb            24  \n",
            "                                    aten::gelu_backward         0.09%     410.369us         0.15%     641.655us      26.736us       2.828ms         3.31%       2.828ms     117.824us           0 b           0 b       1.12 Gb       1.12 Gb            24  \n",
            "                                          aten::resize_         0.01%      48.190us         0.01%      48.190us       6.024us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      97.50 Mb      97.50 Mb             8  \n",
            "                                              aten::sub         0.01%      44.220us         0.02%      65.659us      32.829us      13.089us         0.02%      13.089us       6.544us           0 b           0 b      16.00 Mb      16.00 Mb             2  \n",
            "                                           Buffer Flush         0.02%      80.270us         0.02%      80.270us      80.270us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      12.00 Mb      12.00 Mb             1  \n",
            "                                             aten::tanh         0.01%      52.462us         0.02%      73.845us      36.923us       4.960us         0.01%       4.960us       2.480us           0 b           0 b      96.00 Kb      96.00 Kb             2  \n",
            "                                    aten::tanh_backward         0.01%      35.516us         0.01%      54.469us      27.235us       4.063us         0.00%       4.063us       2.032us           0 b           0 b      96.00 Kb      96.00 Kb             2  \n",
            "                                              aten::sum         0.30%       1.313ms         0.50%       2.177ms      43.536us       1.059ms         1.24%       1.059ms      21.175us           0 b           0 b      73.00 Kb      73.00 Kb            50  \n",
            "                                               aten::eq         0.02%      68.082us         0.02%      94.138us      47.069us       5.536us         0.01%       5.536us       2.768us           0 b           0 b      16.00 Kb      16.00 Kb             2  \n",
            "                                aten::nll_loss_backward         0.01%      39.282us         0.02%     104.353us      52.176us       4.704us         0.01%       8.255us       4.128us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                     aten::_log_softmax         0.02%      69.430us         0.02%     105.873us      52.936us       4.640us         0.01%       4.640us       2.320us           0 b           0 b       5.00 Kb       5.00 Kb             2  \n",
            "                       aten::_log_softmax_backward_data         0.01%      33.537us         0.01%      51.787us      25.893us       4.865us         0.01%       4.865us       2.432us           0 b           0 b       5.00 Kb       5.00 Kb             2  \n",
            "                                 aten::nll_loss_forward         0.01%      56.773us         0.02%      76.176us      38.088us       4.864us         0.01%       4.864us       2.432us           0 b           0 b       2.00 Kb       2.00 Kb             2  \n",
            "                                              aten::all         0.01%      59.122us         0.02%      83.644us      41.822us      10.464us         0.01%      10.464us       5.232us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 433.892ms\n",
            "Self CUDA time total: 85.306ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.80%       3.483ms        83.37%     361.751ms     180.876ms       0.000us         0.00%      36.445ms      18.223ms     128.25 Kb    -128.25 Kb           0 b    -378.00 Kb             2  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        36.03%     156.353ms        36.81%     159.734ms      79.867ms       0.000us         0.00%       0.000us       0.000us     256.50 Kb    -384.50 Kb           0 b           0 b             2  \n",
            "                                          backward_pass        21.32%      92.527ms        23.75%     103.036ms      51.518ms       0.000us         0.00%     266.019us     133.009us        -768 b        -768 b      -4.70 Gb      -4.71 Gb             2  \n",
            "                                           forward_pass         6.30%      27.356ms        21.66%      93.979ms      46.989ms       0.000us         0.00%      36.140ms      18.070ms         768 b         384 b       4.70 Gb      -5.35 Gb             2  \n",
            "                                           aten::linear         1.18%       5.126ms        16.45%      71.396ms     146.303us       0.000us         0.00%      34.068ms      69.811us           0 b           0 b       7.13 Gb      -1.14 Gb           488  \n",
            "                                               aten::to         0.46%       2.010ms         8.04%      34.890ms      28.412us       0.000us         0.00%      12.974ms      10.565us           0 b           0 b       5.89 Gb           0 b          1228  \n",
            "                                         aten::_to_copy         1.67%       7.256ms         7.58%      32.880ms      35.895us       0.000us         0.00%      12.974ms      14.163us           0 b           0 b       5.89 Gb           0 b           916  \n",
            "                                       cudaLaunchKernel         4.90%      21.251ms         4.90%      21.251ms       9.437us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          2252  \n",
            "                                               aten::mm         3.14%      13.618ms         4.38%      19.014ms      44.424us      16.550ms        19.40%      16.550ms      38.669us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "                                            aten::copy_         2.01%       8.713ms         4.09%      17.758ms      19.219us      13.091ms        15.35%      13.091ms      14.167us           0 b           0 b           0 b           0 b           924  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         0.71%       3.093ms         3.94%      17.108ms      59.817us       0.000us         0.00%      12.854ms      44.944us           0 b           0 b      -1.57 Gb      -4.71 Gb           286  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.44%       1.896ms         2.97%      12.867ms      88.131us       0.000us         0.00%      13.526ms      92.642us           0 b           0 b    -425.43 Mb      -2.88 Gb           146  \n",
            "       autograd::engine::evaluate_function: MmBackward0         0.36%       1.569ms         2.89%      12.528ms     130.498us       0.000us         0.00%       2.900ms      30.209us           0 b           0 b    -629.95 Mb      -1.14 Gb            96  \n",
            "                                        ToCopyBackward0         0.18%     798.270us         2.71%      11.770ms      41.155us       0.000us         0.00%       5.116ms      17.887us           0 b           0 b       3.14 Gb           0 b           286  \n",
            "                                            aten::addmm         1.87%       8.113ms         2.58%      11.194ms      75.634us      12.800ms        15.00%      12.800ms      86.483us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                            MmBackward0         0.27%       1.164ms         2.53%      10.959ms     114.156us       0.000us         0.00%       2.900ms      30.209us           0 b           0 b     535.12 Mb           0 b            96  \n",
            "                                    aten::empty_strided         2.25%       9.755ms         2.25%       9.755ms       8.338us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       6.79 Gb       6.79 Gb          1170  \n",
            "                              Optimizer.step#AdamW.step         1.18%       5.114ms         2.10%       9.116ms       4.558ms       0.000us         0.00%     201.375us     100.687us           0 b          -8 b           0 b      -2.63 Mb             2  \n",
            "                                         AddmmBackward0         0.22%     966.490us         1.99%       8.640ms      59.178us       0.000us         0.00%      12.467ms      85.390us           0 b           0 b       2.46 Gb           0 b           146  \n",
            "                     aten::scaled_dot_product_attention         0.13%     558.315us         1.66%       7.214ms     150.297us       0.000us         0.00%      10.318ms     214.954us         768 b           0 b     690.00 Mb           0 b            48  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 433.892ms\n",
            "Self CUDA time total: 85.306ms\n",
            "\n",
            "Average training loss: 1.7518\n",
            "Validation Accuracy: 0.5665\n",
            "Macro F1: 0.3039\n",
            "Weighted F1: 0.5013\n",
            "Epoch 3/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch : 100%|██████████| 5022/5022 [07:16<00:00, 11.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us     159.013ms       186.46%     159.013ms      79.507ms           0 b           0 b           0 b           0 b             2  \n",
            "                                          backward_pass         0.00%       0.000us         0.00%       0.000us       0.000us      96.238ms       112.85%      96.238ms      48.119ms           0 b           0 b           0 b           0 b             2  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us      88.912ms       104.26%      88.912ms      44.456ms           0 b           0 b           0 b           0 b             2  \n",
            "                                          ProfilerStep*         0.85%       3.546ms        83.61%     348.718ms     174.359ms       0.000us         0.00%      36.441ms      18.220ms     128.25 Kb    -128.25 Kb           0 b    -378.00 Kb             2  \n",
            "                                           forward_pass         6.45%      26.896ms        21.88%      91.272ms      45.636ms       0.000us         0.00%      36.133ms      18.066ms         768 b         384 b       4.70 Gb      -5.36 Gb             2  \n",
            "                                           aten::linear         1.08%       4.521ms        16.37%      68.263ms     139.883us       0.000us         0.00%      34.064ms      69.803us           0 b           0 b       7.14 Gb      -1.13 Gb           488  \n",
            "                                               aten::mm         3.13%      13.034ms         4.34%      18.111ms      42.315us      16.542ms        19.40%      16.542ms      38.650us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.45%       1.876ms         2.93%      12.200ms      83.560us       0.000us         0.00%      13.521ms      92.608us           0 b           0 b    -425.43 Mb      -2.88 Gb           146  \n",
            "                                            aten::copy_         2.02%       8.436ms         4.10%      17.108ms      18.516us      13.087ms        15.35%      13.087ms      14.163us           0 b           0 b           0 b           0 b           924  \n",
            "                                               aten::to         0.45%       1.870ms         7.93%      33.089ms      26.945us       0.000us         0.00%      12.970ms      10.562us           0 b           0 b       5.89 Gb           0 b          1228  \n",
            "                                         aten::_to_copy         1.62%       6.776ms         7.49%      31.219ms      34.082us       0.000us         0.00%      12.970ms      14.160us           0 b           0 b       5.89 Gb           0 b           916  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         0.72%       3.000ms         3.84%      16.002ms      55.951us       0.000us         0.00%      12.846ms      44.916us           0 b           0 b      -1.57 Gb      -4.71 Gb           286  \n",
            "                                            aten::addmm         1.91%       7.957ms         2.63%      10.960ms      74.056us      12.796ms        15.00%      12.796ms      86.462us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                         AddmmBackward0         0.22%     910.720us         1.94%       8.104ms      55.507us       0.000us         0.00%      12.465ms      85.374us           0 b           0 b       2.46 Gb           0 b           146  \n",
            "ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      12.409ms        14.55%      12.409ms      89.917us           0 b           0 b           0 b           0 b           138  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.15%     618.495us         1.08%       4.507ms     187.803us       0.000us         0.00%      10.364ms     431.842us        -384 b        -384 b    -705.00 Mb      -1.51 Gb            24  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.06%     246.722us         0.93%       3.889ms     162.033us       0.000us         0.00%      10.364ms     431.842us           0 b           0 b     840.00 Mb     -24.00 Mb            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.15%     634.584us         0.87%       3.642ms     151.753us       0.000us         0.00%      10.364ms     431.842us           0 b           0 b     864.00 Mb           0 b            24  \n",
            "                    aten::_efficient_attention_backward         0.19%     802.936us         0.60%       2.494ms     103.924us       9.941ms        11.66%      10.364ms     431.842us           0 b           0 b     864.00 Mb    -585.56 Mb            24  \n",
            "                     aten::scaled_dot_product_attention         0.13%     523.030us         1.64%       6.842ms     142.544us       0.000us         0.00%      10.316ms     214.916us         768 b           0 b     690.00 Mb           0 b            48  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 417.060ms\n",
            "Self CUDA time total: 85.282ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                    aten::empty_strided         2.21%       9.206ms         2.21%       9.206ms       7.868us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       6.79 Gb       6.79 Gb          1170  \n",
            "                                            aten::empty         1.18%       4.912ms         1.18%       4.912ms       5.861us       0.000us         0.00%       0.000us       0.000us     384.51 Kb     384.51 Kb       4.82 Gb       4.82 Gb           838  \n",
            "                                               aten::mm         3.13%      13.034ms         4.34%      18.111ms      42.315us      16.542ms        19.40%      16.542ms      38.650us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "                                            aten::addmm         1.91%       7.957ms         2.63%      10.960ms      74.056us      12.796ms        15.00%      12.796ms      86.462us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                              aten::add         0.47%       1.967ms         0.67%       2.776ms      28.324us       3.980ms         4.67%       3.980ms      40.612us           0 b           0 b       1.73 Gb       1.73 Gb            98  \n",
            "                                              aten::mul         0.55%       2.287ms         0.79%       3.295ms      32.948us       1.594ms         1.87%       1.594ms      15.940us           0 b           0 b       1.13 Gb       1.13 Gb           100  \n",
            "                                             aten::gelu         0.13%     536.793us         0.19%     781.021us      32.543us       1.951ms         2.29%       1.951ms      81.286us           0 b           0 b       1.12 Gb       1.12 Gb            24  \n",
            "                                    aten::gelu_backward         0.10%     401.004us         0.15%     625.073us      26.045us       2.828ms         3.32%       2.828ms     117.830us           0 b           0 b       1.12 Gb       1.12 Gb            24  \n",
            "                                          aten::resize_         0.01%      48.094us         0.01%      48.094us       6.012us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      97.50 Mb      97.50 Mb             8  \n",
            "                                              aten::sub         0.01%      44.287us         0.02%      65.188us      32.594us      12.769us         0.01%      12.769us       6.385us           0 b           0 b      16.00 Mb      16.00 Mb             2  \n",
            "                                           Buffer Flush         0.02%      79.011us         0.02%      79.011us      79.011us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      12.00 Mb      12.00 Mb             1  \n",
            "                                             aten::tanh         0.01%      50.908us         0.02%      72.234us      36.117us       4.960us         0.01%       4.960us       2.480us           0 b           0 b      96.00 Kb      96.00 Kb             2  \n",
            "                                    aten::tanh_backward         0.01%      42.546us         0.02%      66.223us      33.111us       4.064us         0.00%       4.064us       2.032us           0 b           0 b      96.00 Kb      96.00 Kb             2  \n",
            "                                              aten::sum         0.31%       1.294ms         0.50%       2.093ms      41.861us       1.056ms         1.24%       1.056ms      21.125us           0 b           0 b      73.00 Kb      73.00 Kb            50  \n",
            "                                               aten::eq         0.02%      67.733us         0.02%      90.766us      45.383us       5.761us         0.01%       5.761us       2.880us           0 b           0 b      16.00 Kb      16.00 Kb             2  \n",
            "                                aten::nll_loss_backward         0.01%      38.735us         0.02%     103.030us      51.515us       4.577us         0.01%       8.129us       4.064us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                     aten::_log_softmax         0.02%      67.239us         0.02%     101.465us      50.733us       4.640us         0.01%       4.640us       2.320us           0 b           0 b       5.00 Kb       5.00 Kb             2  \n",
            "                       aten::_log_softmax_backward_data         0.01%      34.639us         0.01%      51.739us      25.869us       4.898us         0.01%       4.898us       2.449us           0 b           0 b       5.00 Kb       5.00 Kb             2  \n",
            "                                 aten::nll_loss_forward         0.01%      50.834us         0.02%      69.562us      34.781us       4.896us         0.01%       4.896us       2.448us           0 b           0 b       2.00 Kb       2.00 Kb             2  \n",
            "                                              aten::all         0.01%      61.032us         0.02%      84.203us      42.101us      10.369us         0.01%      10.369us       5.185us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 417.060ms\n",
            "Self CUDA time total: 85.282ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.85%       3.546ms        83.61%     348.718ms     174.359ms       0.000us         0.00%      36.441ms      18.220ms     128.25 Kb    -128.25 Kb           0 b    -378.00 Kb             2  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        36.58%     152.579ms        37.33%     155.707ms      77.854ms       0.000us         0.00%       0.000us       0.000us     256.50 Kb    -384.50 Kb           0 b           0 b             2  \n",
            "                                          backward_pass        20.77%      86.607ms        23.18%      96.658ms      48.329ms       0.000us         0.00%     267.910us     133.955us        -768 b        -768 b      -4.70 Gb      -4.71 Gb             2  \n",
            "                                           forward_pass         6.45%      26.896ms        21.88%      91.272ms      45.636ms       0.000us         0.00%      36.133ms      18.066ms         768 b         384 b       4.70 Gb      -5.36 Gb             2  \n",
            "                                           aten::linear         1.08%       4.521ms        16.37%      68.263ms     139.883us       0.000us         0.00%      34.064ms      69.803us           0 b           0 b       7.14 Gb      -1.13 Gb           488  \n",
            "                                               aten::to         0.45%       1.870ms         7.93%      33.089ms      26.945us       0.000us         0.00%      12.970ms      10.562us           0 b           0 b       5.89 Gb           0 b          1228  \n",
            "                                         aten::_to_copy         1.62%       6.776ms         7.49%      31.219ms      34.082us       0.000us         0.00%      12.970ms      14.160us           0 b           0 b       5.89 Gb           0 b           916  \n",
            "                                       cudaLaunchKernel         4.87%      20.330ms         4.87%      20.330ms       9.027us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          2252  \n",
            "                                               aten::mm         3.13%      13.034ms         4.34%      18.111ms      42.315us      16.542ms        19.40%      16.542ms      38.650us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "                                            aten::copy_         2.02%       8.436ms         4.10%      17.108ms      18.516us      13.087ms        15.35%      13.087ms      14.163us           0 b           0 b           0 b           0 b           924  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         0.72%       3.000ms         3.84%      16.002ms      55.951us       0.000us         0.00%      12.846ms      44.916us           0 b           0 b      -1.57 Gb      -4.71 Gb           286  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.45%       1.876ms         2.93%      12.200ms      83.560us       0.000us         0.00%      13.521ms      92.608us           0 b           0 b    -425.43 Mb      -2.88 Gb           146  \n",
            "       autograd::engine::evaluate_function: MmBackward0         0.35%       1.446ms         2.82%      11.746ms     122.351us       0.000us         0.00%       2.894ms      30.146us           0 b           0 b    -629.95 Mb      -1.14 Gb            96  \n",
            "                                            aten::addmm         1.91%       7.957ms         2.63%      10.960ms      74.056us      12.796ms        15.00%      12.796ms      86.462us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                        ToCopyBackward0         0.18%     751.993us         2.60%      10.854ms      37.952us       0.000us         0.00%       5.113ms      17.877us           0 b           0 b       3.14 Gb           0 b           286  \n",
            "                                            MmBackward0         0.28%       1.181ms         2.47%      10.300ms     107.289us       0.000us         0.00%       2.894ms      30.146us           0 b           0 b     535.12 Mb           0 b            96  \n",
            "                                    aten::empty_strided         2.21%       9.206ms         2.21%       9.206ms       7.868us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       6.79 Gb       6.79 Gb          1170  \n",
            "                              Optimizer.step#AdamW.step         1.17%       4.880ms         2.07%       8.625ms       4.313ms       0.000us         0.00%     202.884us     101.442us           0 b          -8 b           0 b      -2.63 Mb             2  \n",
            "                                         AddmmBackward0         0.22%     910.720us         1.94%       8.104ms      55.507us       0.000us         0.00%      12.465ms      85.374us           0 b           0 b       2.46 Gb           0 b           146  \n",
            "                     aten::scaled_dot_product_attention         0.13%     523.030us         1.64%       6.842ms     142.544us       0.000us         0.00%      10.316ms     214.916us         768 b           0 b     690.00 Mb           0 b            48  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 417.060ms\n",
            "Self CUDA time total: 85.282ms\n",
            "\n",
            "Average training loss: 1.6037\n",
            "Validation Accuracy: 0.5855\n",
            "Macro F1: 0.3497\n",
            "Weighted F1: 0.5288\n",
            "Epoch 4/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch : 100%|██████████| 5022/5022 [07:16<00:00, 11.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us     183.581ms       215.20%     183.581ms      91.791ms           0 b           0 b           0 b           0 b             2  \n",
            "                                          backward_pass         0.00%       0.000us         0.00%       0.000us       0.000us     100.158ms       117.41%     100.158ms      50.079ms           0 b           0 b           0 b           0 b             2  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us      92.209ms       108.09%      92.209ms      46.105ms           0 b           0 b           0 b           0 b             2  \n",
            "                                          ProfilerStep*         8.07%      36.371ms        84.52%     380.791ms     190.395ms       0.000us         0.00%      36.448ms      18.224ms     128.25 Kb    -128.25 Kb           0 b    -378.00 Kb             2  \n",
            "                                           forward_pass         6.15%      27.697ms        21.02%      94.691ms      47.346ms       0.000us         0.00%      36.143ms      18.071ms         768 b         384 b       4.70 Gb      -5.35 Gb             2  \n",
            "                                           aten::linear         1.15%       5.177ms        15.94%      71.821ms     147.173us       0.000us         0.00%      34.083ms      69.842us           0 b           0 b       7.13 Gb      -1.14 Gb           488  \n",
            "                                               aten::mm         2.94%      13.238ms         4.09%      18.417ms      43.029us      16.548ms        19.40%      16.548ms      38.663us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.43%       1.918ms         2.74%      12.349ms      84.585us       0.000us         0.00%      13.521ms      92.612us           0 b           0 b    -425.43 Mb      -2.88 Gb           146  \n",
            "                                            aten::copy_         1.91%       8.613ms         3.88%      17.497ms      18.936us      13.095ms        15.35%      13.095ms      14.172us           0 b           0 b           0 b           0 b           924  \n",
            "                                               aten::to         0.43%       1.934ms         7.60%      34.254ms      27.894us       0.000us         0.00%      12.978ms      10.569us           0 b           0 b       5.89 Gb           0 b          1228  \n",
            "                                         aten::_to_copy         1.60%       7.197ms         7.17%      32.320ms      35.284us       0.000us         0.00%      12.978ms      14.168us           0 b           0 b       5.89 Gb           0 b           916  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         0.67%       3.022ms         3.62%      16.322ms      57.069us       0.000us         0.00%      12.849ms      44.925us           0 b           0 b      -1.57 Gb      -4.71 Gb           286  \n",
            "                                            aten::addmm         1.81%       8.164ms         2.50%      11.248ms      76.002us      12.804ms        15.01%      12.804ms      86.513us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                         AddmmBackward0         0.22%     974.050us         1.82%       8.191ms      56.104us       0.000us         0.00%      12.466ms      85.386us           0 b           0 b       2.46 Gb           0 b           146  \n",
            "ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      12.409ms        14.55%      12.409ms      89.919us           0 b           0 b           0 b           0 b           138  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.14%     629.978us         1.02%       4.597ms     191.540us       0.000us         0.00%      10.368ms     431.989us        -384 b        -384 b    -705.00 Mb      -1.51 Gb            24  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.06%     258.751us         0.88%       3.967ms     165.291us       0.000us         0.00%      10.368ms     431.989us           0 b           0 b     840.00 Mb     -24.00 Mb            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.14%     618.005us         0.82%       3.708ms     154.510us       0.000us         0.00%      10.368ms     431.989us           0 b           0 b     864.00 Mb           0 b            24  \n",
            "                    aten::_efficient_attention_backward         0.18%     808.694us         0.57%       2.548ms     106.161us       9.948ms        11.66%      10.368ms     431.989us           0 b           0 b     864.00 Mb    -585.56 Mb            24  \n",
            "                     aten::scaled_dot_product_attention         0.12%     542.122us         1.57%       7.082ms     147.537us       0.000us         0.00%      10.313ms     214.856us         768 b           0 b     690.00 Mb           0 b            48  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 450.529ms\n",
            "Self CUDA time total: 85.309ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                    aten::empty_strided         2.12%       9.540ms         2.12%       9.540ms       8.154us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       6.79 Gb       6.79 Gb          1170  \n",
            "                                            aten::empty         1.12%       5.053ms         1.12%       5.053ms       6.030us       0.000us         0.00%       0.000us       0.000us     384.51 Kb     384.51 Kb       4.82 Gb       4.82 Gb           838  \n",
            "                                               aten::mm         2.94%      13.238ms         4.09%      18.417ms      43.029us      16.548ms        19.40%      16.548ms      38.663us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "                                            aten::addmm         1.81%       8.164ms         2.50%      11.248ms      76.002us      12.804ms        15.01%      12.804ms      86.513us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                              aten::add         0.42%       1.896ms         0.61%       2.737ms      27.926us       3.978ms         4.66%       3.978ms      40.588us           0 b           0 b       1.73 Gb       1.73 Gb            98  \n",
            "                                              aten::mul         0.55%       2.458ms         0.77%       3.458ms      34.582us       1.595ms         1.87%       1.595ms      15.951us           0 b           0 b       1.13 Gb       1.13 Gb           100  \n",
            "                                             aten::gelu         0.12%     522.929us         0.18%     788.793us      32.866us       1.952ms         2.29%       1.952ms      81.326us           0 b           0 b       1.12 Gb       1.12 Gb            24  \n",
            "                                    aten::gelu_backward         0.09%     407.077us         0.14%     631.151us      26.298us       2.829ms         3.32%       2.829ms     117.890us           0 b           0 b       1.12 Gb       1.12 Gb            24  \n",
            "                                          aten::resize_         0.01%      47.522us         0.01%      47.522us       5.940us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      97.50 Mb      97.50 Mb             8  \n",
            "                                              aten::sub         0.01%      42.432us         0.01%      64.044us      32.022us      13.249us         0.02%      13.249us       6.624us           0 b           0 b      16.00 Mb      16.00 Mb             2  \n",
            "                                           Buffer Flush         0.02%      84.660us         0.02%      84.660us      84.660us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      12.00 Mb      12.00 Mb             1  \n",
            "                                             aten::tanh         0.01%      51.797us         0.02%      73.769us      36.885us       4.928us         0.01%       4.928us       2.464us           0 b           0 b      96.00 Kb      96.00 Kb             2  \n",
            "                                    aten::tanh_backward         0.01%      34.408us         0.01%      52.972us      26.486us       4.064us         0.00%       4.064us       2.032us           0 b           0 b      96.00 Kb      96.00 Kb             2  \n",
            "                                              aten::sum         0.28%       1.272ms         0.47%       2.101ms      42.022us       1.055ms         1.24%       1.055ms      21.101us           0 b           0 b      73.00 Kb      73.00 Kb            50  \n",
            "                                               aten::eq         0.01%      65.293us         0.02%      89.047us      44.523us       5.569us         0.01%       5.569us       2.785us           0 b           0 b      16.00 Kb      16.00 Kb             2  \n",
            "                                aten::nll_loss_backward         0.01%      42.381us         0.03%     113.594us      56.797us       4.576us         0.01%       8.096us       4.048us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                     aten::_log_softmax         0.02%      76.345us         0.03%     113.092us      56.546us       4.672us         0.01%       4.672us       2.336us           0 b           0 b       5.00 Kb       5.00 Kb             2  \n",
            "                       aten::_log_softmax_backward_data         0.01%      33.898us         0.01%      51.716us      25.858us       4.897us         0.01%       4.897us       2.449us           0 b           0 b       5.00 Kb       5.00 Kb             2  \n",
            "                                 aten::nll_loss_forward         0.01%      54.611us         0.02%      74.922us      37.461us       5.024us         0.01%       5.024us       2.512us           0 b           0 b       2.00 Kb       2.00 Kb             2  \n",
            "                                              aten::all         0.01%      59.193us         0.02%      82.675us      41.337us      10.432us         0.01%      10.432us       5.216us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 450.529ms\n",
            "Self CUDA time total: 85.309ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         8.07%      36.371ms        84.52%     380.791ms     190.395ms       0.000us         0.00%      36.448ms      18.224ms     128.25 Kb    -128.25 Kb           0 b    -378.00 Kb             2  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        32.01%     144.224ms        32.73%     147.475ms      73.737ms       0.000us         0.00%       0.000us       0.000us     256.50 Kb    -384.50 Kb           0 b           0 b             2  \n",
            "                                          backward_pass        19.98%      90.001ms        22.37%     100.805ms      50.403ms       0.000us         0.00%     265.442us     132.721us        -768 b        -768 b      -4.70 Gb      -4.71 Gb             2  \n",
            "                                           forward_pass         6.15%      27.697ms        21.02%      94.691ms      47.346ms       0.000us         0.00%      36.143ms      18.071ms         768 b         384 b       4.70 Gb      -5.35 Gb             2  \n",
            "                                           aten::linear         1.15%       5.177ms        15.94%      71.821ms     147.173us       0.000us         0.00%      34.083ms      69.842us           0 b           0 b       7.13 Gb      -1.14 Gb           488  \n",
            "                                               aten::to         0.43%       1.934ms         7.60%      34.254ms      27.894us       0.000us         0.00%      12.978ms      10.569us           0 b           0 b       5.89 Gb           0 b          1228  \n",
            "                                         aten::_to_copy         1.60%       7.197ms         7.17%      32.320ms      35.284us       0.000us         0.00%      12.978ms      14.168us           0 b           0 b       5.89 Gb           0 b           916  \n",
            "                                       cudaLaunchKernel         4.60%      20.718ms         4.60%      20.718ms       9.200us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          2252  \n",
            "                                               aten::mm         2.94%      13.238ms         4.09%      18.417ms      43.029us      16.548ms        19.40%      16.548ms      38.663us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "                                            aten::copy_         1.91%       8.613ms         3.88%      17.497ms      18.936us      13.095ms        15.35%      13.095ms      14.172us           0 b           0 b           0 b           0 b           924  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         0.67%       3.022ms         3.62%      16.322ms      57.069us       0.000us         0.00%      12.849ms      44.925us           0 b           0 b      -1.57 Gb      -4.71 Gb           286  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.43%       1.918ms         2.74%      12.349ms      84.585us       0.000us         0.00%      13.521ms      92.612us           0 b           0 b    -425.43 Mb      -2.88 Gb           146  \n",
            "       autograd::engine::evaluate_function: MmBackward0         0.34%       1.532ms         2.68%      12.091ms     125.949us       0.000us         0.00%       2.899ms      30.196us           0 b           0 b    -629.95 Mb      -1.14 Gb            96  \n",
            "                                            aten::addmm         1.81%       8.164ms         2.50%      11.248ms      76.002us      12.804ms        15.01%      12.804ms      86.513us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                        ToCopyBackward0         0.17%     752.345us         2.47%      11.117ms      38.872us       0.000us         0.00%       5.114ms      17.883us           0 b           0 b       3.14 Gb           0 b           286  \n",
            "                                            MmBackward0         0.26%       1.186ms         2.34%      10.559ms     109.992us       0.000us         0.00%       2.899ms      30.196us           0 b           0 b     535.12 Mb           0 b            96  \n",
            "                                    aten::empty_strided         2.12%       9.540ms         2.12%       9.540ms       8.154us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       6.79 Gb       6.79 Gb          1170  \n",
            "                              Optimizer.step#AdamW.step         1.14%       5.130ms         2.03%       9.153ms       4.576ms       0.000us         0.00%     200.737us     100.368us           0 b          -8 b           0 b      -2.63 Mb             2  \n",
            "                                         AddmmBackward0         0.22%     974.050us         1.82%       8.191ms      56.104us       0.000us         0.00%      12.466ms      85.386us           0 b           0 b       2.46 Gb           0 b           146  \n",
            "                     aten::scaled_dot_product_attention         0.12%     542.122us         1.57%       7.082ms     147.537us       0.000us         0.00%      10.313ms     214.856us         768 b           0 b     690.00 Mb           0 b            48  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 450.529ms\n",
            "Self CUDA time total: 85.309ms\n",
            "\n",
            "Average training loss: 1.5263\n",
            "Validation Accuracy: 0.5996\n",
            "Macro F1: 0.3826\n",
            "Weighted F1: 0.5499\n",
            "Epoch 5/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch : 100%|██████████| 5022/5022 [07:17<00:00, 11.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us     163.615ms       191.81%     163.615ms      81.808ms           0 b           0 b           0 b           0 b             2  \n",
            "                                          backward_pass         0.00%       0.000us         0.00%       0.000us       0.000us      97.328ms       114.10%      97.328ms      48.664ms           0 b           0 b           0 b           0 b             2  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us      90.121ms       105.65%      90.121ms      45.060ms           0 b           0 b           0 b           0 b             2  \n",
            "                                          ProfilerStep*         1.00%       4.237ms        83.95%     356.016ms     178.008ms       0.000us         0.00%      36.442ms      18.221ms     128.25 Kb    -128.25 Kb           0 b    -378.00 Kb             2  \n",
            "                                           forward_pass         6.42%      27.222ms        21.83%      92.554ms      46.277ms       0.000us         0.00%      36.136ms      18.068ms         768 b         384 b       4.70 Gb      -5.35 Gb             2  \n",
            "                                           aten::linear         1.08%       4.597ms        16.43%      69.653ms     142.732us       0.000us         0.00%      34.058ms      69.791us           0 b           0 b       7.13 Gb      -1.14 Gb           488  \n",
            "                                               aten::mm         3.02%      12.819ms         4.21%      17.863ms      41.736us      16.540ms        19.39%      16.540ms      38.644us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.43%       1.841ms         2.80%      11.873ms      81.319us       0.000us         0.00%      13.521ms      92.613us           0 b           0 b    -425.43 Mb      -2.88 Gb           146  \n",
            "                                            aten::copy_         2.00%       8.484ms         4.04%      17.150ms      18.560us      13.081ms        15.34%      13.081ms      14.157us           0 b           0 b           0 b           0 b           924  \n",
            "                                               aten::to         0.46%       1.952ms         8.02%      33.993ms      27.682us       0.000us         0.00%      12.965ms      10.558us           0 b           0 b       5.89 Gb           0 b          1228  \n",
            "                                         aten::_to_copy         1.66%       7.052ms         7.56%      32.042ms      34.980us       0.000us         0.00%      12.965ms      14.154us           0 b           0 b       5.89 Gb           0 b           916  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         0.74%       3.128ms         3.82%      16.197ms      56.635us       0.000us         0.00%      12.855ms      44.949us           0 b           0 b      -1.57 Gb      -4.71 Gb           286  \n",
            "                                            aten::addmm         1.90%       8.040ms         2.60%      11.041ms      74.603us      12.798ms        15.00%      12.798ms      86.474us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                         AddmmBackward0         0.22%     912.586us         1.86%       7.905ms      54.144us       0.000us         0.00%      12.464ms      85.371us           0 b           0 b       2.46 Gb           0 b           146  \n",
            "ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      12.408ms        14.55%      12.408ms      89.914us           0 b           0 b           0 b           0 b           138  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.14%     593.842us         1.07%       4.522ms     188.400us       0.000us         0.00%      10.369ms     432.037us        -384 b        -384 b    -705.00 Mb      -1.51 Gb            24  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.06%     243.858us         0.93%       3.928ms     163.657us       0.000us         0.00%      10.369ms     432.037us           0 b           0 b     840.00 Mb     -24.00 Mb            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.14%     603.157us         0.87%       3.684ms     153.496us       0.000us         0.00%      10.369ms     432.037us           0 b           0 b     864.00 Mb           0 b            24  \n",
            "                    aten::_efficient_attention_backward         0.19%     825.595us         0.61%       2.581ms     107.532us       9.947ms        11.66%      10.369ms     432.037us           0 b           0 b     864.00 Mb    -585.56 Mb            24  \n",
            "                     aten::scaled_dot_product_attention         0.12%     497.748us         1.64%       6.954ms     144.868us       0.000us         0.00%      10.320ms     215.004us         768 b           0 b     690.00 Mb           0 b            48  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 424.058ms\n",
            "Self CUDA time total: 85.303ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                    aten::empty_strided         2.30%       9.735ms         2.30%       9.735ms       8.320us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       6.79 Gb       6.79 Gb          1170  \n",
            "                                            aten::empty         1.17%       4.966ms         1.17%       4.966ms       5.926us       0.000us         0.00%       0.000us       0.000us     384.51 Kb     384.51 Kb       4.82 Gb       4.82 Gb           838  \n",
            "                                               aten::mm         3.02%      12.819ms         4.21%      17.863ms      41.736us      16.540ms        19.39%      16.540ms      38.644us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "                                            aten::addmm         1.90%       8.040ms         2.60%      11.041ms      74.603us      12.798ms        15.00%      12.798ms      86.474us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                              aten::add         0.44%       1.858ms         0.63%       2.672ms      27.263us       3.985ms         4.67%       3.985ms      40.665us           0 b           0 b       1.73 Gb       1.73 Gb            98  \n",
            "                                              aten::mul         0.54%       2.284ms         0.77%       3.270ms      32.696us       1.595ms         1.87%       1.595ms      15.949us           0 b           0 b       1.13 Gb       1.13 Gb           100  \n",
            "                                             aten::gelu         0.12%     512.924us         0.18%     755.733us      31.489us       1.951ms         2.29%       1.951ms      81.273us           0 b           0 b       1.12 Gb       1.12 Gb            24  \n",
            "                                    aten::gelu_backward         0.09%     385.625us         0.15%     628.985us      26.208us       2.830ms         3.32%       2.830ms     117.914us           0 b           0 b       1.12 Gb       1.12 Gb            24  \n",
            "                                          aten::resize_         0.01%      47.947us         0.01%      47.947us       5.993us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      97.50 Mb      97.50 Mb             8  \n",
            "                                              aten::sub         0.01%      42.246us         0.01%      63.154us      31.577us      13.184us         0.02%      13.184us       6.592us           0 b           0 b      16.00 Mb      16.00 Mb             2  \n",
            "                                           Buffer Flush         0.02%      80.554us         0.02%      80.554us      80.554us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      12.00 Mb      12.00 Mb             1  \n",
            "                                             aten::tanh         0.01%      53.159us         0.02%      75.623us      37.811us       4.960us         0.01%       4.960us       2.480us           0 b           0 b      96.00 Kb      96.00 Kb             2  \n",
            "                                    aten::tanh_backward         0.01%      35.346us         0.01%      57.284us      28.642us       4.096us         0.00%       4.096us       2.048us           0 b           0 b      96.00 Kb      96.00 Kb             2  \n",
            "                                              aten::sum         0.29%       1.236ms         0.47%       2.001ms      40.019us       1.057ms         1.24%       1.057ms      21.146us           0 b           0 b      73.00 Kb      73.00 Kb            50  \n",
            "                                               aten::eq         0.02%      69.324us         0.02%      95.051us      47.526us       5.632us         0.01%       5.632us       2.816us           0 b           0 b      16.00 Kb      16.00 Kb             2  \n",
            "                                aten::nll_loss_backward         0.01%      38.455us         0.02%     102.928us      51.464us       4.480us         0.01%       7.967us       3.984us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                     aten::_log_softmax         0.02%      76.581us         0.03%     110.319us      55.160us       4.673us         0.01%       4.673us       2.336us           0 b           0 b       5.00 Kb       5.00 Kb             2  \n",
            "                       aten::_log_softmax_backward_data         0.01%      33.507us         0.02%      81.107us      40.553us       4.768us         0.01%       4.768us       2.384us           0 b           0 b       5.00 Kb       5.00 Kb             2  \n",
            "                                 aten::nll_loss_forward         0.01%      51.708us         0.02%      70.616us      35.308us       4.896us         0.01%       4.896us       2.448us           0 b           0 b       2.00 Kb       2.00 Kb             2  \n",
            "                                              aten::all         0.01%      60.674us         0.02%      84.694us      42.347us      10.560us         0.01%      10.560us       5.280us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 424.058ms\n",
            "Self CUDA time total: 85.303ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         1.00%       4.237ms        83.95%     356.016ms     178.008ms       0.000us         0.00%      36.442ms      18.221ms     128.25 Kb    -128.25 Kb           0 b    -378.00 Kb             2  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        36.94%     156.667ms        37.72%     159.943ms      79.972ms       0.000us         0.00%       0.000us       0.000us     256.50 Kb    -384.50 Kb           0 b           0 b             2  \n",
            "                                          backward_pass        20.64%      87.524ms        23.06%      97.773ms      48.886ms       0.000us         0.00%     267.332us     133.666us        -768 b        -768 b      -4.70 Gb      -4.71 Gb             2  \n",
            "                                           forward_pass         6.42%      27.222ms        21.83%      92.554ms      46.277ms       0.000us         0.00%      36.136ms      18.068ms         768 b         384 b       4.70 Gb      -5.35 Gb             2  \n",
            "                                           aten::linear         1.08%       4.597ms        16.43%      69.653ms     142.732us       0.000us         0.00%      34.058ms      69.791us           0 b           0 b       7.13 Gb      -1.14 Gb           488  \n",
            "                                               aten::to         0.46%       1.952ms         8.02%      33.993ms      27.682us       0.000us         0.00%      12.965ms      10.558us           0 b           0 b       5.89 Gb           0 b          1228  \n",
            "                                         aten::_to_copy         1.66%       7.052ms         7.56%      32.042ms      34.980us       0.000us         0.00%      12.965ms      14.154us           0 b           0 b       5.89 Gb           0 b           916  \n",
            "                                       cudaLaunchKernel         4.80%      20.352ms         4.80%      20.352ms       9.037us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          2252  \n",
            "                                               aten::mm         3.02%      12.819ms         4.21%      17.863ms      41.736us      16.540ms        19.39%      16.540ms      38.644us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "                                            aten::copy_         2.00%       8.484ms         4.04%      17.150ms      18.560us      13.081ms        15.34%      13.081ms      14.157us           0 b           0 b           0 b           0 b           924  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         0.74%       3.128ms         3.82%      16.197ms      56.635us       0.000us         0.00%      12.855ms      44.949us           0 b           0 b      -1.57 Gb      -4.71 Gb           286  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.43%       1.841ms         2.80%      11.873ms      81.319us       0.000us         0.00%      13.521ms      92.613us           0 b           0 b    -425.43 Mb      -2.88 Gb           146  \n",
            "       autograd::engine::evaluate_function: MmBackward0         0.36%       1.506ms         2.74%      11.629ms     121.139us       0.000us         0.00%       2.894ms      30.146us           0 b           0 b    -629.95 Mb      -1.14 Gb            96  \n",
            "                                            aten::addmm         1.90%       8.040ms         2.60%      11.041ms      74.603us      12.798ms        15.00%      12.798ms      86.474us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                        ToCopyBackward0         0.18%     756.674us         2.57%      10.892ms      38.084us       0.000us         0.00%       5.113ms      17.877us           0 b           0 b       3.14 Gb           0 b           286  \n",
            "                                            MmBackward0         0.27%       1.162ms         2.39%      10.124ms     105.455us       0.000us         0.00%       2.894ms      30.146us           0 b           0 b     535.12 Mb           0 b            96  \n",
            "                                    aten::empty_strided         2.30%       9.735ms         2.30%       9.735ms       8.320us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       6.79 Gb       6.79 Gb          1170  \n",
            "                              Optimizer.step#AdamW.step         1.14%       4.842ms         2.04%       8.653ms       4.327ms       0.000us         0.00%     202.050us     101.025us           0 b          -8 b           0 b      -2.63 Mb             2  \n",
            "                                         AddmmBackward0         0.22%     912.586us         1.86%       7.905ms      54.144us       0.000us         0.00%      12.464ms      85.371us           0 b           0 b       2.46 Gb           0 b           146  \n",
            "                     aten::scaled_dot_product_attention         0.12%     497.748us         1.64%       6.954ms     144.868us       0.000us         0.00%      10.320ms     215.004us         768 b           0 b     690.00 Mb           0 b            48  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 424.058ms\n",
            "Self CUDA time total: 85.303ms\n",
            "\n",
            "Average training loss: 1.4789\n",
            "Validation Accuracy: 0.6083\n",
            "Macro F1: 0.4055\n",
            "Weighted F1: 0.5635\n",
            "Epoch 6/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch : 100%|██████████| 5022/5022 [07:17<00:00, 11.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us     154.060ms       180.57%     154.060ms      77.030ms           0 b           0 b           0 b           0 b             2  \n",
            "                                          backward_pass         0.00%       0.000us         0.00%       0.000us       0.000us      99.932ms       117.13%      99.932ms      49.966ms           0 b           0 b           0 b           0 b             2  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us      91.906ms       107.72%      91.906ms      45.953ms           0 b           0 b           0 b           0 b             2  \n",
            "                                          ProfilerStep*         0.90%       3.802ms        83.24%     350.819ms     175.409ms       0.000us         0.00%      36.450ms      18.225ms     128.25 Kb    -128.25 Kb           0 b    -378.00 Kb             2  \n",
            "                                           forward_pass         6.53%      27.501ms        22.42%      94.479ms      47.240ms       0.000us         0.00%      36.146ms      18.073ms         768 b         384 b       4.70 Gb      -5.36 Gb             2  \n",
            "                                           aten::linear         1.10%       4.657ms        16.93%      71.352ms     146.214us       0.000us         0.00%      34.076ms      69.827us           0 b           0 b       7.14 Gb      -1.13 Gb           488  \n",
            "                                               aten::mm         3.19%      13.428ms         4.40%      18.565ms      43.376us      16.544ms        19.39%      16.544ms      38.655us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.47%       1.965ms         2.99%      12.605ms      86.333us       0.000us         0.00%      13.521ms      92.608us           0 b           0 b    -425.43 Mb      -2.88 Gb           146  \n",
            "                                            aten::copy_         2.04%       8.601ms         4.15%      17.489ms      18.928us      13.099ms        15.35%      13.099ms      14.176us           0 b           0 b           0 b           0 b           924  \n",
            "                                               aten::to         0.45%       1.899ms         8.14%      34.292ms      27.925us       0.000us         0.00%      12.982ms      10.571us           0 b           0 b       5.89 Gb           0 b          1228  \n",
            "                                         aten::_to_copy         1.70%       7.170ms         7.69%      32.393ms      35.363us       0.000us         0.00%      12.982ms      14.172us           0 b           0 b       5.89 Gb           0 b           916  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         0.75%       3.151ms         3.93%      16.544ms      57.848us       0.000us         0.00%      12.864ms      44.978us           0 b           0 b      -1.57 Gb      -4.71 Gb           286  \n",
            "                                            aten::addmm         1.96%       8.254ms         2.69%      11.357ms      76.735us      12.802ms        15.00%      12.802ms      86.497us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                         AddmmBackward0         0.24%     992.516us         1.98%       8.348ms      57.181us       0.000us         0.00%      12.466ms      85.386us           0 b           0 b       2.46 Gb           0 b           146  \n",
            "ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      12.410ms        14.55%      12.410ms      89.929us           0 b           0 b           0 b           0 b           138  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.15%     642.932us         1.10%       4.631ms     192.951us       0.000us         0.00%      10.372ms     432.186us        -384 b        -384 b    -705.00 Mb      -1.51 Gb            24  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.06%     273.167us         0.95%       3.988ms     166.162us       0.000us         0.00%      10.372ms     432.186us           0 b           0 b     840.00 Mb     -24.00 Mb            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.15%     631.983us         0.88%       3.715ms     154.780us       0.000us         0.00%      10.372ms     432.186us           0 b           0 b     864.00 Mb           0 b            24  \n",
            "                    aten::_efficient_attention_backward         0.20%     825.607us         0.61%       2.563ms     106.805us       9.951ms        11.66%      10.372ms     432.186us           0 b           0 b     864.00 Mb    -585.56 Mb            24  \n",
            "                     aten::scaled_dot_product_attention         0.12%     518.569us         1.72%       7.254ms     151.120us       0.000us         0.00%      10.316ms     214.909us         768 b           0 b     690.00 Mb           0 b            48  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 421.469ms\n",
            "Self CUDA time total: 85.318ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                    aten::empty_strided         2.30%       9.686ms         2.30%       9.686ms       8.279us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       6.79 Gb       6.79 Gb          1170  \n",
            "                                            aten::empty         1.21%       5.087ms         1.21%       5.087ms       6.070us       0.000us         0.00%       0.000us       0.000us     384.51 Kb     384.51 Kb       4.82 Gb       4.82 Gb           838  \n",
            "                                               aten::mm         3.19%      13.428ms         4.40%      18.565ms      43.376us      16.544ms        19.39%      16.544ms      38.655us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "                                            aten::addmm         1.96%       8.254ms         2.69%      11.357ms      76.735us      12.802ms        15.00%      12.802ms      86.497us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                              aten::add         0.46%       1.922ms         0.66%       2.771ms      28.278us       3.979ms         4.66%       3.979ms      40.597us           0 b           0 b       1.73 Gb       1.73 Gb            98  \n",
            "                                              aten::mul         0.58%       2.443ms         0.82%       3.458ms      34.584us       1.594ms         1.87%       1.594ms      15.944us           0 b           0 b       1.13 Gb       1.13 Gb           100  \n",
            "                                             aten::gelu         0.13%     553.611us         0.19%     796.857us      33.202us       1.952ms         2.29%       1.952ms      81.327us           0 b           0 b       1.12 Gb       1.12 Gb            24  \n",
            "                                    aten::gelu_backward         0.10%     425.580us         0.16%     655.099us      27.296us       2.829ms         3.32%       2.829ms     117.877us           0 b           0 b       1.12 Gb       1.12 Gb            24  \n",
            "                                          aten::resize_         0.01%      47.171us         0.01%      47.171us       5.896us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      97.50 Mb      97.50 Mb             8  \n",
            "                                           Buffer Flush         0.02%      99.804us         0.02%      99.804us      99.804us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      48.00 Mb      48.00 Mb             1  \n",
            "                                              aten::sub         0.01%      43.591us         0.02%      79.858us      39.929us      12.993us         0.02%      12.993us       6.496us           0 b           0 b      16.00 Mb      16.00 Mb             2  \n",
            "                                             aten::tanh         0.01%      52.704us         0.02%      73.334us      36.667us       4.928us         0.01%       4.928us       2.464us           0 b           0 b      96.00 Kb      96.00 Kb             2  \n",
            "                                    aten::tanh_backward         0.01%      33.815us         0.01%      53.037us      26.519us       4.064us         0.00%       4.064us       2.032us           0 b           0 b      96.00 Kb      96.00 Kb             2  \n",
            "                                              aten::sum         0.31%       1.297ms         0.51%       2.161ms      43.218us       1.054ms         1.24%       1.054ms      21.089us           0 b           0 b      73.00 Kb      73.00 Kb            50  \n",
            "                                               aten::eq         0.02%      64.069us         0.02%      86.549us      43.274us       5.376us         0.01%       5.376us       2.688us           0 b           0 b      16.00 Kb      16.00 Kb             2  \n",
            "                                aten::nll_loss_backward         0.01%      40.631us         0.03%     108.531us      54.266us       4.544us         0.01%       8.128us       4.064us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                     aten::_log_softmax         0.02%      73.174us         0.03%     109.512us      54.756us       4.768us         0.01%       4.768us       2.384us           0 b           0 b       5.00 Kb       5.00 Kb             2  \n",
            "                       aten::_log_softmax_backward_data         0.01%      33.884us         0.01%      52.622us      26.311us       4.736us         0.01%       4.736us       2.368us           0 b           0 b       5.00 Kb       5.00 Kb             2  \n",
            "                                 aten::nll_loss_forward         0.01%      53.951us         0.02%      80.557us      40.279us       5.024us         0.01%       5.024us       2.512us           0 b           0 b       2.00 Kb       2.00 Kb             2  \n",
            "                                              aten::all         0.01%      58.654us         0.02%      83.403us      41.701us      10.656us         0.01%      10.656us       5.328us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 421.469ms\n",
            "Self CUDA time total: 85.318ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.90%       3.802ms        83.24%     350.819ms     175.409ms       0.000us         0.00%      36.450ms      18.225ms     128.25 Kb    -128.25 Kb           0 b    -378.00 Kb             2  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        34.96%     147.354ms        35.72%     150.564ms      75.282ms       0.000us         0.00%       0.000us       0.000us     256.50 Kb    -384.50 Kb           0 b           0 b             2  \n",
            "                                          backward_pass        21.30%      89.782ms        23.85%     100.530ms      50.265ms       0.000us         0.00%     264.771us     132.386us        -768 b        -768 b      -4.70 Gb      -4.74 Gb             2  \n",
            "                                           forward_pass         6.53%      27.501ms        22.42%      94.479ms      47.240ms       0.000us         0.00%      36.146ms      18.073ms         768 b         384 b       4.70 Gb      -5.36 Gb             2  \n",
            "                                           aten::linear         1.10%       4.657ms        16.93%      71.352ms     146.214us       0.000us         0.00%      34.076ms      69.827us           0 b           0 b       7.14 Gb      -1.13 Gb           488  \n",
            "                                               aten::to         0.45%       1.899ms         8.14%      34.292ms      27.925us       0.000us         0.00%      12.982ms      10.571us           0 b           0 b       5.89 Gb           0 b          1228  \n",
            "                                         aten::_to_copy         1.70%       7.170ms         7.69%      32.393ms      35.363us       0.000us         0.00%      12.982ms      14.172us           0 b           0 b       5.89 Gb           0 b           916  \n",
            "                                       cudaLaunchKernel         4.93%      20.765ms         4.93%      20.765ms       9.221us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          2252  \n",
            "                                               aten::mm         3.19%      13.428ms         4.40%      18.565ms      43.376us      16.544ms        19.39%      16.544ms      38.655us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "                                            aten::copy_         2.04%       8.601ms         4.15%      17.489ms      18.928us      13.099ms        15.35%      13.099ms      14.176us           0 b           0 b           0 b           0 b           924  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         0.75%       3.151ms         3.93%      16.544ms      57.848us       0.000us         0.00%      12.864ms      44.978us           0 b           0 b      -1.57 Gb      -4.71 Gb           286  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.47%       1.965ms         2.99%      12.605ms      86.333us       0.000us         0.00%      13.521ms      92.608us           0 b           0 b    -425.43 Mb      -2.88 Gb           146  \n",
            "       autograd::engine::evaluate_function: MmBackward0         0.43%       1.796ms         2.92%      12.307ms     128.203us       0.000us         0.00%       2.894ms      30.144us           0 b           0 b    -629.95 Mb      -1.14 Gb            96  \n",
            "                                            aten::addmm         1.96%       8.254ms         2.69%      11.357ms      76.735us      12.802ms        15.00%      12.802ms      86.497us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                        ToCopyBackward0         0.19%     800.191us         2.65%      11.154ms      39.000us       0.000us         0.00%       5.124ms      17.917us           0 b           0 b       3.14 Gb           0 b           286  \n",
            "                                            MmBackward0         0.28%       1.191ms         2.49%      10.511ms     109.490us       0.000us         0.00%       2.894ms      30.144us           0 b           0 b     535.12 Mb           0 b            96  \n",
            "                                    aten::empty_strided         2.30%       9.686ms         2.30%       9.686ms       8.279us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       6.79 Gb       6.79 Gb          1170  \n",
            "                              Optimizer.step#AdamW.step         1.22%       5.129ms         2.15%       9.064ms       4.532ms       0.000us         0.00%     200.323us     100.162us           0 b          -8 b           0 b      -2.63 Mb             2  \n",
            "                                         AddmmBackward0         0.24%     992.516us         1.98%       8.348ms      57.181us       0.000us         0.00%      12.466ms      85.386us           0 b           0 b       2.46 Gb           0 b           146  \n",
            "                     aten::scaled_dot_product_attention         0.12%     518.569us         1.72%       7.254ms     151.120us       0.000us         0.00%      10.316ms     214.909us         768 b           0 b     690.00 Mb           0 b            48  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 421.469ms\n",
            "Self CUDA time total: 85.318ms\n",
            "\n",
            "Average training loss: 1.4470\n",
            "Validation Accuracy: 0.6136\n",
            "Macro F1: 0.4180\n",
            "Weighted F1: 0.5728\n",
            "Epoch 7/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch : 100%|██████████| 5022/5022 [07:18<00:00, 11.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us     150.885ms       176.92%     150.885ms      75.443ms           0 b           0 b           0 b           0 b             2  \n",
            "                                          backward_pass         0.00%       0.000us         0.00%       0.000us       0.000us      99.904ms       117.14%      99.904ms      49.952ms           0 b           0 b           0 b           0 b             2  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us      89.858ms       105.36%      89.858ms      44.929ms           0 b           0 b           0 b           0 b             2  \n",
            "                                          ProfilerStep*         0.87%       3.631ms        83.05%     345.493ms     172.746ms       0.000us         0.00%      36.439ms      18.220ms     128.25 Kb    -128.25 Kb       1.31 Mb    -378.00 Kb             2  \n",
            "                                           forward_pass         6.48%      26.949ms        22.24%      92.519ms      46.259ms       0.000us         0.00%      36.131ms      18.065ms         768 b         384 b       4.70 Gb      -5.35 Gb             2  \n",
            "                                           aten::linear         1.12%       4.643ms        16.83%      70.000ms     143.443us       0.000us         0.00%      34.066ms      69.807us           0 b           0 b       7.13 Gb      -1.14 Gb           488  \n",
            "                                               aten::mm         3.21%      13.358ms         4.47%      18.577ms      43.405us      16.541ms        19.39%      16.541ms      38.647us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.47%       1.960ms         3.02%      12.563ms      86.049us       0.000us         0.00%      13.522ms      92.618us           0 b           0 b    -425.43 Mb      -2.88 Gb           146  \n",
            "                                            aten::copy_         2.03%       8.440ms         4.13%      17.181ms      18.594us      13.089ms        15.35%      13.089ms      14.166us           0 b           0 b           0 b           0 b           924  \n",
            "                                               aten::to         0.48%       1.986ms         8.23%      34.236ms      27.880us       0.000us         0.00%      12.972ms      10.564us           0 b           0 b       5.89 Gb           0 b          1228  \n",
            "                                         aten::_to_copy         1.71%       7.117ms         7.75%      32.250ms      35.207us       0.000us         0.00%      12.972ms      14.162us           0 b           0 b       5.89 Gb           0 b           916  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         0.76%       3.146ms         4.00%      16.643ms      58.191us       0.000us         0.00%      12.848ms      44.923us           0 b           0 b      -1.57 Gb      -4.71 Gb           286  \n",
            "                                            aten::addmm         1.93%       8.029ms         2.67%      11.115ms      75.099us      12.799ms        15.01%      12.799ms      86.483us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                         AddmmBackward0         0.23%     959.175us         2.00%       8.326ms      57.025us       0.000us         0.00%      12.467ms      85.392us           0 b           0 b       2.46 Gb           0 b           146  \n",
            "ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      12.410ms        14.55%      12.410ms      89.926us           0 b           0 b           0 b           0 b           138  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.15%     624.168us         1.12%       4.656ms     194.009us       0.000us         0.00%      10.362ms     431.765us        -384 b        -384 b    -705.00 Mb      -1.51 Gb            24  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.06%     256.954us         0.97%       4.032ms     168.002us       0.000us         0.00%      10.362ms     431.765us           0 b           0 b     840.00 Mb     -24.00 Mb            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.16%     663.996us         0.91%       3.775ms     157.295us       0.000us         0.00%      10.362ms     431.765us           0 b           0 b     864.00 Mb           0 b            24  \n",
            "                    aten::_efficient_attention_backward         0.20%     811.661us         0.62%       2.572ms     107.184us       9.940ms        11.66%      10.362ms     431.765us           0 b           0 b     864.00 Mb    -585.56 Mb            24  \n",
            "                     aten::scaled_dot_product_attention         0.12%     503.460us         1.68%       6.973ms     145.266us       0.000us         0.00%      10.316ms     214.914us         768 b           0 b     690.00 Mb           0 b            48  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 416.022ms\n",
            "Self CUDA time total: 85.285ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                    aten::empty_strided         2.38%       9.898ms         2.38%       9.898ms       8.460us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       6.79 Gb       6.79 Gb          1170  \n",
            "                                            aten::empty         1.23%       5.108ms         1.23%       5.108ms       6.095us       0.000us         0.00%       0.000us       0.000us     384.51 Kb     384.51 Kb       4.82 Gb       4.82 Gb           838  \n",
            "                                               aten::mm         3.21%      13.358ms         4.47%      18.577ms      43.405us      16.541ms        19.39%      16.541ms      38.647us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "                                            aten::addmm         1.93%       8.029ms         2.67%      11.115ms      75.099us      12.799ms        15.01%      12.799ms      86.483us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                              aten::add         0.45%       1.875ms         0.65%       2.689ms      27.439us       3.977ms         4.66%       3.977ms      40.584us           0 b           0 b       1.73 Gb       1.73 Gb            98  \n",
            "                                              aten::mul         0.55%       2.268ms         0.78%       3.262ms      32.623us       1.592ms         1.87%       1.592ms      15.916us           0 b           0 b       1.13 Gb       1.13 Gb           100  \n",
            "                                             aten::gelu         0.12%     513.313us         0.18%     755.822us      31.493us       1.952ms         2.29%       1.952ms      81.322us           0 b           0 b       1.12 Gb       1.12 Gb            24  \n",
            "                                    aten::gelu_backward         0.10%     422.149us         0.16%     662.150us      27.590us       2.829ms         3.32%       2.829ms     117.856us           0 b           0 b       1.12 Gb       1.12 Gb            24  \n",
            "                                          aten::resize_         0.01%      47.577us         0.01%      47.577us       5.947us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      97.50 Mb      97.50 Mb             8  \n",
            "                                              aten::sub         0.01%      44.608us         0.02%      65.814us      32.907us      13.216us         0.02%      13.216us       6.608us           0 b           0 b      16.00 Mb      16.00 Mb             2  \n",
            "                                           Buffer Flush         0.02%      64.727us         0.02%      64.727us      64.727us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      12.00 Mb      12.00 Mb             1  \n",
            "                                             aten::tanh         0.01%      50.816us         0.02%      70.208us      35.104us       4.960us         0.01%       4.960us       2.480us           0 b           0 b      96.00 Kb      96.00 Kb             2  \n",
            "                                    aten::tanh_backward         0.01%      35.540us         0.01%      53.687us      26.844us       4.063us         0.00%       4.063us       2.031us           0 b           0 b      96.00 Kb      96.00 Kb             2  \n",
            "                                              aten::sum         0.32%       1.330ms         0.51%       2.139ms      42.771us       1.055ms         1.24%       1.055ms      21.099us           0 b           0 b      73.00 Kb      73.00 Kb            50  \n",
            "                                               aten::eq         0.02%      69.444us         0.02%      97.394us      48.697us       5.696us         0.01%       5.696us       2.848us           0 b           0 b      16.00 Kb      16.00 Kb             2  \n",
            "                                aten::nll_loss_backward         0.01%      41.432us         0.03%     111.517us      55.759us       4.480us         0.01%       7.936us       3.968us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                     aten::_log_softmax         0.02%      66.902us         0.02%      99.163us      49.582us       4.672us         0.01%       4.672us       2.336us           0 b           0 b       5.00 Kb       5.00 Kb             2  \n",
            "                       aten::_log_softmax_backward_data         0.01%      33.291us         0.01%      52.008us      26.004us       4.801us         0.01%       4.801us       2.400us           0 b           0 b       5.00 Kb       5.00 Kb             2  \n",
            "                                 aten::nll_loss_forward         0.01%      52.362us         0.02%      70.794us      35.397us       4.929us         0.01%       4.929us       2.465us           0 b           0 b       2.00 Kb       2.00 Kb             2  \n",
            "                                              aten::all         0.01%      60.918us         0.02%      84.648us      42.324us      10.463us         0.01%      10.463us       5.232us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 416.022ms\n",
            "Self CUDA time total: 85.285ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.87%       3.631ms        83.05%     345.493ms     172.746ms       0.000us         0.00%      36.439ms      18.220ms     128.25 Kb    -128.25 Kb       1.31 Mb    -378.00 Kb             2  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        34.63%     144.066ms        35.44%     147.443ms      73.722ms       0.000us         0.00%       0.000us       0.000us     256.50 Kb    -384.50 Kb           0 b           0 b             2  \n",
            "                                          backward_pass        21.54%      89.613ms        24.13%     100.367ms      50.183ms       0.000us         0.00%     268.992us     134.496us        -768 b        -768 b      -4.70 Gb      -4.71 Gb             2  \n",
            "                                           forward_pass         6.48%      26.949ms        22.24%      92.519ms      46.259ms       0.000us         0.00%      36.131ms      18.065ms         768 b         384 b       4.70 Gb      -5.35 Gb             2  \n",
            "                                           aten::linear         1.12%       4.643ms        16.83%      70.000ms     143.443us       0.000us         0.00%      34.066ms      69.807us           0 b           0 b       7.13 Gb      -1.14 Gb           488  \n",
            "                                               aten::to         0.48%       1.986ms         8.23%      34.236ms      27.880us       0.000us         0.00%      12.972ms      10.564us           0 b           0 b       5.89 Gb           0 b          1228  \n",
            "                                         aten::_to_copy         1.71%       7.117ms         7.75%      32.250ms      35.207us       0.000us         0.00%      12.972ms      14.162us           0 b           0 b       5.89 Gb           0 b           916  \n",
            "                                       cudaLaunchKernel         4.95%      20.582ms         4.95%      20.582ms       9.140us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          2252  \n",
            "                                               aten::mm         3.21%      13.358ms         4.47%      18.577ms      43.405us      16.541ms        19.39%      16.541ms      38.647us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "                                            aten::copy_         2.03%       8.440ms         4.13%      17.181ms      18.594us      13.089ms        15.35%      13.089ms      14.166us           0 b           0 b           0 b           0 b           924  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         0.76%       3.146ms         4.00%      16.643ms      58.191us       0.000us         0.00%      12.848ms      44.923us           0 b           0 b      -1.57 Gb      -4.71 Gb           286  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.47%       1.960ms         3.02%      12.563ms      86.049us       0.000us         0.00%      13.522ms      92.618us           0 b           0 b    -425.43 Mb      -2.88 Gb           146  \n",
            "       autograd::engine::evaluate_function: MmBackward0         0.37%       1.544ms         2.94%      12.234ms     127.441us       0.000us         0.00%       2.893ms      30.133us           0 b           0 b    -629.95 Mb      -1.14 Gb            96  \n",
            "                                        ToCopyBackward0         0.19%     770.351us         2.70%      11.243ms      39.311us       0.000us         0.00%       5.112ms      17.874us           0 b           0 b       3.14 Gb           0 b           286  \n",
            "                                            aten::addmm         1.93%       8.029ms         2.67%      11.115ms      75.099us      12.799ms        15.01%      12.799ms      86.483us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                            MmBackward0         0.29%       1.204ms         2.57%      10.690ms     111.358us       0.000us         0.00%       2.893ms      30.133us           0 b           0 b     535.12 Mb           0 b            96  \n",
            "                                    aten::empty_strided         2.38%       9.898ms         2.38%       9.898ms       8.460us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       6.79 Gb       6.79 Gb          1170  \n",
            "                              Optimizer.step#AdamW.step         1.25%       5.207ms         2.20%       9.145ms       4.573ms       0.000us         0.00%     204.384us     102.192us           0 b          -8 b       1.31 Mb      -1.31 Mb             2  \n",
            "                                         AddmmBackward0         0.23%     959.175us         2.00%       8.326ms      57.025us       0.000us         0.00%      12.467ms      85.392us           0 b           0 b       2.46 Gb           0 b           146  \n",
            "                     aten::scaled_dot_product_attention         0.12%     503.460us         1.68%       6.973ms     145.266us       0.000us         0.00%      10.316ms     214.914us         768 b           0 b     690.00 Mb           0 b            48  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 416.022ms\n",
            "Self CUDA time total: 85.285ms\n",
            "\n",
            "Average training loss: 1.4286\n",
            "Validation Accuracy: 0.6159\n",
            "Macro F1: 0.4237\n",
            "Weighted F1: 0.5768\n",
            "Epoch 8/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch : 100%|██████████| 5022/5022 [07:19<00:00, 11.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us     150.009ms       175.88%     150.009ms      75.004ms           0 b           0 b           0 b           0 b             2  \n",
            "                                          backward_pass         0.00%       0.000us         0.00%       0.000us       0.000us      98.840ms       115.88%      98.840ms      49.420ms           0 b           0 b           0 b           0 b             2  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us      91.404ms       107.16%      91.404ms      45.702ms           0 b           0 b           0 b           0 b             2  \n",
            "                                          ProfilerStep*         0.93%       3.851ms        83.32%     345.212ms     172.606ms       0.000us         0.00%      36.434ms      18.217ms     128.25 Kb    -128.25 Kb           0 b    -378.00 Kb             2  \n",
            "                                           forward_pass         6.66%      27.603ms        22.70%      94.065ms      47.033ms       0.000us         0.00%      36.126ms      18.063ms         768 b         384 b       4.70 Gb      -5.36 Gb             2  \n",
            "                                           aten::linear         1.13%       4.693ms        17.11%      70.876ms     145.238us       0.000us         0.00%      34.070ms      69.817us           0 b           0 b       7.14 Gb      -1.13 Gb           488  \n",
            "                                               aten::mm         3.19%      13.196ms         4.42%      18.301ms      42.760us      16.544ms        19.40%      16.544ms      38.653us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.45%       1.879ms         2.98%      12.327ms      84.429us       0.000us         0.00%      13.516ms      92.574us           0 b           0 b    -425.43 Mb      -2.88 Gb           146  \n",
            "                                            aten::copy_         2.03%       8.410ms         4.14%      17.157ms      18.569us      13.101ms        15.36%      13.101ms      14.179us           0 b           0 b           0 b           0 b           924  \n",
            "                                               aten::to         0.46%       1.920ms         8.14%      33.723ms      27.462us       0.000us         0.00%      12.985ms      10.575us           0 b           0 b       5.89 Gb           0 b          1228  \n",
            "                                         aten::_to_copy         1.71%       7.072ms         7.68%      31.803ms      34.719us       0.000us         0.00%      12.985ms      14.176us           0 b           0 b       5.89 Gb           0 b           916  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         0.71%       2.949ms         3.82%      15.846ms      55.405us       0.000us         0.00%      12.861ms      44.967us           0 b           0 b      -1.57 Gb      -4.71 Gb           286  \n",
            "                                            aten::addmm         1.98%       8.216ms         2.73%      11.299ms      76.342us      12.800ms        15.01%      12.800ms      86.487us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                         AddmmBackward0         0.23%     967.749us         1.98%       8.187ms      56.078us       0.000us         0.00%      12.464ms      85.369us           0 b           0 b       2.46 Gb           0 b           146  \n",
            "ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      12.408ms        14.55%      12.408ms      89.911us           0 b           0 b           0 b           0 b           138  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.15%     616.689us         1.11%       4.583ms     190.946us       0.000us         0.00%      10.358ms     431.585us        -384 b        -384 b    -705.00 Mb      -1.51 Gb            24  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.06%     256.230us         0.96%       3.966ms     165.250us       0.000us         0.00%      10.358ms     431.585us           0 b           0 b     840.00 Mb     -24.00 Mb            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.15%     635.245us         0.90%       3.710ms     154.574us       0.000us         0.00%      10.358ms     431.585us           0 b           0 b     864.00 Mb           0 b            24  \n",
            "                    aten::_efficient_attention_backward         0.19%     801.450us         0.61%       2.534ms     105.581us       9.937ms        11.65%      10.358ms     431.585us           0 b           0 b     864.00 Mb    -585.56 Mb            24  \n",
            "                     aten::scaled_dot_product_attention         0.13%     523.075us         1.72%       7.137ms     148.680us       0.000us         0.00%      10.311ms     214.813us         768 b           0 b     690.00 Mb           0 b            48  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 414.317ms\n",
            "Self CUDA time total: 85.293ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                    aten::empty_strided         2.30%       9.545ms         2.30%       9.545ms       8.158us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       6.79 Gb       6.79 Gb          1170  \n",
            "                                            aten::empty         1.24%       5.122ms         1.24%       5.122ms       6.112us       0.000us         0.00%       0.000us       0.000us     384.51 Kb     384.51 Kb       4.82 Gb       4.82 Gb           838  \n",
            "                                               aten::mm         3.19%      13.196ms         4.42%      18.301ms      42.760us      16.544ms        19.40%      16.544ms      38.653us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "                                            aten::addmm         1.98%       8.216ms         2.73%      11.299ms      76.342us      12.800ms        15.01%      12.800ms      86.487us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                              aten::add         0.46%       1.918ms         0.66%       2.753ms      28.096us       3.977ms         4.66%       3.977ms      40.582us           0 b           0 b       1.73 Gb       1.73 Gb            98  \n",
            "                                              aten::mul         0.56%       2.333ms         0.80%       3.313ms      33.127us       1.595ms         1.87%       1.595ms      15.951us           0 b           0 b       1.13 Gb       1.13 Gb           100  \n",
            "                                             aten::gelu         0.13%     536.773us         0.19%     803.083us      33.462us       1.951ms         2.29%       1.951ms      81.297us           0 b           0 b       1.12 Gb       1.12 Gb            24  \n",
            "                                    aten::gelu_backward         0.09%     383.213us         0.15%     604.547us      25.189us       2.829ms         3.32%       2.829ms     117.885us           0 b           0 b       1.12 Gb       1.12 Gb            24  \n",
            "                                          aten::resize_         0.01%      48.487us         0.01%      48.487us       6.061us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      97.50 Mb      97.50 Mb             8  \n",
            "                                              aten::sub         0.01%      42.986us         0.02%      63.569us      31.785us      13.440us         0.02%      13.440us       6.720us           0 b           0 b      16.00 Mb      16.00 Mb             2  \n",
            "                                             aten::tanh         0.01%      52.307us         0.02%      72.526us      36.263us       4.960us         0.01%       4.960us       2.480us           0 b           0 b      96.00 Kb      96.00 Kb             2  \n",
            "                                    aten::tanh_backward         0.01%      33.419us         0.01%      52.463us      26.232us       4.032us         0.00%       4.032us       2.016us           0 b           0 b      96.00 Kb      96.00 Kb             2  \n",
            "                                              aten::sum         0.31%       1.288ms         0.51%       2.109ms      42.175us       1.052ms         1.23%       1.052ms      21.040us           0 b           0 b      73.00 Kb      73.00 Kb            50  \n",
            "                                               aten::eq         0.02%      67.867us         0.02%      93.122us      46.561us       5.440us         0.01%       5.440us       2.720us           0 b           0 b      16.00 Kb      16.00 Kb             2  \n",
            "                                aten::nll_loss_backward         0.01%      41.251us         0.03%     112.238us      56.119us       4.577us         0.01%       8.129us       4.065us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                     aten::_log_softmax         0.02%      77.592us         0.03%     110.124us      55.062us       4.927us         0.01%       4.927us       2.463us           0 b           0 b       5.00 Kb       5.00 Kb             2  \n",
            "                       aten::_log_softmax_backward_data         0.01%      34.326us         0.01%      51.912us      25.956us       4.864us         0.01%       4.864us       2.432us           0 b           0 b       5.00 Kb       5.00 Kb             2  \n",
            "                                 aten::nll_loss_forward         0.01%      53.735us         0.02%      72.642us      36.321us       4.766us         0.01%       4.766us       2.383us           0 b           0 b       2.00 Kb       2.00 Kb             2  \n",
            "                                              aten::all         0.01%      58.668us         0.02%      82.464us      41.232us      10.528us         0.01%      10.528us       5.264us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
            "                                       aten::reciprocal         0.02%      98.569us         0.03%     121.580us      60.790us       3.776us         0.00%       3.776us       1.888us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 414.317ms\n",
            "Self CUDA time total: 85.293ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.93%       3.851ms        83.32%     345.212ms     172.606ms       0.000us         0.00%      36.434ms      18.217ms     128.25 Kb    -128.25 Kb           0 b    -378.00 Kb             2  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        34.59%     143.306ms        35.34%     146.421ms      73.210ms       0.000us         0.00%       0.000us       0.000us     256.50 Kb    -384.50 Kb           0 b           0 b             2  \n",
            "                                          backward_pass        21.26%      88.096ms        23.97%      99.309ms      49.654ms       0.000us         0.00%     267.171us     133.585us        -768 b        -768 b      -4.70 Gb      -4.70 Gb             2  \n",
            "                                           forward_pass         6.66%      27.603ms        22.70%      94.065ms      47.033ms       0.000us         0.00%      36.126ms      18.063ms         768 b         384 b       4.70 Gb      -5.36 Gb             2  \n",
            "                                           aten::linear         1.13%       4.693ms        17.11%      70.876ms     145.238us       0.000us         0.00%      34.070ms      69.817us           0 b           0 b       7.14 Gb      -1.13 Gb           488  \n",
            "                                               aten::to         0.46%       1.920ms         8.14%      33.723ms      27.462us       0.000us         0.00%      12.985ms      10.575us           0 b           0 b       5.89 Gb           0 b          1228  \n",
            "                                         aten::_to_copy         1.71%       7.072ms         7.68%      31.803ms      34.719us       0.000us         0.00%      12.985ms      14.176us           0 b           0 b       5.89 Gb           0 b           916  \n",
            "                                       cudaLaunchKernel         4.96%      20.556ms         4.96%      20.556ms       9.128us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          2252  \n",
            "                                               aten::mm         3.19%      13.196ms         4.42%      18.301ms      42.760us      16.544ms        19.40%      16.544ms      38.653us           0 b           0 b       3.55 Gb       3.55 Gb           428  \n",
            "                                            aten::copy_         2.03%       8.410ms         4.14%      17.157ms      18.569us      13.101ms        15.36%      13.101ms      14.179us           0 b           0 b           0 b           0 b           924  \n",
            "autograd::engine::evaluate_function: ToCopyBackward0...         0.71%       2.949ms         3.82%      15.846ms      55.405us       0.000us         0.00%      12.861ms      44.967us           0 b           0 b      -1.57 Gb      -4.71 Gb           286  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.45%       1.879ms         2.98%      12.327ms      84.429us       0.000us         0.00%      13.516ms      92.574us           0 b           0 b    -425.43 Mb      -2.88 Gb           146  \n",
            "       autograd::engine::evaluate_function: MmBackward0         0.41%       1.708ms         2.93%      12.119ms     126.241us       0.000us         0.00%       2.896ms      30.171us           0 b           0 b    -629.95 Mb      -1.14 Gb            96  \n",
            "                                            aten::addmm         1.98%       8.216ms         2.73%      11.299ms      76.342us      12.800ms        15.01%      12.800ms      86.487us           0 b           0 b       2.53 Gb       2.39 Gb           148  \n",
            "                                        ToCopyBackward0         0.18%     738.158us         2.59%      10.730ms      37.517us       0.000us         0.00%       5.124ms      17.914us           0 b           0 b       3.14 Gb           0 b           286  \n",
            "                                            MmBackward0         0.28%       1.180ms         2.51%      10.411ms     108.446us       0.000us         0.00%       2.896ms      30.171us           0 b           0 b     535.12 Mb           0 b            96  \n",
            "                              Optimizer.step#AdamW.step         1.32%       5.480ms         2.34%       9.689ms       4.844ms       0.000us         0.00%     201.247us     100.623us           0 b          -8 b           0 b      -2.63 Mb             2  \n",
            "                                    aten::empty_strided         2.30%       9.545ms         2.30%       9.545ms       8.158us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       6.79 Gb       6.79 Gb          1170  \n",
            "                                         AddmmBackward0         0.23%     967.749us         1.98%       8.187ms      56.078us       0.000us         0.00%      12.464ms      85.369us           0 b           0 b       2.46 Gb           0 b           146  \n",
            "                     aten::scaled_dot_product_attention         0.13%     523.075us         1.72%       7.137ms     148.680us       0.000us         0.00%      10.311ms     214.813us         768 b           0 b     690.00 Mb           0 b            48  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 414.317ms\n",
            "Self CUDA time total: 85.293ms\n",
            "\n",
            "Average training loss: 1.4186\n",
            "Validation Accuracy: 0.6178\n",
            "Macro F1: 0.4277\n",
            "Weighted F1: 0.5800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.base_model.model.save_pretrained(\"bert-base-checkpoint\")\n",
        "model.save_pretrained(\"lora-adapter-checkpoint\")"
      ],
      "metadata": {
        "id": "DUY6NVa2IneB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Size：\n",
        "def get_dir_size(path):\n",
        "    return sum(os.path.getsize(os.path.join(dp, f)) for dp, _, fn in os.walk(path) for f in fn)\n",
        "\n",
        "print(f\"Base size: {get_dir_size('bert-base-checkpoint') / 1024**2:.2f} MB\")\n",
        "print(f\"LoRA size: {get_dir_size('lora-adapter-checkpoint') / 1024**2:.2f} MB\")"
      ],
      "metadata": {
        "id": "JOFKA63gIn6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6509620-0f18-401d-b263-6b18fc7d498c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base size: 419.03 MB\n",
            "LoRA size: 1.25 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation time for LoRA+Mixed Precision\n",
        "texts, labels, label_classes = load_news_data(\"/content/drive/MyDrive/News_Category_Dataset_v2.json\")\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.classes_ = np.array(label_classes)\n",
        "\n",
        "test_text = \"NASA launches new space telescope to explore exoplanets.\"\n",
        "predicted_category = predict_news_category_amp(test_text, model, tokenizer, device, encoder)\n",
        "\n",
        "print(f\"Headline: {test_text}\")\n",
        "print(f\"Predicted Category: {predicted_category}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1vi66xdIiLk",
        "outputId": "3c798345-a7f6-4a3c-8aeb-cf535462f17b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset contains 40 unique categories.\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                              inference         0.00%       0.000us         0.00%       0.000us       0.000us     197.560ms      1349.76%     197.560ms      39.512ms           0 b           0 b           0 b           0 b             5  \n",
            "                                           aten::linear         5.69%      11.470ms        77.19%     155.688ms     127.614us       0.000us         0.00%      15.668ms      12.842us           0 b           0 b     261.31 Mb      -1.06 Gb          1220  \n",
            "                                          ProfilerStep*         0.25%     508.409us        99.99%     201.665ms      40.333ms       0.000us         0.00%      14.637ms       2.927ms           0 b           0 b     576.00 Kb           0 b             5  \n",
            "                                              inference        30.66%      61.833ms        99.74%     201.156ms      40.231ms       0.000us         0.00%      14.637ms       2.927ms           0 b           0 b     576.00 Kb    -338.45 Mb             5  \n",
            "                                            aten::copy_         6.03%      12.154ms        12.23%      24.658ms      17.364us       5.560ms        37.99%       5.560ms       3.916us           0 b           0 b           0 b           0 b          1420  \n",
            "                                               aten::to         1.31%       2.641ms        24.29%      48.985ms      31.912us       0.000us         0.00%       5.547ms       3.614us           0 b           0 b       1.08 Gb           0 b          1535  \n",
            "                                         aten::_to_copy         4.74%       9.568ms        22.98%      46.344ms      32.752us       0.000us         0.00%       5.547ms       3.920us           0 b           0 b       1.08 Gb           0 b          1415  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.492ms        37.52%       5.492ms       3.909us           0 b           0 b           0 b           0 b          1405  \n",
            "                                            aten::addmm         8.65%      17.444ms        11.82%      23.847ms      64.451us       3.868ms        26.42%       3.868ms      10.453us           0 b           0 b     101.26 Mb    -268.74 Mb           370  \n",
            "sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize32x32x...         0.00%       0.000us         0.00%       0.000us       0.000us       2.716ms        18.55%       2.716ms       7.544us           0 b           0 b           0 b           0 b           360  \n",
            "                     aten::scaled_dot_product_attention         0.71%       1.430ms         7.39%      14.897ms     124.143us       0.000us         0.00%       2.292ms      19.097us           0 b        -960 b      22.53 Mb      -1.84 Mb           120  \n",
            "                                           aten::matmul         1.11%       2.236ms         7.35%      14.830ms      61.791us       0.000us         0.00%       1.307ms       5.444us           0 b           0 b      22.73 Mb           0 b           240  \n",
            "                                               aten::mm         4.44%       8.946ms         5.52%      11.139ms      46.415us       1.307ms         8.93%       1.307ms       5.444us           0 b           0 b      22.73 Mb      22.73 Mb           240  \n",
            "                                              aten::add         2.01%       4.056ms         3.12%       6.289ms      25.671us       1.138ms         7.78%       1.138ms       4.646us           0 b           0 b      69.38 Mb      69.38 Mb           245  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.42%     837.294us         2.28%       4.599ms      76.644us       0.000us         0.00%       1.060ms      17.660us         960 b           0 b      11.25 Mb           0 b            60  \n",
            "                     aten::_efficient_attention_forward         0.63%       1.277ms         1.48%       2.976ms      49.600us       1.060ms         7.24%       1.060ms      17.660us         960 b           0 b      11.25 Mb           0 b            60  \n",
            "fmha_cutlassF_f16_aligned_64x64_rf_sm80(PyTorchMemEf...         0.00%       0.000us         0.00%       0.000us       0.000us       1.060ms         7.24%       1.060ms      17.660us           0 b           0 b           0 b           0 b            60  \n",
            "                                       aten::layer_norm         0.54%       1.090ms         4.06%       8.196ms      65.567us       0.000us         0.00%     893.118us       7.145us           0 b           0 b      46.88 Mb    -125.00 Kb           125  \n",
            "                                aten::native_layer_norm         1.62%       3.269ms         3.52%       7.106ms      56.845us     893.118us         6.10%     893.118us       7.145us           0 b           0 b      47.00 Mb           0 b           125  \n",
            "void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us     893.118us         6.10%     893.118us       7.145us           0 b           0 b           0 b           0 b           125  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 201.688ms\n",
            "Self CUDA time total: 14.637ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                    aten::empty_strided         6.07%      12.252ms         6.07%      12.252ms       8.659us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       1.08 Gb       1.08 Gb          1415  \n",
            "                                            aten::empty         3.12%       6.291ms         3.12%       6.291ms       6.260us       0.000us         0.00%       0.000us       0.000us         960 b         960 b     428.56 Mb     428.56 Mb          1005  \n",
            "                                              aten::add         2.01%       4.056ms         3.12%       6.289ms      25.671us       1.138ms         7.78%       1.138ms       4.646us           0 b           0 b      69.38 Mb      69.38 Mb           245  \n",
            "                                             aten::gelu         0.83%       1.670ms         1.10%       2.222ms      37.027us     238.116us         1.63%     238.116us       3.969us           0 b           0 b      45.00 Mb      45.00 Mb            60  \n",
            "                                               aten::mm         4.44%       8.946ms         5.52%      11.139ms      46.415us       1.307ms         8.93%       1.307ms       5.444us           0 b           0 b      22.73 Mb      22.73 Mb           240  \n",
            "                                              aten::mul         1.11%       2.237ms         1.63%       3.285ms      27.377us     347.652us         2.38%     347.652us       2.897us           0 b           0 b      22.50 Mb      22.50 Mb           120  \n",
            "                                          aten::resize_         0.05%     102.640us         0.05%     102.640us       6.843us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       5.62 Mb       5.62 Mb            15  \n",
            "                                              aten::sub         0.05%      97.348us         0.07%     148.723us      29.745us      12.736us         0.09%      12.736us       2.547us           0 b           0 b     320.00 Kb     320.00 Kb             5  \n",
            "                                             aten::tanh         0.05%      97.059us         0.07%     149.678us      29.936us      15.009us         0.10%      15.009us       3.002us           0 b           0 b       7.50 Kb       7.50 Kb             5  \n",
            "                                              aten::max         0.10%     209.267us         0.14%     289.691us      57.938us      38.048us         0.26%      38.048us       7.610us           0 b           0 b       5.00 Kb       5.00 Kb             5  \n",
            "                                               aten::eq         0.08%     158.050us         0.11%     229.780us      45.956us      12.768us         0.09%      12.768us       2.554us           0 b           0 b       2.50 Kb       2.50 Kb             5  \n",
            "                                              aten::all         0.07%     138.016us         0.10%     196.018us      39.204us      24.640us         0.17%      24.640us       4.928us           0 b           0 b       2.50 Kb       2.50 Kb             5  \n",
            "                                           Buffer Flush         0.04%      74.719us         0.04%      74.719us      74.719us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       1.50 Kb       1.50 Kb             1  \n",
            "                                          ProfilerStep*         0.25%     508.409us        99.99%     201.665ms      40.333ms       0.000us         0.00%      14.637ms       2.927ms           0 b           0 b     576.00 Kb           0 b             5  \n",
            "                                            aten::slice         0.14%     285.006us         0.16%     327.168us       9.348us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            35  \n",
            "                                       aten::as_strided         0.85%       1.714ms         0.85%       1.714ms       1.399us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1225  \n",
            "                                           aten::expand         0.21%     418.934us         0.26%     516.700us       7.381us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            70  \n",
            "                                        aten::embedding         0.07%     141.061us         0.45%     906.332us      60.422us       0.000us         0.00%      82.176us       5.478us           0 b           0 b       5.62 Mb           0 b            15  \n",
            "                                          aten::reshape         0.70%       1.412ms         1.61%       3.243ms       4.804us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           675  \n",
            "                                             aten::view         1.71%       3.453ms         1.71%       3.453ms       2.333us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1480  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 201.688ms\n",
            "Self CUDA time total: 14.637ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.25%     508.409us        99.99%     201.665ms      40.333ms       0.000us         0.00%      14.637ms       2.927ms           0 b           0 b     576.00 Kb           0 b             5  \n",
            "                                              inference        30.66%      61.833ms        99.74%     201.156ms      40.231ms       0.000us         0.00%      14.637ms       2.927ms           0 b           0 b     576.00 Kb    -338.45 Mb             5  \n",
            "                                           aten::linear         5.69%      11.470ms        77.19%     155.688ms     127.614us       0.000us         0.00%      15.668ms      12.842us           0 b           0 b     261.31 Mb      -1.06 Gb          1220  \n",
            "                                               aten::to         1.31%       2.641ms        24.29%      48.985ms      31.912us       0.000us         0.00%       5.547ms       3.614us           0 b           0 b       1.08 Gb           0 b          1535  \n",
            "                                         aten::_to_copy         4.74%       9.568ms        22.98%      46.344ms      32.752us       0.000us         0.00%       5.547ms       3.920us           0 b           0 b       1.08 Gb           0 b          1415  \n",
            "                                            aten::copy_         6.03%      12.154ms        12.23%      24.658ms      17.364us       5.560ms        37.99%       5.560ms       3.916us           0 b           0 b           0 b           0 b          1420  \n",
            "                                            aten::addmm         8.65%      17.444ms        11.82%      23.847ms      64.451us       3.868ms        26.42%       3.868ms      10.453us           0 b           0 b     101.26 Mb    -268.74 Mb           370  \n",
            "                                       cudaLaunchKernel        11.30%      22.782ms        11.30%      22.782ms       8.882us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          2565  \n",
            "                     aten::scaled_dot_product_attention         0.71%       1.430ms         7.39%      14.897ms     124.143us       0.000us         0.00%       2.292ms      19.097us           0 b        -960 b      22.53 Mb      -1.84 Mb           120  \n",
            "                                           aten::matmul         1.11%       2.236ms         7.35%      14.830ms      61.791us       0.000us         0.00%       1.307ms       5.444us           0 b           0 b      22.73 Mb           0 b           240  \n",
            "                                    aten::empty_strided         6.07%      12.252ms         6.07%      12.252ms       8.659us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       1.08 Gb       1.08 Gb          1415  \n",
            "                                               aten::mm         4.44%       8.946ms         5.52%      11.139ms      46.415us       1.307ms         8.93%       1.307ms       5.444us           0 b           0 b      22.73 Mb      22.73 Mb           240  \n",
            "                                       aten::layer_norm         0.54%       1.090ms         4.06%       8.196ms      65.567us       0.000us         0.00%     893.118us       7.145us           0 b           0 b      46.88 Mb    -125.00 Kb           125  \n",
            "                                aten::native_layer_norm         1.62%       3.269ms         3.52%       7.106ms      56.845us     893.118us         6.10%     893.118us       7.145us           0 b           0 b      47.00 Mb           0 b           125  \n",
            "                                            aten::empty         3.12%       6.291ms         3.12%       6.291ms       6.260us       0.000us         0.00%       0.000us       0.000us         960 b         960 b     428.56 Mb     428.56 Mb          1005  \n",
            "                                              aten::add         2.01%       4.056ms         3.12%       6.289ms      25.671us       1.138ms         7.78%       1.138ms       4.646us           0 b           0 b      69.38 Mb      69.38 Mb           245  \n",
            "                                                aten::t         1.01%       2.047ms         2.54%       5.131ms       8.411us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           610  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.42%     837.294us         2.28%       4.599ms      76.644us       0.000us         0.00%       1.060ms      17.660us         960 b           0 b      11.25 Mb           0 b            60  \n",
            "                                        aten::transpose         1.46%       2.950ms         2.06%       4.152ms       4.563us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           910  \n",
            "                                             aten::view         1.71%       3.453ms         1.71%       3.453ms       2.333us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1480  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 201.688ms\n",
            "Self CUDA time total: 14.637ms\n",
            "\n",
            "✅ Profiling complete. Run: tensorboard --logdir=./log_amp_predict\n",
            "Headline: NASA launches new space telescope to explore exoplanets.\n",
            "Predicted Category: SCIENCE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vbgo_uWrKaGb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}