{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzUaFDoDkIzh",
        "outputId": "670ef62a-e3d7-4764-b9db-d66ac5a132ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcHBtBKicB-H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "4b40e4e6-1fd2-4ec0-9a2f-bf4ef955441f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhl6151\u001b[0m (\u001b[33mhl6151-new-york-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import pandas as pd\n",
        "from torch.optim import AdamW\n",
        "from torchinfo import summary\n",
        "import numpy as np\n",
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mxYLBZlB8XIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_news_data(data_file):\n",
        "\n",
        "    df = pd.read_json(data_file, lines=True)\n",
        "    df.head()\n",
        "\n",
        "    df['category'] = df['category'].map(lambda x: \"WORLDPOST\" if x == \"THE WORLDPOST\" else x)\n",
        "\n",
        "    df['headline'] = df['headline'].apply(lambda x: str(x).lower())\n",
        "    df['short_description'] = df['short_description'].apply(lambda x: str(x).lower())\n",
        "\n",
        "    df['text'] = df['headline'] + \" \" + df['short_description']\n",
        "    encoder = LabelEncoder()\n",
        "    df['label'] = encoder.fit_transform(df['category'])\n",
        "    print(f\"The dataset contains {df['category'].nunique()} unique categories.\")\n",
        "\n",
        "    return df['text'].tolist(), df['label'].tolist(), encoder.classes_.tolist()"
      ],
      "metadata": {
        "id": "rdAUEwDJcDP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "944EgMsfg8BD",
        "outputId": "53f07852-dfc5-4b0e-ced6-707ea1e2e29b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = \"/content/drive/MyDrive/News_Category_Dataset_v2.json\"\n",
        "texts, labels, label_names = load_news_data(data_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1iQ3D7wcUcn",
        "outputId": "853c1f09-8b0b-47f6-f777-c5791f869fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset contains 40 unique categories.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for idx, name in enumerate(label_names):\n",
        "    print(f\"{idx} → {name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x28ciF82oHjB",
        "outputId": "e2d5e553-6cd3-480d-8a0a-45a84a43d848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 → ARTS\n",
            "1 → ARTS & CULTURE\n",
            "2 → BLACK VOICES\n",
            "3 → BUSINESS\n",
            "4 → COLLEGE\n",
            "5 → COMEDY\n",
            "6 → CRIME\n",
            "7 → CULTURE & ARTS\n",
            "8 → DIVORCE\n",
            "9 → EDUCATION\n",
            "10 → ENTERTAINMENT\n",
            "11 → ENVIRONMENT\n",
            "12 → FIFTY\n",
            "13 → FOOD & DRINK\n",
            "14 → GOOD NEWS\n",
            "15 → GREEN\n",
            "16 → HEALTHY LIVING\n",
            "17 → HOME & LIVING\n",
            "18 → IMPACT\n",
            "19 → LATINO VOICES\n",
            "20 → MEDIA\n",
            "21 → MONEY\n",
            "22 → PARENTING\n",
            "23 → PARENTS\n",
            "24 → POLITICS\n",
            "25 → QUEER VOICES\n",
            "26 → RELIGION\n",
            "27 → SCIENCE\n",
            "28 → SPORTS\n",
            "29 → STYLE\n",
            "30 → STYLE & BEAUTY\n",
            "31 → TASTE\n",
            "32 → TECH\n",
            "33 → TRAVEL\n",
            "34 → WEDDINGS\n",
            "35 → WEIRD NEWS\n",
            "36 → WELLNESS\n",
            "37 → WOMEN\n",
            "38 → WORLD NEWS\n",
            "39 → WORLDPOST\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up parameters\n",
        "bert_model_name = 'bert-base-uncased'\n",
        "num_classes = len(label_names)\n",
        "max_length = 256\n",
        "batch_size = 32\n",
        "num_epochs = 8\n",
        "learning_rate = 2e-5"
      ],
      "metadata": {
        "id": "S7sIYVYmc4MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
        "        return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}"
      ],
      "metadata": {
        "id": "o6OaJGUzcd_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self, bert_model_name, num_classes):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        x = self.dropout(pooled_output)\n",
        "        logits = self.fc(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "mH--1xTNes_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_loader, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    progress_bar = tqdm(data_loader, desc=\"Training\", leave=True)\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    print(f\"\\nEpoch completed. Average training loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "mkEMls1eeuyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Without mixed precision\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "def train_original(model, dataloader, optimizer, scheduler, device, epoch=None):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    with profile(\n",
        "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA] if device.type == \"cuda\" else [ProfilerActivity.CPU],\n",
        "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=2, repeat=1),\n",
        "        on_trace_ready=torch.profiler.tensorboard_trace_handler(f\"./log_train_profiler\"),\n",
        "        record_shapes=True,\n",
        "        profile_memory=True,\n",
        "        with_stack=True\n",
        "    ) as profiler:\n",
        "\n",
        "        for step, batch in enumerate(tqdm(dataloader, desc=f\"Training Epoch {epoch if epoch is not None else ''}\")):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with record_function(\"forward_pass\"):\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                # logits = outputs.logits\n",
        "                loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "\n",
        "            with record_function(\"backward_pass\"):\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            scheduler.step()\n",
        "            profiler.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            # wandb.log({\"train/loss_batch\": loss.item()})\n",
        "\n",
        "    print(profiler.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"cpu_time_total\", row_limit=20))\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"Average training loss: {avg_loss:.4f}\")\n",
        "    # wandb.log({\"train/loss_epoch\": avg_loss})"
      ],
      "metadata": {
        "id": "54dSN89l1hDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "def train_original(model, dataloader, optimizer, scheduler, device, epoch=None):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    with profile(\n",
        "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA] if device.type == \"cuda\" else [ProfilerActivity.CPU],\n",
        "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=2, repeat=1),\n",
        "        on_trace_ready=torch.profiler.tensorboard_trace_handler(f\"./log_train_profiler\"),\n",
        "        record_shapes=True,\n",
        "        profile_memory=True,\n",
        "        with_stack=True\n",
        "    ) as profiler:\n",
        "\n",
        "        for step, batch in enumerate(tqdm(dataloader, desc=f\"Training Epoch {epoch if epoch is not None else ''}\")):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with record_function(\"forward_pass\"):\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "\n",
        "            with record_function(\"backward_pass\"):\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            scheduler.step()\n",
        "            profiler.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            wandb.log({\"train/loss_batch\": loss.item()})\n",
        "\n",
        "    # ===  profiler Report!  ===\n",
        "    print(profiler.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"cpu_time_total\", row_limit=20))\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"Average training loss: {avg_loss:.4f}\")\n",
        "    wandb.log({\"train/loss_epoch\": avg_loss})"
      ],
      "metadata": {
        "id": "r_aTqZPo9MIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actual_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            predictions.extend(preds.cpu().tolist())\n",
        "            actual_labels.extend(labels.cpu().tolist())\n",
        "    acc = accuracy_score(actual_labels, predictions)\n",
        "    macro_f1 = f1_score(actual_labels, predictions, average='macro')\n",
        "    weighted_f1 = f1_score(actual_labels, predictions, average='weighted')\n",
        "\n",
        "    return acc, macro_f1, weighted_f1"
      ],
      "metadata": {
        "id": "FHsoludJewrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_news_category(text, model, tokenizer, device, encoder, max_length=128):\n",
        "    model.eval()\n",
        "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length,\n",
        "                         padding='max_length', truncation=True)\n",
        "\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        _, predicted_label = torch.max(outputs, dim=1)\n",
        "\n",
        "    predicted_category = encoder.inverse_transform(predicted_label.cpu().numpy())[0]\n",
        "    return predicted_category"
      ],
      "metadata": {
        "id": "MNtYDSl1lwrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.profiler import profile, record_function, ProfilerActivity, schedule, tensorboard_trace_handler\n",
        "import time\n",
        "def predict_news_category(text, model, tokenizer, device, encoder, max_length=128):\n",
        "    model.eval()\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=max_length\n",
        "    )\n",
        "    input_ids = inputs[\"input_ids\"].to(device)\n",
        "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
        "\n",
        "    with profile(\n",
        "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA] if device.type == \"cuda\" else [ProfilerActivity.CPU],\n",
        "        schedule=schedule(wait=1, warmup=1, active=5, repeat=1),\n",
        "        record_shapes=True,\n",
        "        profile_memory=True,\n",
        "        with_stack=True,\n",
        "        on_trace_ready=tensorboard_trace_handler(\"./log_predict_base_warmup\")\n",
        "    ) as profiler:\n",
        "        for i in range(7):\n",
        "            with torch.no_grad():\n",
        "                with record_function(f\"model_inference_{i}\"):\n",
        "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                    _, predicted_label = torch.max(outputs, dim=1)\n",
        "            profiler.step()\n",
        "\n",
        "    print(profiler.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"cpu_time_total\", row_limit=20))\n",
        "\n",
        "    predicted_category = encoder.inverse_transform(predicted_label.cpu().numpy())[0]\n",
        "\n",
        "    return predicted_category"
      ],
      "metadata": {
        "id": "aj7IqlhvPgaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "a6sO8uI0dAl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
        "train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n",
        "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "i6LTdTTrdC_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BERTClassifier(bert_model_name, num_classes).to(device)\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_8qO4lidH1c",
        "outputId": "234f32f9-72cf-4c48-a3fb-b45e241bfb35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "total_steps = len(train_dataloader) * num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
      ],
      "metadata": {
        "id": "OH0DIqmVdMYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 128\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "input_data = {\n",
        "    \"input_ids\": torch.zeros((batch_size, seq_len), dtype=torch.long).to(device),\n",
        "    \"attention_mask\": torch.ones((batch_size, seq_len), dtype=torch.long).to(device)\n",
        "}\n",
        "\n",
        "summary(model, input_data=input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XBe_-eCklCr",
        "outputId": "7c4c3f0b-869e-46b6-fe0b-47c1be15dfcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==============================================================================================================\n",
              "Layer (type:depth-idx)                                       Output Shape              Param #\n",
              "==============================================================================================================\n",
              "BERTClassifier                                               [32, 40]                  --\n",
              "├─BertModel: 1-1                                             [32, 768]                 --\n",
              "│    └─BertEmbeddings: 2-1                                   [32, 128, 768]            --\n",
              "│    │    └─Embedding: 3-1                                   [32, 128, 768]            23,440,896\n",
              "│    │    └─Embedding: 3-2                                   [32, 128, 768]            1,536\n",
              "│    │    └─Embedding: 3-3                                   [1, 128, 768]             393,216\n",
              "│    │    └─LayerNorm: 3-4                                   [32, 128, 768]            1,536\n",
              "│    │    └─Dropout: 3-5                                     [32, 128, 768]            --\n",
              "│    └─BertEncoder: 2-2                                      [32, 128, 768]            --\n",
              "│    │    └─ModuleList: 3-6                                  --                        85,054,464\n",
              "│    └─BertPooler: 2-3                                       [32, 768]                 --\n",
              "│    │    └─Linear: 3-7                                      [32, 768]                 590,592\n",
              "│    │    └─Tanh: 3-8                                        [32, 768]                 --\n",
              "├─Dropout: 1-2                                               [32, 768]                 --\n",
              "├─Linear: 1-3                                                [32, 40]                  30,760\n",
              "==============================================================================================================\n",
              "Total params: 109,513,000\n",
              "Trainable params: 109,513,000\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 3.49\n",
              "==============================================================================================================\n",
              "Input size (MB): 0.07\n",
              "Forward/backward pass size (MB): 3398.38\n",
              "Params size (MB): 438.05\n",
              "Estimated Total Size (MB): 3836.50\n",
              "=============================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb initialization\n",
        "wandb.init(project=\"News classification\", name=\"Bert-base\", config={\n",
        "    \"Model_name\": bert_model_name,\n",
        "    \"Epoch\": num_epochs,\n",
        "    \"Batch_size\": batch_size,\n",
        "    \"Learning_rate\": learning_rate,\n",
        "    \"Max_length\": max_length\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "q0zZx13_8bIj",
        "outputId": "dbf465d4-3262-4565-c057-e4c9d1dd2bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250507_225516-cw38bzjy</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/hl6151-new-york-university/News%20classification/runs/cw38bzjy' target=\"_blank\">Bert-base</a></strong> to <a href='https://wandb.ai/hl6151-new-york-university/News%20classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/hl6151-new-york-university/News%20classification' target=\"_blank\">https://wandb.ai/hl6151-new-york-university/News%20classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/hl6151-new-york-university/News%20classification/runs/cw38bzjy' target=\"_blank\">https://wandb.ai/hl6151-new-york-university/News%20classification/runs/cw38bzjy</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/hl6151-new-york-university/News%20classification/runs/cw38bzjy?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f4d74e8afd0>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "        train_original(model, train_dataloader, optimizer, scheduler, device)\n",
        "        accuracy, macro_f1, weighted_f1 = evaluate(model, val_dataloader, device)\n",
        "        print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Macro F1: {macro_f1:.4f}\")\n",
        "        print(f\"Weighted F1: {weighted_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BLgBUfmdd5y",
        "outputId": "eacb030e-33f6-4895-f225-8ee6ec9d689d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch : 100%|██████████| 5022/5022 [26:24<00:00,  3.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.31%       3.154ms         2.56%      25.935ms     175.239us       0.000us         0.00%     323.066ms       2.183ms           0 b           0 b      -2.77 Gb      -8.48 Gb           148  \n",
            "                                         AddmmBackward0         0.22%       2.194ms         1.59%      16.126ms     108.960us       0.000us         0.00%     316.746ms       2.140ms           0 b           0 b       5.72 Gb           0 b           148  \n",
            "                                               aten::mm         0.73%       7.447ms         1.05%      10.689ms      36.113us     316.746ms        39.69%     316.746ms       1.070ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                          ProfilerStep*         0.63%       6.398ms        73.11%     741.314ms     370.657ms       0.000us         0.00%     196.686ms      98.343ms     258.50 Kb    -128.25 Kb       1.50 Mb    -257.00 Kb             2  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us     185.798ms        23.28%     185.798ms      92.899ms           0 b           0 b           0 b           0 b             2  \n",
            "                                           forward_pass         1.79%      18.170ms         4.81%      48.800ms      24.400ms       0.000us         0.00%     182.799ms      91.399ms         384 b           0 b       9.42 Gb      -2.43 Gb             2  \n",
            "                        ampere_sgemm_64x32_sliced1x4_nt         0.00%       0.000us         0.00%       0.000us       0.000us     168.434ms        21.11%     168.434ms     935.745us           0 b           0 b           0 b           0 b           180  \n",
            "                                           aten::linear         0.16%       1.636ms         1.47%      14.881ms     100.548us       0.000us         0.00%     160.555ms       1.085ms           0 b           0 b       5.06 Gb           0 b           148  \n",
            "                                            aten::addmm         0.67%       6.825ms         1.00%      10.154ms      68.606us     160.555ms        20.12%     160.555ms       1.085ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "                                 ampere_sgemm_128x32_nn         0.00%       0.000us         0.00%       0.000us       0.000us     159.016ms        19.93%     159.016ms     883.422us           0 b           0 b           0 b           0 b           180  \n",
            "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us     145.603ms        18.25%     145.603ms      72.802ms           0 b           0 b           0 b           0 b             2  \n",
            "                                 ampere_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us      74.581ms         9.35%      74.581ms       2.072ms           0 b           0 b           0 b           0 b            36  \n",
            "                                ampere_sgemm_128x128_nt         0.00%       0.000us         0.00%       0.000us       0.000us      72.945ms         9.14%      72.945ms       2.026ms           0 b           0 b           0 b           0 b            36  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us      68.507ms         8.58%      68.507ms       2.284ms           0 b           0 b           0 b           0 b            30  \n",
            "                                 ampere_sgemm_128x32_tn         0.00%       0.000us         0.00%       0.000us       0.000us      67.750ms         8.49%      67.750ms     579.059us           0 b           0 b           0 b           0 b           117  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us      62.436ms         7.82%      62.436ms       2.081ms           0 b           0 b           0 b           0 b            30  \n",
            "fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyT...         0.00%       0.000us         0.00%       0.000us       0.000us      34.202ms         4.29%      34.202ms     950.068us           0 b           0 b           0 b           0 b            36  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.06%     648.909us         0.69%       7.021ms     292.532us       0.000us         0.00%      25.310ms       1.055ms        -384 b        -384 b      -1.15 Gb      -2.84 Gb            24  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.03%     257.935us         0.63%       6.372ms     265.494us       0.000us         0.00%      25.310ms       1.055ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.07%     698.699us         0.60%       6.114ms     254.747us       0.000us         0.00%      25.310ms       1.055ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.014s\n",
            "Self CUDA time total: 798.026ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                            aten::empty         0.59%       5.948ms         0.59%       5.948ms       6.020us       0.000us         0.00%       0.000us       0.000us     384.51 Kb     384.51 Kb       6.84 Gb       6.84 Gb           988  \n",
            "                                               aten::mm         0.73%       7.447ms         1.05%      10.689ms      36.113us     316.746ms        39.69%     316.746ms       1.070ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                            aten::addmm         0.67%       6.825ms         1.00%      10.154ms      68.606us     160.555ms        20.12%     160.555ms       1.085ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "                                    aten::empty_strided         0.31%       3.185ms         0.31%       3.185ms       6.148us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       2.30 Gb       2.30 Gb           518  \n",
            "                                             aten::gelu         0.06%     581.031us         0.09%     862.637us      35.943us       3.412ms         0.43%       3.412ms     142.152us           0 b           0 b       2.25 Gb       2.25 Gb            24  \n",
            "                                    aten::gelu_backward         0.04%     399.113us         0.06%     655.961us      27.332us       5.108ms         0.64%       5.108ms     212.852us           0 b           0 b       2.25 Gb       2.25 Gb            24  \n",
            "                                              aten::add         0.10%       1.037ms         0.15%       1.549ms      30.972us       2.794ms         0.35%       2.794ms      55.876us           0 b           0 b       1.17 Gb       1.17 Gb            50  \n",
            "                                              aten::mul         0.03%     343.086us         0.07%     661.074us      27.545us       1.131ms         0.14%       1.131ms      47.132us           0 b           0 b     576.00 Mb     576.00 Mb            24  \n",
            "                                          aten::resize_         0.01%      71.828us         0.01%      71.828us       5.986us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      97.75 Mb      97.75 Mb            12  \n",
            "                                              aten::sub         0.00%      48.434us         0.01%      74.835us      37.418us      12.929us         0.00%      12.929us       6.464us           0 b           0 b      16.00 Mb      16.00 Mb             2  \n",
            "                                              aten::sum         0.44%       4.468ms         0.69%       7.014ms      40.309us       7.361ms         0.92%       7.361ms      42.306us           0 b           0 b      11.14 Mb      11.14 Mb           174  \n",
            "                                             aten::tanh         0.01%      57.357us         0.01%      81.137us      40.568us       4.992us         0.00%       4.992us       2.496us           0 b           0 b     192.00 Kb     192.00 Kb             2  \n",
            "                                    aten::tanh_backward         0.00%      36.833us         0.01%      56.745us      28.372us       4.096us         0.00%       4.096us       2.048us           0 b           0 b     192.00 Kb     192.00 Kb             2  \n",
            "                                               aten::eq         0.01%      77.793us         0.01%     109.219us      54.610us       5.792us         0.00%       5.792us       2.896us           0 b           0 b      16.00 Kb      16.00 Kb             2  \n",
            "                                     aten::_log_softmax         0.01%      86.407us         0.01%     118.988us      59.494us       4.800us         0.00%       4.800us       2.400us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                aten::nll_loss_backward         0.01%      60.250us         0.02%     164.113us      82.056us       4.544us         0.00%       8.096us       4.048us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                       aten::_log_softmax_backward_data         0.00%      35.166us         0.01%      53.140us      26.570us       4.768us         0.00%       4.768us       2.384us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                 aten::nll_loss_forward         0.01%      61.887us         0.01%      86.165us      43.083us       5.088us         0.00%       5.088us       2.544us           0 b           0 b       2.00 Kb       2.00 Kb             2  \n",
            "                                              aten::all         0.01%      60.298us         0.01%      85.228us      42.614us      10.497us         0.00%      10.497us       5.248us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
            "                                             aten::item         0.10%     992.273us        44.28%     448.954ms     554.264us       0.000us         0.00%      14.945us       0.018us           0 b           0 b           0 b           0 b           810  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.014s\n",
            "Self CUDA time total: 798.026ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.63%       6.398ms        73.11%     741.314ms     370.657ms       0.000us         0.00%     196.686ms      98.343ms     258.50 Kb    -128.25 Kb       1.50 Mb    -257.00 Kb             2  \n",
            "                                             aten::item         0.10%     992.273us        44.28%     448.954ms     554.264us       0.000us         0.00%      14.945us       0.018us           0 b           0 b           0 b           0 b           810  \n",
            "                              aten::_local_scalar_dense         0.04%     393.899us        44.18%     447.961ms     553.039us      14.945us         0.00%      14.945us       0.018us           0 b           0 b           0 b           0 b           810  \n",
            "                                  cudaStreamSynchronize        44.13%     447.488ms        44.13%     447.488ms      37.291ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            12  \n",
            "                                  cudaDeviceSynchronize        20.87%     211.662ms        20.87%     211.662ms     211.662ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        13.38%     135.687ms        13.70%     138.932ms      69.466ms       0.000us         0.00%       0.000us       0.000us     386.75 Kb    -254.25 Kb           0 b           0 b             2  \n",
            "                                          backward_pass         7.51%      76.187ms         9.56%      96.932ms      48.466ms       0.000us         0.00%      13.846ms       6.923ms        -384 b        -384 b      -8.58 Gb      -8.58 Gb             2  \n",
            "                                           forward_pass         1.79%      18.170ms         4.81%      48.800ms      24.400ms       0.000us         0.00%     182.799ms      91.399ms         384 b           0 b       9.42 Gb      -2.43 Gb             2  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.31%       3.154ms         2.56%      25.935ms     175.239us       0.000us         0.00%     323.066ms       2.183ms           0 b           0 b      -2.77 Gb      -8.48 Gb           148  \n",
            "                              Optimizer.step#AdamW.step         1.06%      10.729ms         2.02%      20.517ms      10.258ms       0.000us         0.00%      13.843ms       6.922ms           0 b          -8 b           0 b    -837.02 Mb             2  \n",
            "                                         AddmmBackward0         0.22%       2.194ms         1.59%      16.126ms     108.960us       0.000us         0.00%     316.746ms       2.140ms           0 b           0 b       5.72 Gb           0 b           148  \n",
            "                                           aten::linear         0.16%       1.636ms         1.47%      14.881ms     100.548us       0.000us         0.00%     160.555ms       1.085ms           0 b           0 b       5.06 Gb           0 b           148  \n",
            "                                       cudaLaunchKernel         1.36%      13.740ms         1.36%      13.740ms       9.676us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1420  \n",
            "                                               aten::mm         0.73%       7.447ms         1.05%      10.689ms      36.113us     316.746ms        39.69%     316.746ms       1.070ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                            aten::addmm         0.67%       6.825ms         1.00%      10.154ms      68.606us     160.555ms        20.12%     160.555ms       1.085ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "     autograd::engine::evaluate_function: ViewBackward0         0.29%       2.965ms         0.76%       7.670ms      19.973us       0.000us         0.00%       4.274ms      11.130us           0 b           0 b      -2.25 Gb      -2.25 Gb           384  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.06%     648.909us         0.69%       7.021ms     292.532us       0.000us         0.00%      25.310ms       1.055ms        -384 b        -384 b      -1.15 Gb      -2.84 Gb            24  \n",
            "                                              aten::sum         0.44%       4.468ms         0.69%       7.014ms      40.309us       7.361ms         0.92%       7.361ms      42.306us           0 b           0 b      11.14 Mb      11.14 Mb           174  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.03%     257.935us         0.63%       6.372ms     265.494us       0.000us         0.00%      25.310ms       1.055ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.07%     698.699us         0.60%       6.114ms     254.747us       0.000us         0.00%      25.310ms       1.055ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.014s\n",
            "Self CUDA time total: 798.026ms\n",
            "\n",
            "Average training loss: 1.2980\n",
            "Validation Accuracy: 0.7055\n",
            "Macro F1: 0.6008\n",
            "Weighted F1: 0.6954\n",
            "Epoch 2/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch : 100%|██████████| 5022/5022 [26:27<00:00,  3.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.34%       3.424ms         2.65%      27.105ms     183.142us       0.000us         0.00%     322.771ms       2.181ms           0 b           0 b      -2.77 Gb      -8.48 Gb           148  \n",
            "                                         AddmmBackward0         0.23%       2.385ms         1.64%      16.746ms     113.148us       0.000us         0.00%     316.469ms       2.138ms           0 b           0 b       5.72 Gb           0 b           148  \n",
            "                                               aten::mm         0.74%       7.610ms         1.08%      11.046ms      37.316us     316.469ms        39.97%     316.469ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                          ProfilerStep*         0.51%       5.207ms        73.12%     747.390ms     373.695ms       0.000us         0.00%     196.566ms      98.283ms     128.25 Kb    -128.25 Kb           0 b    -257.00 Kb             2  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us     185.344ms        23.41%     185.344ms      92.672ms           0 b           0 b           0 b           0 b             2  \n",
            "                                           forward_pass         1.72%      17.569ms         4.66%      47.626ms      23.813ms       0.000us         0.00%     182.680ms      91.340ms         384 b           0 b       9.42 Gb      -2.43 Gb             2  \n",
            "                        ampere_sgemm_64x32_sliced1x4_nt         0.00%       0.000us         0.00%       0.000us       0.000us     168.300ms        21.26%     168.300ms     935.001us           0 b           0 b           0 b           0 b           180  \n",
            "                                           aten::linear         0.16%       1.610ms         1.45%      14.801ms     100.007us       0.000us         0.00%     160.427ms       1.084ms           0 b           0 b       5.06 Gb           0 b           148  \n",
            "                                            aten::addmm         0.66%       6.785ms         0.98%      10.067ms      68.023us     160.427ms        20.26%     160.427ms       1.084ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "                                 ampere_sgemm_128x32_nn         0.00%       0.000us         0.00%       0.000us       0.000us     158.860ms        20.06%     158.860ms     882.554us           0 b           0 b           0 b           0 b           180  \n",
            "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us     157.707ms        19.92%     157.707ms      78.854ms           0 b           0 b           0 b           0 b             2  \n",
            "                                 ampere_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us      74.563ms         9.42%      74.563ms       2.071ms           0 b           0 b           0 b           0 b            36  \n",
            "                                ampere_sgemm_128x128_nt         0.00%       0.000us         0.00%       0.000us       0.000us      72.822ms         9.20%      72.822ms       2.023ms           0 b           0 b           0 b           0 b            36  \n",
            "                                 ampere_sgemm_128x32_tn         0.00%       0.000us         0.00%       0.000us       0.000us      67.141ms         8.48%      67.141ms     578.802us           0 b           0 b           0 b           0 b           116  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us      66.209ms         8.36%      66.209ms       2.283ms           0 b           0 b           0 b           0 b            29  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us      60.375ms         7.63%      60.375ms       2.082ms           0 b           0 b           0 b           0 b            29  \n",
            "fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyT...         0.00%       0.000us         0.00%       0.000us       0.000us      34.141ms         4.31%      34.141ms     948.363us           0 b           0 b           0 b           0 b            36  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.06%     625.621us         0.70%       7.133ms     297.224us       0.000us         0.00%      25.271ms       1.053ms        -384 b        -384 b      -1.15 Gb      -2.84 Gb            24  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.03%     258.572us         0.64%       6.508ms     271.156us       0.000us         0.00%      25.271ms       1.053ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.07%     722.734us         0.61%       6.249ms     260.383us       0.000us         0.00%      25.271ms       1.053ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.022s\n",
            "Self CUDA time total: 791.790ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                            aten::empty         0.57%       5.818ms         0.57%       5.818ms       5.889us       0.000us         0.00%       0.000us       0.000us     384.51 Kb     384.51 Kb       6.84 Gb       6.84 Gb           988  \n",
            "                                               aten::mm         0.74%       7.610ms         1.08%      11.046ms      37.316us     316.469ms        39.97%     316.469ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                            aten::addmm         0.66%       6.785ms         0.98%      10.067ms      68.023us     160.427ms        20.26%     160.427ms       1.084ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "                                    aten::empty_strided         0.31%       3.207ms         0.31%       3.207ms       6.192us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       2.30 Gb       2.30 Gb           518  \n",
            "                                             aten::gelu         0.05%     543.122us         0.08%     810.595us      33.775us       3.414ms         0.43%       3.414ms     142.266us           0 b           0 b       2.25 Gb       2.25 Gb            24  \n",
            "                                    aten::gelu_backward         0.04%     424.410us         0.07%     688.603us      28.692us       5.105ms         0.64%       5.105ms     212.701us           0 b           0 b       2.25 Gb       2.25 Gb            24  \n",
            "                                              aten::add         0.10%       1.022ms         0.14%       1.470ms      29.408us       2.796ms         0.35%       2.796ms      55.928us           0 b           0 b       1.17 Gb       1.17 Gb            50  \n",
            "                                              aten::mul         0.03%     344.496us         0.07%     671.290us      27.970us       1.129ms         0.14%       1.129ms      47.034us           0 b           0 b     576.00 Mb     576.00 Mb            24  \n",
            "                                          aten::resize_         0.01%      69.422us         0.01%      69.422us       5.785us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      97.75 Mb      97.75 Mb            12  \n",
            "                                              aten::sub         0.00%      47.791us         0.01%      71.797us      35.898us      12.992us         0.00%      12.992us       6.496us           0 b           0 b      16.00 Mb      16.00 Mb             2  \n",
            "                                              aten::sum         0.45%       4.623ms         0.71%       7.293ms      41.911us       7.341ms         0.93%       7.341ms      42.188us           0 b           0 b      11.14 Mb      11.14 Mb           174  \n",
            "                                             aten::tanh         0.01%      54.425us         0.01%      75.891us      37.946us       5.024us         0.00%       5.024us       2.512us           0 b           0 b     192.00 Kb     192.00 Kb             2  \n",
            "                                    aten::tanh_backward         0.00%      34.949us         0.01%      54.413us      27.207us       4.095us         0.00%       4.095us       2.047us           0 b           0 b     192.00 Kb     192.00 Kb             2  \n",
            "                                               aten::eq         0.01%      69.219us         0.01%      94.280us      47.140us       5.600us         0.00%       5.600us       2.800us           0 b           0 b      16.00 Kb      16.00 Kb             2  \n",
            "                                     aten::_log_softmax         0.01%      58.547us         0.01%      86.351us      43.176us       4.800us         0.00%       4.800us       2.400us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                aten::nll_loss_backward         0.01%      79.691us         0.02%     191.010us      95.505us       4.704us         0.00%       8.224us       4.112us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                       aten::_log_softmax_backward_data         0.00%      36.310us         0.01%      54.134us      27.067us       4.640us         0.00%       4.640us       2.320us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                 aten::nll_loss_forward         0.01%      51.267us         0.01%      72.100us      36.050us       5.152us         0.00%       5.152us       2.576us           0 b           0 b       2.00 Kb       2.00 Kb             2  \n",
            "                                              aten::all         0.01%      58.891us         0.01%      82.902us      41.451us      10.560us         0.00%      10.560us       5.280us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
            "                                             aten::item         0.10%     978.399us        43.14%     440.922ms     544.348us       0.000us         0.00%      12.736us       0.016us           0 b           0 b           0 b           0 b           810  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.022s\n",
            "Self CUDA time total: 791.790ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.51%       5.207ms        73.12%     747.390ms     373.695ms       0.000us         0.00%     196.566ms      98.283ms     128.25 Kb    -128.25 Kb           0 b    -257.00 Kb             2  \n",
            "                                             aten::item         0.10%     978.399us        43.14%     440.922ms     544.348us       0.000us         0.00%      12.736us       0.016us           0 b           0 b           0 b           0 b           810  \n",
            "                              aten::_local_scalar_dense         0.04%     384.565us        43.04%     439.944ms     543.140us      12.736us         0.00%      12.736us       0.016us           0 b           0 b           0 b           0 b           810  \n",
            "                                  cudaStreamSynchronize        42.99%     439.442ms        42.99%     439.442ms      36.620ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            12  \n",
            "                                  cudaDeviceSynchronize        20.71%     211.631ms        20.71%     211.631ms     211.631ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        14.58%     149.046ms        14.89%     152.236ms      76.118ms       0.000us         0.00%       0.000us       0.000us     256.50 Kb    -384.50 Kb           0 b           0 b             2  \n",
            "                                          backward_pass         7.76%      79.340ms         9.86%     100.740ms      50.370ms       0.000us         0.00%      13.846ms       6.923ms        -384 b        -384 b      -8.58 Gb      -8.58 Gb             2  \n",
            "                                           forward_pass         1.72%      17.569ms         4.66%      47.626ms      23.813ms       0.000us         0.00%     182.680ms      91.340ms         384 b           0 b       9.42 Gb      -2.43 Gb             2  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.34%       3.424ms         2.65%      27.105ms     183.142us       0.000us         0.00%     322.771ms       2.181ms           0 b           0 b      -2.77 Gb      -8.48 Gb           148  \n",
            "                              Optimizer.step#AdamW.step         1.09%      11.146ms         2.07%      21.160ms      10.580ms       0.000us         0.00%      13.843ms       6.922ms           0 b          -8 b           0 b    -837.02 Mb             2  \n",
            "                                         AddmmBackward0         0.23%       2.385ms         1.64%      16.746ms     113.148us       0.000us         0.00%     316.469ms       2.138ms           0 b           0 b       5.72 Gb           0 b           148  \n",
            "                                           aten::linear         0.16%       1.610ms         1.45%      14.801ms     100.007us       0.000us         0.00%     160.427ms       1.084ms           0 b           0 b       5.06 Gb           0 b           148  \n",
            "                                       cudaLaunchKernel         1.35%      13.748ms         1.35%      13.748ms       9.682us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1420  \n",
            "                                               aten::mm         0.74%       7.610ms         1.08%      11.046ms      37.316us     316.469ms        39.97%     316.469ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                            aten::addmm         0.66%       6.785ms         0.98%      10.067ms      68.023us     160.427ms        20.26%     160.427ms       1.084ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "     autograd::engine::evaluate_function: ViewBackward0         0.30%       3.029ms         0.78%       7.953ms      20.712us       0.000us         0.00%       4.271ms      11.123us           0 b           0 b      -2.25 Gb      -2.25 Gb           384  \n",
            "                                              aten::sum         0.45%       4.623ms         0.71%       7.293ms      41.911us       7.341ms         0.93%       7.341ms      42.188us           0 b           0 b      11.14 Mb      11.14 Mb           174  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.06%     625.621us         0.70%       7.133ms     297.224us       0.000us         0.00%      25.271ms       1.053ms        -384 b        -384 b      -1.15 Gb      -2.84 Gb            24  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.03%     258.572us         0.64%       6.508ms     271.156us       0.000us         0.00%      25.271ms       1.053ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.07%     722.734us         0.61%       6.249ms     260.383us       0.000us         0.00%      25.271ms       1.053ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.022s\n",
            "Self CUDA time total: 791.790ms\n",
            "\n",
            "Average training loss: 0.8406\n",
            "Validation Accuracy: 0.7180\n",
            "Macro F1: 0.6290\n",
            "Weighted F1: 0.7134\n",
            "Epoch 3/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch : 100%|██████████| 5022/5022 [26:27<00:00,  3.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.36%       3.714ms         2.54%      26.012ms     175.755us       0.000us         0.00%     322.790ms       2.181ms           0 b           0 b      -2.77 Gb      -8.48 Gb           148  \n",
            "                                         AddmmBackward0         0.22%       2.222ms         1.54%      15.779ms     106.616us       0.000us         0.00%     316.493ms       2.138ms           0 b           0 b       5.72 Gb           0 b           148  \n",
            "                                               aten::mm         0.70%       7.133ms         1.01%      10.330ms      34.899us     316.493ms        39.74%     316.493ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                          ProfilerStep*         0.53%       5.452ms        73.27%     751.714ms     375.857ms       0.000us         0.00%     196.537ms      98.268ms     128.25 Kb    -128.25 Kb           0 b    -257.00 Kb             2  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us     185.888ms        23.34%     185.888ms      92.944ms           0 b           0 b           0 b           0 b             2  \n",
            "                                           forward_pass         1.93%      19.763ms         5.39%      55.266ms      27.633ms       0.000us         0.00%     182.666ms      91.333ms         384 b           0 b       9.42 Gb      -2.43 Gb             2  \n",
            "                        ampere_sgemm_64x32_sliced1x4_nt         0.00%       0.000us         0.00%       0.000us       0.000us     168.315ms        21.13%     168.315ms     935.083us           0 b           0 b           0 b           0 b           180  \n",
            "                                           aten::linear         0.20%       2.011ms         1.71%      17.536ms     118.487us       0.000us         0.00%     160.431ms       1.084ms           0 b           0 b       5.06 Gb           0 b           148  \n",
            "                                            aten::addmm         0.76%       7.835ms         1.13%      11.543ms      77.993us     160.431ms        20.14%     160.431ms       1.084ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us     160.377ms        20.14%     160.377ms      80.189ms           0 b           0 b           0 b           0 b             2  \n",
            "                                 ampere_sgemm_128x32_nn         0.00%       0.000us         0.00%       0.000us       0.000us     158.873ms        19.95%     158.873ms     882.629us           0 b           0 b           0 b           0 b           180  \n",
            "                                 ampere_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us      74.563ms         9.36%      74.563ms       2.071ms           0 b           0 b           0 b           0 b            36  \n",
            "                                ampere_sgemm_128x128_nt         0.00%       0.000us         0.00%       0.000us       0.000us      72.825ms         9.14%      72.825ms       2.023ms           0 b           0 b           0 b           0 b            36  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us      68.498ms         8.60%      68.498ms       2.283ms           0 b           0 b           0 b           0 b            30  \n",
            "                                 ampere_sgemm_128x32_tn         0.00%       0.000us         0.00%       0.000us       0.000us      67.147ms         8.43%      67.147ms     578.854us           0 b           0 b           0 b           0 b           116  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us      62.456ms         7.84%      62.456ms       2.082ms           0 b           0 b           0 b           0 b            30  \n",
            "fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyT...         0.00%       0.000us         0.00%       0.000us       0.000us      34.168ms         4.29%      34.168ms     949.110us           0 b           0 b           0 b           0 b            36  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.06%     608.738us         0.69%       7.116ms     296.508us       0.000us         0.00%      25.288ms       1.054ms        -384 b        -384 b      -1.15 Gb      -2.84 Gb            24  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.02%     246.191us         0.63%       6.507ms     271.144us       0.000us         0.00%      25.288ms       1.054ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.07%     749.322us         0.61%       6.261ms     260.886us       0.000us         0.00%      25.288ms       1.054ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.026s\n",
            "Self CUDA time total: 796.455ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                            aten::empty         0.62%       6.339ms         0.62%       6.339ms       6.416us       0.000us         0.00%       0.000us       0.000us     384.51 Kb     384.51 Kb       6.84 Gb       6.84 Gb           988  \n",
            "                                               aten::mm         0.70%       7.133ms         1.01%      10.330ms      34.899us     316.493ms        39.74%     316.493ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                            aten::addmm         0.76%       7.835ms         1.13%      11.543ms      77.993us     160.431ms        20.14%     160.431ms       1.084ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "                                    aten::empty_strided         0.33%       3.381ms         0.33%       3.381ms       6.528us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       2.30 Gb       2.30 Gb           518  \n",
            "                                             aten::gelu         0.06%     639.338us         0.09%     934.716us      38.947us       3.412ms         0.43%       3.412ms     142.182us           0 b           0 b       2.25 Gb       2.25 Gb            24  \n",
            "                                    aten::gelu_backward         0.04%     412.342us         0.07%     667.432us      27.810us       5.106ms         0.64%       5.106ms     212.737us           0 b           0 b       2.25 Gb       2.25 Gb            24  \n",
            "                                              aten::add         0.11%       1.140ms         0.16%       1.633ms      32.662us       2.796ms         0.35%       2.796ms      55.922us           0 b           0 b       1.17 Gb       1.17 Gb            50  \n",
            "                                              aten::mul         0.03%     333.164us         0.06%     652.010us      27.167us       1.129ms         0.14%       1.129ms      47.031us           0 b           0 b     576.00 Mb     576.00 Mb            24  \n",
            "                                          aten::resize_         0.01%      71.486us         0.01%      71.486us       5.957us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      97.75 Mb      97.75 Mb            12  \n",
            "                                              aten::sub         0.01%      53.987us         0.01%      86.219us      43.110us      12.928us         0.00%      12.928us       6.464us           0 b           0 b      16.00 Mb      16.00 Mb             2  \n",
            "                                              aten::sum         0.43%       4.377ms         0.67%       6.889ms      39.594us       7.336ms         0.92%       7.336ms      42.163us           0 b           0 b      11.14 Mb      11.14 Mb           174  \n",
            "                                             aten::tanh         0.01%      72.429us         0.01%      97.106us      48.553us       5.057us         0.00%       5.057us       2.529us           0 b           0 b     192.00 Kb     192.00 Kb             2  \n",
            "                                    aten::tanh_backward         0.00%      37.432us         0.01%      70.245us      35.122us       4.064us         0.00%       4.064us       2.032us           0 b           0 b     192.00 Kb     192.00 Kb             2  \n",
            "                                               aten::eq         0.01%      79.792us         0.01%     107.642us      53.821us       5.471us         0.00%       5.471us       2.735us           0 b           0 b      16.00 Kb      16.00 Kb             2  \n",
            "                                     aten::_log_softmax         0.01%      69.328us         0.01%     111.242us      55.621us       4.800us         0.00%       4.800us       2.400us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                aten::nll_loss_backward         0.01%      74.025us         0.02%     180.067us      90.034us       4.704us         0.00%       8.224us       4.112us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                       aten::_log_softmax_backward_data         0.00%      40.968us         0.01%      59.663us      29.832us       4.640us         0.00%       4.640us       2.320us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                 aten::nll_loss_forward         0.01%      63.316us         0.01%      92.452us      46.226us       5.087us         0.00%       5.087us       2.543us           0 b           0 b       2.00 Kb       2.00 Kb             2  \n",
            "                                              aten::all         0.01%      74.197us         0.01%      99.239us      49.620us      10.560us         0.00%      10.560us       5.280us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
            "void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us       2.461ms         0.31%       2.461ms      37.859us           0 b           0 b           0 b           0 b            65  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.026s\n",
            "Self CUDA time total: 796.455ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.53%       5.452ms        73.27%     751.714ms     375.857ms       0.000us         0.00%     196.537ms      98.268ms     128.25 Kb    -128.25 Kb           0 b    -257.00 Kb             2  \n",
            "                                             aten::item         0.10%     988.983us        42.74%     438.446ms     541.291us       0.000us         0.00%      12.063us       0.015us           0 b           0 b           0 b           0 b           810  \n",
            "                              aten::_local_scalar_dense         0.06%     610.923us        42.64%     437.457ms     540.070us      12.063us         0.00%      12.063us       0.015us           0 b           0 b           0 b           0 b           810  \n",
            "                                  cudaStreamSynchronize        42.56%     436.571ms        42.56%     436.571ms      36.381ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            12  \n",
            "                                  cudaDeviceSynchronize        20.84%     213.819ms        20.84%     213.819ms     213.819ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        14.62%     150.029ms        15.00%     153.885ms      76.943ms       0.000us         0.00%       0.000us       0.000us     256.50 Kb    -384.50 Kb           0 b           0 b             2  \n",
            "                                          backward_pass         7.35%      75.426ms         9.53%      97.744ms      48.872ms       0.000us         0.00%      13.831ms       6.916ms        -384 b        -384 b      -8.58 Gb      -8.58 Gb             2  \n",
            "                                           forward_pass         1.93%      19.763ms         5.39%      55.266ms      27.633ms       0.000us         0.00%     182.666ms      91.333ms         384 b           0 b       9.42 Gb      -2.43 Gb             2  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.36%       3.714ms         2.54%      26.012ms     175.755us       0.000us         0.00%     322.790ms       2.181ms           0 b           0 b      -2.77 Gb      -8.48 Gb           148  \n",
            "                              Optimizer.step#AdamW.step         1.11%      11.394ms         2.15%      22.100ms      11.050ms       0.000us         0.00%      13.828ms       6.914ms           0 b          -8 b           0 b    -837.02 Mb             2  \n",
            "                                           aten::linear         0.20%       2.011ms         1.71%      17.536ms     118.487us       0.000us         0.00%     160.431ms       1.084ms           0 b           0 b       5.06 Gb           0 b           148  \n",
            "                                         AddmmBackward0         0.22%       2.222ms         1.54%      15.779ms     106.616us       0.000us         0.00%     316.493ms       2.138ms           0 b           0 b       5.72 Gb           0 b           148  \n",
            "                                       cudaLaunchKernel         1.36%      13.927ms         1.36%      13.927ms       9.808us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1420  \n",
            "                                            aten::addmm         0.76%       7.835ms         1.13%      11.543ms      77.993us     160.431ms        20.14%     160.431ms       1.084ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "                                               aten::mm         0.70%       7.133ms         1.01%      10.330ms      34.899us     316.493ms        39.74%     316.493ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "     autograd::engine::evaluate_function: ViewBackward0         0.28%       2.888ms         0.73%       7.492ms      19.509us       0.000us         0.00%       4.272ms      11.125us           0 b           0 b      -2.25 Gb      -2.25 Gb           384  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.06%     608.738us         0.69%       7.116ms     296.508us       0.000us         0.00%      25.288ms       1.054ms        -384 b        -384 b      -1.15 Gb      -2.84 Gb            24  \n",
            "                                              aten::sum         0.43%       4.377ms         0.67%       6.889ms      39.594us       7.336ms         0.92%       7.336ms      42.163us           0 b           0 b      11.14 Mb      11.14 Mb           174  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.02%     246.191us         0.63%       6.507ms     271.144us       0.000us         0.00%      25.288ms       1.054ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "                                            aten::empty         0.62%       6.339ms         0.62%       6.339ms       6.416us       0.000us         0.00%       0.000us       0.000us     384.51 Kb     384.51 Kb       6.84 Gb       6.84 Gb           988  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.026s\n",
            "Self CUDA time total: 796.455ms\n",
            "\n",
            "Average training loss: 0.6209\n",
            "Validation Accuracy: 0.7224\n",
            "Macro F1: 0.6336\n",
            "Weighted F1: 0.7181\n",
            "Epoch 4/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch : 100%|██████████| 5022/5022 [26:29<00:00,  3.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.32%       3.310ms         2.51%      25.799ms     174.318us       0.000us         0.00%     322.771ms       2.181ms           0 b           0 b      -2.77 Gb      -8.48 Gb           148  \n",
            "                                         AddmmBackward0         0.22%       2.247ms         1.54%      15.879ms     107.291us       0.000us         0.00%     316.487ms       2.138ms           0 b           0 b       5.72 Gb           0 b           148  \n",
            "                                               aten::mm         0.70%       7.224ms         1.01%      10.371ms      35.038us     316.487ms        39.59%     316.487ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                          ProfilerStep*         0.49%       5.036ms        73.41%     755.362ms     377.681ms       0.000us         0.00%     196.596ms      98.298ms      64.25 Kb    -192.25 Kb           0 b    -257.00 Kb             2  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us     185.678ms        23.23%     185.678ms      92.839ms           0 b           0 b           0 b           0 b             2  \n",
            "                                           forward_pass         1.83%      18.843ms         4.86%      50.014ms      25.007ms       0.000us         0.00%     182.670ms      91.335ms         384 b           0 b       9.42 Gb      -2.43 Gb             2  \n",
            "                        ampere_sgemm_64x32_sliced1x4_nt         0.00%       0.000us         0.00%       0.000us       0.000us     168.313ms        21.05%     168.313ms     935.074us           0 b           0 b           0 b           0 b           180  \n",
            "                                           aten::linear         0.16%       1.637ms         1.49%      15.330ms     103.578us       0.000us         0.00%     160.439ms       1.084ms           0 b           0 b       5.06 Gb           0 b           148  \n",
            "                                            aten::addmm         0.67%       6.933ms         1.00%      10.341ms      69.870us     160.439ms        20.07%     160.439ms       1.084ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us     159.372ms        19.94%     159.372ms      79.686ms           0 b           0 b           0 b           0 b             2  \n",
            "                                 ampere_sgemm_128x32_nn         0.00%       0.000us         0.00%       0.000us       0.000us     158.879ms        19.87%     158.879ms     882.660us           0 b           0 b           0 b           0 b           180  \n",
            "                                 ampere_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us      74.567ms         9.33%      74.567ms       2.071ms           0 b           0 b           0 b           0 b            36  \n",
            "                                ampere_sgemm_128x128_nt         0.00%       0.000us         0.00%       0.000us       0.000us      72.827ms         9.11%      72.827ms       2.023ms           0 b           0 b           0 b           0 b            36  \n",
            "                                 ampere_sgemm_128x32_tn         0.00%       0.000us         0.00%       0.000us       0.000us      69.461ms         8.69%      69.461ms     578.841us           0 b           0 b           0 b           0 b           120  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us      68.496ms         8.57%      68.496ms       2.283ms           0 b           0 b           0 b           0 b            30  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us      62.464ms         7.81%      62.464ms       2.082ms           0 b           0 b           0 b           0 b            30  \n",
            "fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyT...         0.00%       0.000us         0.00%       0.000us       0.000us      34.165ms         4.27%      34.165ms     949.038us           0 b           0 b           0 b           0 b            36  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.06%     657.715us         0.70%       7.158ms     298.248us       0.000us         0.00%      25.286ms       1.054ms        -384 b        -384 b      -1.15 Gb      -2.84 Gb            24  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.03%     268.353us         0.63%       6.500ms     270.843us       0.000us         0.00%      25.286ms       1.054ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.07%     703.977us         0.61%       6.232ms     259.662us       0.000us         0.00%      25.286ms       1.054ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.029s\n",
            "Self CUDA time total: 799.456ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                            aten::empty         0.57%       5.904ms         0.57%       5.904ms       5.975us       0.000us         0.00%       0.000us       0.000us     384.51 Kb     384.51 Kb       6.84 Gb       6.84 Gb           988  \n",
            "                                               aten::mm         0.70%       7.224ms         1.01%      10.371ms      35.038us     316.487ms        39.59%     316.487ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                            aten::addmm         0.67%       6.933ms         1.00%      10.341ms      69.870us     160.439ms        20.07%     160.439ms       1.084ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "                                    aten::empty_strided         0.31%       3.203ms         0.31%       3.203ms       6.184us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       2.30 Gb       2.30 Gb           518  \n",
            "                                             aten::gelu         0.05%     546.346us         0.08%     817.447us      34.060us       3.411ms         0.43%       3.411ms     142.131us           0 b           0 b       2.25 Gb       2.25 Gb            24  \n",
            "                                    aten::gelu_backward         0.04%     413.172us         0.06%     665.715us      27.738us       5.109ms         0.64%       5.109ms     212.866us           0 b           0 b       2.25 Gb       2.25 Gb            24  \n",
            "                                              aten::add         0.10%       1.036ms         0.15%       1.494ms      29.879us       2.795ms         0.35%       2.795ms      55.906us           0 b           0 b       1.17 Gb       1.17 Gb            50  \n",
            "                                              aten::mul         0.03%     340.421us         0.06%     664.538us      27.689us       1.130ms         0.14%       1.130ms      47.100us           0 b           0 b     576.00 Mb     576.00 Mb            24  \n",
            "                                          aten::resize_         0.01%      72.251us         0.01%      72.251us       6.021us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      97.75 Mb      97.75 Mb            12  \n",
            "                                              aten::sub         0.00%      45.562us         0.01%      72.020us      36.010us      13.344us         0.00%      13.344us       6.672us           0 b           0 b      16.00 Mb      16.00 Mb             2  \n",
            "                                              aten::sum         0.43%       4.395ms         0.68%       6.971ms      40.063us       7.324ms         0.92%       7.324ms      42.092us           0 b           0 b      11.14 Mb      11.14 Mb           174  \n",
            "                                             aten::tanh         0.01%      53.891us         0.01%      75.734us      37.867us       5.024us         0.00%       5.024us       2.512us           0 b           0 b     192.00 Kb     192.00 Kb             2  \n",
            "                                    aten::tanh_backward         0.00%      34.375us         0.01%      53.540us      26.770us       4.097us         0.00%       4.097us       2.049us           0 b           0 b     192.00 Kb     192.00 Kb             2  \n",
            "                                               aten::eq         0.01%      75.391us         0.01%     104.714us      52.357us       5.728us         0.00%       5.728us       2.864us           0 b           0 b      16.00 Kb      16.00 Kb             2  \n",
            "                                     aten::_log_softmax         0.01%      57.398us         0.01%      86.548us      43.274us       4.800us         0.00%       4.800us       2.400us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                aten::nll_loss_backward         0.01%      76.310us         0.02%     174.532us      87.266us       4.801us         0.00%       8.321us       4.160us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                       aten::_log_softmax_backward_data         0.00%      35.380us         0.01%      53.426us      26.713us       4.608us         0.00%       4.608us       2.304us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                 aten::nll_loss_forward         0.01%      56.336us         0.01%      77.976us      38.988us       5.120us         0.00%       5.120us       2.560us           0 b           0 b       2.00 Kb       2.00 Kb             2  \n",
            "                                              aten::all         0.01%      59.842us         0.01%      85.058us      42.529us      10.369us         0.00%      10.369us       5.184us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
            "                                             aten::item         0.10%     990.887us        43.48%     447.445ms     552.402us       0.000us         0.00%      12.193us       0.015us           0 b           0 b           0 b           0 b           810  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.029s\n",
            "Self CUDA time total: 799.456ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.49%       5.036ms        73.41%     755.362ms     377.681ms       0.000us         0.00%     196.596ms      98.298ms      64.25 Kb    -192.25 Kb           0 b    -257.00 Kb             2  \n",
            "                                             aten::item         0.10%     990.887us        43.48%     447.445ms     552.402us       0.000us         0.00%      12.193us       0.015us           0 b           0 b           0 b           0 b           810  \n",
            "                              aten::_local_scalar_dense         0.04%     401.674us        43.39%     446.454ms     551.178us      12.193us         0.00%      12.193us       0.015us           0 b           0 b           0 b           0 b           810  \n",
            "                                  cudaStreamSynchronize        43.34%     445.977ms        43.34%     445.977ms      37.165ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            12  \n",
            "                                  cudaDeviceSynchronize        20.72%     213.218ms        20.72%     213.218ms     213.218ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        14.63%     150.510ms        14.97%     154.033ms      77.017ms       0.000us         0.00%       0.000us       0.000us     256.50 Kb    -384.50 Kb           0 b           0 b             2  \n",
            "                                          backward_pass         7.45%      76.636ms         9.52%      98.008ms      49.004ms       0.000us         0.00%      13.886ms       6.943ms        -384 b        -384 b      -8.58 Gb      -8.58 Gb             2  \n",
            "                                           forward_pass         1.83%      18.843ms         4.86%      50.014ms      25.007ms       0.000us         0.00%     182.670ms      91.335ms         384 b           0 b       9.42 Gb      -2.43 Gb             2  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.32%       3.310ms         2.51%      25.799ms     174.318us       0.000us         0.00%     322.771ms       2.181ms           0 b           0 b      -2.77 Gb      -8.48 Gb           148  \n",
            "                              Optimizer.step#AdamW.step         1.09%      11.244ms         2.06%      21.194ms      10.597ms       0.000us         0.00%      13.883ms       6.942ms           0 b          -8 b           0 b    -837.02 Mb             2  \n",
            "                                         AddmmBackward0         0.22%       2.247ms         1.54%      15.879ms     107.291us       0.000us         0.00%     316.487ms       2.138ms           0 b           0 b       5.72 Gb           0 b           148  \n",
            "                                           aten::linear         0.16%       1.637ms         1.49%      15.330ms     103.578us       0.000us         0.00%     160.439ms       1.084ms           0 b           0 b       5.06 Gb           0 b           148  \n",
            "                                       cudaLaunchKernel         1.31%      13.479ms         1.31%      13.479ms       9.493us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1420  \n",
            "                                               aten::mm         0.70%       7.224ms         1.01%      10.371ms      35.038us     316.487ms        39.59%     316.487ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                            aten::addmm         0.67%       6.933ms         1.00%      10.341ms      69.870us     160.439ms        20.07%     160.439ms       1.084ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "     autograd::engine::evaluate_function: ViewBackward0         0.29%       2.939ms         0.74%       7.623ms      19.851us       0.000us         0.00%       4.272ms      11.124us           0 b           0 b      -2.25 Gb      -2.25 Gb           384  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.06%     657.715us         0.70%       7.158ms     298.248us       0.000us         0.00%      25.286ms       1.054ms        -384 b        -384 b      -1.15 Gb      -2.84 Gb            24  \n",
            "                                              aten::sum         0.43%       4.395ms         0.68%       6.971ms      40.063us       7.324ms         0.92%       7.324ms      42.092us           0 b           0 b      11.14 Mb      11.14 Mb           174  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.03%     268.353us         0.63%       6.500ms     270.843us       0.000us         0.00%      25.286ms       1.054ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.07%     703.977us         0.61%       6.232ms     259.662us       0.000us         0.00%      25.286ms       1.054ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.029s\n",
            "Self CUDA time total: 799.456ms\n",
            "\n",
            "Average training loss: 0.4479\n",
            "Validation Accuracy: 0.7167\n",
            "Macro F1: 0.6303\n",
            "Weighted F1: 0.7140\n",
            "Epoch 5/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch : 100%|██████████| 5022/5022 [26:29<00:00,  3.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.32%       3.254ms         2.49%      25.663ms     173.395us       0.000us         0.00%     322.766ms       2.181ms           0 b           0 b      -2.77 Gb      -8.48 Gb           148  \n",
            "                                         AddmmBackward0         0.22%       2.247ms         1.53%      15.811ms     106.830us       0.000us         0.00%     316.481ms       2.138ms           0 b           0 b       5.72 Gb           0 b           148  \n",
            "                                               aten::mm         0.70%       7.188ms         1.00%      10.340ms      34.932us     316.481ms        39.59%     316.481ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                          ProfilerStep*         0.48%       4.994ms        73.53%     758.534ms     379.267ms       0.000us         0.00%     196.544ms      98.272ms     128.25 Kb    -128.25 Kb           0 b    -257.00 Kb             2  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us     185.395ms        23.19%     185.395ms      92.698ms           0 b           0 b           0 b           0 b             2  \n",
            "                                           forward_pass         1.73%      17.856ms         4.70%      48.491ms      24.245ms       0.000us         0.00%     182.670ms      91.335ms         384 b           0 b       9.42 Gb      -2.43 Gb             2  \n",
            "                        ampere_sgemm_64x32_sliced1x4_nt         0.00%       0.000us         0.00%       0.000us       0.000us     168.303ms        21.05%     168.303ms     935.018us           0 b           0 b           0 b           0 b           180  \n",
            "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us     162.631ms        20.35%     162.631ms      81.316ms           0 b           0 b           0 b           0 b             2  \n",
            "                                           aten::linear         0.16%       1.623ms         1.46%      15.076ms     101.863us       0.000us         0.00%     160.429ms       1.084ms           0 b           0 b       5.06 Gb           0 b           148  \n",
            "                                            aten::addmm         0.67%       6.878ms         0.99%      10.167ms      68.693us     160.429ms        20.07%     160.429ms       1.084ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "                                 ampere_sgemm_128x32_nn         0.00%       0.000us         0.00%       0.000us       0.000us     158.875ms        19.88%     158.875ms     882.641us           0 b           0 b           0 b           0 b           180  \n",
            "                                 ampere_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us      74.562ms         9.33%      74.562ms       2.071ms           0 b           0 b           0 b           0 b            36  \n",
            "                                ampere_sgemm_128x128_nt         0.00%       0.000us         0.00%       0.000us       0.000us      72.823ms         9.11%      72.823ms       2.023ms           0 b           0 b           0 b           0 b            36  \n",
            "                                 ampere_sgemm_128x32_tn         0.00%       0.000us         0.00%       0.000us       0.000us      69.459ms         8.69%      69.459ms     578.827us           0 b           0 b           0 b           0 b           120  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us      68.485ms         8.57%      68.485ms       2.283ms           0 b           0 b           0 b           0 b            30  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us      62.456ms         7.81%      62.456ms       2.082ms           0 b           0 b           0 b           0 b            30  \n",
            "fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyT...         0.00%       0.000us         0.00%       0.000us       0.000us      34.152ms         4.27%      34.152ms     948.679us           0 b           0 b           0 b           0 b            36  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.06%     643.324us         0.69%       7.167ms     298.624us       0.000us         0.00%      25.278ms       1.053ms        -384 b        -384 b      -1.15 Gb      -2.84 Gb            24  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.03%     268.603us         0.63%       6.524ms     271.819us       0.000us         0.00%      25.278ms       1.053ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.07%     704.490us         0.61%       6.255ms     260.627us       0.000us         0.00%      25.278ms       1.053ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.032s\n",
            "Self CUDA time total: 799.355ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                            aten::empty         0.57%       5.879ms         0.57%       5.879ms       5.950us       0.000us         0.00%       0.000us       0.000us     384.51 Kb     384.51 Kb       6.84 Gb       6.84 Gb           988  \n",
            "                                               aten::mm         0.70%       7.188ms         1.00%      10.340ms      34.932us     316.481ms        39.59%     316.481ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                            aten::addmm         0.67%       6.878ms         0.99%      10.167ms      68.693us     160.429ms        20.07%     160.429ms       1.084ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "                                    aten::empty_strided         0.32%       3.259ms         0.32%       3.259ms       6.291us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       2.30 Gb       2.30 Gb           518  \n",
            "                                             aten::gelu         0.05%     544.147us         0.08%     827.737us      34.489us       3.411ms         0.43%       3.411ms     142.135us           0 b           0 b       2.25 Gb       2.25 Gb            24  \n",
            "                                    aten::gelu_backward         0.04%     410.006us         0.06%     658.984us      27.458us       5.109ms         0.64%       5.109ms     212.882us           0 b           0 b       2.25 Gb       2.25 Gb            24  \n",
            "                                              aten::add         0.10%       1.044ms         0.14%       1.496ms      29.912us       2.795ms         0.35%       2.795ms      55.905us           0 b           0 b       1.17 Gb       1.17 Gb            50  \n",
            "                                              aten::mul         0.03%     353.362us         0.07%     676.356us      28.182us       1.129ms         0.14%       1.129ms      47.041us           0 b           0 b     576.00 Mb     576.00 Mb            24  \n",
            "                                          aten::resize_         0.01%      66.994us         0.01%      66.994us       5.583us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      97.75 Mb      97.75 Mb            12  \n",
            "                                              aten::sub         0.00%      49.080us         0.01%      72.916us      36.458us      13.056us         0.00%      13.056us       6.528us           0 b           0 b      16.00 Mb      16.00 Mb             2  \n",
            "                                              aten::sum         0.44%       4.503ms         0.68%       6.984ms      40.137us       7.325ms         0.92%       7.325ms      42.099us           0 b           0 b      11.14 Mb      11.14 Mb           174  \n",
            "                                             aten::tanh         0.01%      53.230us         0.01%      73.847us      36.924us       5.056us         0.00%       5.056us       2.528us           0 b           0 b     192.00 Kb     192.00 Kb             2  \n",
            "                                    aten::tanh_backward         0.00%      33.645us         0.01%      52.364us      26.182us       4.096us         0.00%       4.096us       2.048us           0 b           0 b     192.00 Kb     192.00 Kb             2  \n",
            "                                               aten::eq         0.01%      70.644us         0.01%      96.251us      48.125us       5.537us         0.00%       5.537us       2.768us           0 b           0 b      16.00 Kb      16.00 Kb             2  \n",
            "                                     aten::_log_softmax         0.01%      58.441us         0.01%      87.312us      43.656us       4.864us         0.00%       4.864us       2.432us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                aten::nll_loss_backward         0.01%      64.914us         0.02%     156.690us      78.345us       4.671us         0.00%       8.191us       4.095us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                       aten::_log_softmax_backward_data         0.00%      35.152us         0.01%      53.494us      26.747us       4.640us         0.00%       4.640us       2.320us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                 aten::nll_loss_forward         0.01%      69.459us         0.01%      90.615us      45.307us       5.120us         0.00%       5.120us       2.560us           0 b           0 b       2.00 Kb       2.00 Kb             2  \n",
            "                                              aten::all         0.01%      59.211us         0.01%      82.897us      41.448us      10.433us         0.00%      10.433us       5.216us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
            "                                             aten::item         0.10%     988.281us        43.50%     448.715ms     553.969us       0.000us         0.00%      12.415us       0.015us           0 b           0 b           0 b           0 b           810  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.032s\n",
            "Self CUDA time total: 799.355ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.48%       4.994ms        73.53%     758.534ms     379.267ms       0.000us         0.00%     196.544ms      98.272ms     128.25 Kb    -128.25 Kb           0 b    -257.00 Kb             2  \n",
            "                                             aten::item         0.10%     988.281us        43.50%     448.715ms     553.969us       0.000us         0.00%      12.415us       0.015us           0 b           0 b           0 b           0 b           810  \n",
            "                              aten::_local_scalar_dense         0.04%     397.363us        43.40%     447.726ms     552.748us      12.415us         0.00%      12.415us       0.015us           0 b           0 b           0 b           0 b           810  \n",
            "                                  cudaStreamSynchronize        43.35%     447.258ms        43.35%     447.258ms      37.272ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            12  \n",
            "                                  cudaDeviceSynchronize        20.63%     212.831ms        20.63%     212.831ms     212.831ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        14.92%     153.967ms        15.25%     157.337ms      78.669ms       0.000us         0.00%       0.000us       0.000us     256.50 Kb    -384.50 Kb           0 b           0 b             2  \n",
            "                                          backward_pass         7.42%      76.566ms         9.52%      98.234ms      49.117ms       0.000us         0.00%      13.834ms       6.917ms        -384 b        -384 b      -8.58 Gb      -8.58 Gb             2  \n",
            "                                           forward_pass         1.73%      17.856ms         4.70%      48.491ms      24.245ms       0.000us         0.00%     182.670ms      91.335ms         384 b           0 b       9.42 Gb      -2.43 Gb             2  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.32%       3.254ms         2.49%      25.663ms     173.395us       0.000us         0.00%     322.766ms       2.181ms           0 b           0 b      -2.77 Gb      -8.48 Gb           148  \n",
            "                              Optimizer.step#AdamW.step         1.10%      11.345ms         2.08%      21.437ms      10.719ms       0.000us         0.00%      13.832ms       6.916ms           0 b          -8 b           0 b    -837.02 Mb             2  \n",
            "                                         AddmmBackward0         0.22%       2.247ms         1.53%      15.811ms     106.830us       0.000us         0.00%     316.481ms       2.138ms           0 b           0 b       5.72 Gb           0 b           148  \n",
            "                                           aten::linear         0.16%       1.623ms         1.46%      15.076ms     101.863us       0.000us         0.00%     160.429ms       1.084ms           0 b           0 b       5.06 Gb           0 b           148  \n",
            "                                       cudaLaunchKernel         1.28%      13.225ms         1.28%      13.225ms       9.313us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1420  \n",
            "                                               aten::mm         0.70%       7.188ms         1.00%      10.340ms      34.932us     316.481ms        39.59%     316.481ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                            aten::addmm         0.67%       6.878ms         0.99%      10.167ms      68.693us     160.429ms        20.07%     160.429ms       1.084ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "     autograd::engine::evaluate_function: ViewBackward0         0.28%       2.910ms         0.74%       7.652ms      19.928us       0.000us         0.00%       4.276ms      11.135us           0 b           0 b      -2.25 Gb      -2.25 Gb           384  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.06%     643.324us         0.69%       7.167ms     298.624us       0.000us         0.00%      25.278ms       1.053ms        -384 b        -384 b      -1.15 Gb      -2.84 Gb            24  \n",
            "                                              aten::sum         0.44%       4.503ms         0.68%       6.984ms      40.137us       7.325ms         0.92%       7.325ms      42.099us           0 b           0 b      11.14 Mb      11.14 Mb           174  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.03%     268.603us         0.63%       6.524ms     271.819us       0.000us         0.00%      25.278ms       1.053ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.07%     704.490us         0.61%       6.255ms     260.627us       0.000us         0.00%      25.278ms       1.053ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.032s\n",
            "Self CUDA time total: 799.355ms\n",
            "\n",
            "Average training loss: 0.3183\n",
            "Validation Accuracy: 0.7159\n",
            "Macro F1: 0.6261\n",
            "Weighted F1: 0.7118\n",
            "Epoch 6/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch : 100%|██████████| 5022/5022 [26:29<00:00,  3.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.40%       4.143ms         2.84%      29.095ms     196.587us       0.000us         0.00%     322.583ms       2.180ms           0 b           0 b      -2.77 Gb      -8.48 Gb           148  \n",
            "                                         AddmmBackward0         0.26%       2.711ms         1.73%      17.750ms     119.931us       0.000us         0.00%     316.290ms       2.137ms           0 b           0 b       5.72 Gb           0 b           148  \n",
            "                                               aten::mm         0.76%       7.787ms         1.10%      11.242ms      37.981us     316.290ms        39.59%     316.290ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                          ProfilerStep*         0.51%       5.195ms        72.61%     743.431ms     371.716ms       0.000us         0.00%     196.436ms      98.218ms     128.25 Kb    -128.25 Kb           0 b    -257.00 Kb             2  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us     185.293ms        23.19%     185.293ms      92.647ms           0 b           0 b           0 b           0 b             2  \n",
            "                                           forward_pass         1.88%      19.260ms         4.92%      50.415ms      25.207ms       0.000us         0.00%     182.573ms      91.287ms         384 b           0 b       9.42 Gb      -2.43 Gb             2  \n",
            "                        ampere_sgemm_64x32_sliced1x4_nt         0.00%       0.000us         0.00%       0.000us       0.000us     168.106ms        21.04%     168.106ms     933.922us           0 b           0 b           0 b           0 b           180  \n",
            "                                           aten::linear         0.16%       1.619ms         1.48%      15.179ms     102.563us       0.000us         0.00%     160.343ms       1.083ms           0 b           0 b       5.06 Gb           0 b           148  \n",
            "                                            aten::addmm         0.67%       6.878ms         1.00%      10.229ms      69.112us     160.343ms        20.07%     160.343ms       1.083ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "                                 ampere_sgemm_128x32_nn         0.00%       0.000us         0.00%       0.000us       0.000us     158.851ms        19.88%     158.851ms     882.505us           0 b           0 b           0 b           0 b           180  \n",
            "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us     144.404ms        18.07%     144.404ms      72.202ms           0 b           0 b           0 b           0 b             2  \n",
            "                                 ampere_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us      74.520ms         9.33%      74.520ms       2.070ms           0 b           0 b           0 b           0 b            36  \n",
            "                                ampere_sgemm_128x128_nt         0.00%       0.000us         0.00%       0.000us       0.000us      72.807ms         9.11%      72.807ms       2.022ms           0 b           0 b           0 b           0 b            36  \n",
            "                                 ampere_sgemm_128x32_tn         0.00%       0.000us         0.00%       0.000us       0.000us      69.436ms         8.69%      69.436ms     578.636us           0 b           0 b           0 b           0 b           120  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us      68.460ms         8.57%      68.460ms       2.282ms           0 b           0 b           0 b           0 b            30  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us      62.401ms         7.81%      62.401ms       2.080ms           0 b           0 b           0 b           0 b            30  \n",
            "fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyT...         0.00%       0.000us         0.00%       0.000us       0.000us      34.148ms         4.27%      34.148ms     948.559us           0 b           0 b           0 b           0 b            36  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.07%     724.641us         0.79%       8.098ms     337.432us       0.000us         0.00%      25.265ms       1.053ms        -384 b        -384 b      -1.15 Gb      -2.84 Gb            24  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.03%     304.247us         0.72%       7.374ms     307.239us       0.000us         0.00%      25.265ms       1.053ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.08%     801.075us         0.69%       7.069ms     294.562us       0.000us         0.00%      25.265ms       1.053ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.024s\n",
            "Self CUDA time total: 798.994ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                            aten::empty         0.63%       6.415ms         0.63%       6.415ms       6.493us       0.000us         0.00%       0.000us       0.000us     384.51 Kb     384.51 Kb       6.84 Gb       6.84 Gb           988  \n",
            "                                               aten::mm         0.76%       7.787ms         1.10%      11.242ms      37.981us     316.290ms        39.59%     316.290ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                            aten::addmm         0.67%       6.878ms         1.00%      10.229ms      69.112us     160.343ms        20.07%     160.343ms       1.083ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "                                    aten::empty_strided         0.32%       3.232ms         0.32%       3.232ms       6.239us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       2.30 Gb       2.30 Gb           518  \n",
            "                                             aten::gelu         0.06%     588.149us         0.08%     864.212us      36.009us       3.414ms         0.43%       3.414ms     142.251us           0 b           0 b       2.25 Gb       2.25 Gb            24  \n",
            "                                    aten::gelu_backward         0.04%     428.231us         0.07%     709.095us      29.546us       5.109ms         0.64%       5.109ms     212.864us           0 b           0 b       2.25 Gb       2.25 Gb            24  \n",
            "                                              aten::add         0.10%       1.046ms         0.15%       1.517ms      30.339us       2.794ms         0.35%       2.794ms      55.884us           0 b           0 b       1.17 Gb       1.17 Gb            50  \n",
            "                                              aten::mul         0.04%     363.432us         0.07%     704.225us      29.343us       1.129ms         0.14%       1.129ms      47.040us           0 b           0 b     576.00 Mb     576.00 Mb            24  \n",
            "                                          aten::resize_         0.01%      67.900us         0.01%      67.900us       5.658us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      97.75 Mb      97.75 Mb            12  \n",
            "                                              aten::sub         0.00%      45.194us         0.01%      85.669us      42.835us      13.312us         0.00%      13.312us       6.656us           0 b           0 b      16.00 Mb      16.00 Mb             2  \n",
            "                                              aten::sum         0.47%       4.833ms         0.74%       7.574ms      43.529us       7.333ms         0.92%       7.333ms      42.143us           0 b           0 b      11.14 Mb      11.14 Mb           174  \n",
            "                                             aten::tanh         0.01%      54.068us         0.01%      76.421us      38.210us       5.024us         0.00%       5.024us       2.512us           0 b           0 b     192.00 Kb     192.00 Kb             2  \n",
            "                                    aten::tanh_backward         0.00%      34.413us         0.01%      54.349us      27.174us       4.096us         0.00%       4.096us       2.048us           0 b           0 b     192.00 Kb     192.00 Kb             2  \n",
            "                                               aten::eq         0.01%      72.230us         0.01%      97.629us      48.814us       5.567us         0.00%       5.567us       2.783us           0 b           0 b      16.00 Kb      16.00 Kb             2  \n",
            "                                     aten::_log_softmax         0.01%      65.656us         0.01%      95.573us      47.787us       4.832us         0.00%       4.832us       2.416us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                aten::nll_loss_backward         0.01%      71.597us         0.02%     202.576us     101.288us       4.671us         0.00%       8.191us       4.095us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                       aten::_log_softmax_backward_data         0.00%      36.367us         0.01%      55.310us      27.655us       4.640us         0.00%       4.640us       2.320us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                 aten::nll_loss_forward         0.01%      54.722us         0.01%      75.399us      37.699us       5.087us         0.00%       5.087us       2.544us           0 b           0 b       2.00 Kb       2.00 Kb             2  \n",
            "                                              aten::all         0.01%      58.600us         0.01%      83.575us      41.787us      10.400us         0.00%      10.400us       5.200us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
            "                                             aten::item         0.10%       1.027ms        42.89%     439.162ms     542.176us       0.000us         0.00%      11.968us       0.015us           0 b           0 b           0 b           0 b           810  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.024s\n",
            "Self CUDA time total: 798.994ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.51%       5.195ms        72.61%     743.431ms     371.716ms       0.000us         0.00%     196.436ms      98.218ms     128.25 Kb    -128.25 Kb           0 b    -257.00 Kb             2  \n",
            "                                             aten::item         0.10%       1.027ms        42.89%     439.162ms     542.176us       0.000us         0.00%      11.968us       0.015us           0 b           0 b           0 b           0 b           810  \n",
            "                              aten::_local_scalar_dense         0.04%     376.145us        42.79%     438.135ms     540.908us      11.968us         0.00%      11.968us       0.015us           0 b           0 b           0 b           0 b           810  \n",
            "                                  cudaStreamSynchronize        42.75%     437.697ms        42.75%     437.697ms      36.475ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            12  \n",
            "                                  cudaDeviceSynchronize        20.61%     211.009ms        20.61%     211.009ms     211.009ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        13.25%     135.688ms        13.57%     138.992ms      69.496ms       0.000us         0.00%       0.000us       0.000us     256.50 Kb    -384.50 Kb           0 b           0 b             2  \n",
            "                                          backward_pass         8.43%      86.332ms        10.55%     107.988ms      53.994ms       0.000us         0.00%      13.822ms       6.911ms        -384 b        -384 b      -8.58 Gb      -8.58 Gb             2  \n",
            "                                           forward_pass         1.88%      19.260ms         4.92%      50.415ms      25.207ms       0.000us         0.00%     182.573ms      91.287ms         384 b           0 b       9.42 Gb      -2.43 Gb             2  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.40%       4.143ms         2.84%      29.095ms     196.587us       0.000us         0.00%     322.583ms       2.180ms           0 b           0 b      -2.77 Gb      -8.48 Gb           148  \n",
            "                              Optimizer.step#AdamW.step         1.11%      11.318ms         2.10%      21.527ms      10.763ms       0.000us         0.00%      13.820ms       6.910ms           0 b          -8 b           0 b    -837.02 Mb             2  \n",
            "                                         AddmmBackward0         0.26%       2.711ms         1.73%      17.750ms     119.931us       0.000us         0.00%     316.290ms       2.137ms           0 b           0 b       5.72 Gb           0 b           148  \n",
            "                                           aten::linear         0.16%       1.619ms         1.48%      15.179ms     102.563us       0.000us         0.00%     160.343ms       1.083ms           0 b           0 b       5.06 Gb           0 b           148  \n",
            "                                       cudaLaunchKernel         1.39%      14.219ms         1.39%      14.219ms      10.014us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1420  \n",
            "                                               aten::mm         0.76%       7.787ms         1.10%      11.242ms      37.981us     316.290ms        39.59%     316.290ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                            aten::addmm         0.67%       6.878ms         1.00%      10.229ms      69.112us     160.343ms        20.07%     160.343ms       1.083ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "     autograd::engine::evaluate_function: ViewBackward0         0.35%       3.588ms         0.89%       9.072ms      23.624us       0.000us         0.00%       4.273ms      11.128us           0 b           0 b      -2.25 Gb      -2.25 Gb           384  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.07%     724.641us         0.79%       8.098ms     337.432us       0.000us         0.00%      25.265ms       1.053ms        -384 b        -384 b      -1.15 Gb      -2.84 Gb            24  \n",
            "                                              aten::sum         0.47%       4.833ms         0.74%       7.574ms      43.529us       7.333ms         0.92%       7.333ms      42.143us           0 b           0 b      11.14 Mb      11.14 Mb           174  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.03%     304.247us         0.72%       7.374ms     307.239us       0.000us         0.00%      25.265ms       1.053ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.08%     801.075us         0.69%       7.069ms     294.562us       0.000us         0.00%      25.265ms       1.053ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.024s\n",
            "Self CUDA time total: 798.994ms\n",
            "\n",
            "Average training loss: 0.2270\n",
            "Validation Accuracy: 0.7126\n",
            "Macro F1: 0.6271\n",
            "Weighted F1: 0.7110\n",
            "Epoch 7/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch : 100%|██████████| 5022/5022 [26:29<00:00,  3.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.32%       3.274ms         2.54%      25.715ms     173.748us       0.000us         0.00%     322.750ms       2.181ms           0 b           0 b      -2.77 Gb      -8.48 Gb           148  \n",
            "                                         AddmmBackward0         0.22%       2.278ms         1.56%      15.819ms     106.885us       0.000us         0.00%     316.457ms       2.138ms           0 b           0 b       5.72 Gb           0 b           148  \n",
            "                                               aten::mm         0.71%       7.182ms         1.01%      10.274ms      34.711us     316.457ms        39.59%     316.457ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                          ProfilerStep*         0.50%       5.075ms        73.03%     739.654ms     369.827ms       0.000us         0.00%     196.537ms      98.268ms     128.25 Kb    -128.25 Kb           0 b    -257.00 Kb             2  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us     185.381ms        23.19%     185.381ms      92.690ms           0 b           0 b           0 b           0 b             2  \n",
            "                                           forward_pass         1.76%      17.807ms         4.77%      48.344ms      24.172ms       0.000us         0.00%     182.660ms      91.330ms         384 b           0 b       9.42 Gb      -2.43 Gb             2  \n",
            "                        ampere_sgemm_64x32_sliced1x4_nt         0.00%       0.000us         0.00%       0.000us       0.000us     168.272ms        21.05%     168.272ms     934.846us           0 b           0 b           0 b           0 b           180  \n",
            "                                           aten::linear         0.16%       1.602ms         1.49%      15.057ms     101.738us       0.000us         0.00%     160.426ms       1.084ms           0 b           0 b       5.06 Gb           0 b           148  \n",
            "                                            aten::addmm         0.68%       6.855ms         1.00%      10.160ms      68.646us     160.426ms        20.07%     160.426ms       1.084ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "                                 ampere_sgemm_128x32_nn         0.00%       0.000us         0.00%       0.000us       0.000us     158.882ms        19.88%     158.882ms     882.679us           0 b           0 b           0 b           0 b           180  \n",
            "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us     144.256ms        18.05%     144.256ms      72.128ms           0 b           0 b           0 b           0 b             2  \n",
            "                                 ampere_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us      74.561ms         9.33%      74.561ms       2.071ms           0 b           0 b           0 b           0 b            36  \n",
            "                                ampere_sgemm_128x128_nt         0.00%       0.000us         0.00%       0.000us       0.000us      72.823ms         9.11%      72.823ms       2.023ms           0 b           0 b           0 b           0 b            36  \n",
            "                                 ampere_sgemm_128x32_tn         0.00%       0.000us         0.00%       0.000us       0.000us      69.438ms         8.69%      69.438ms     578.652us           0 b           0 b           0 b           0 b           120  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us      68.502ms         8.57%      68.502ms       2.283ms           0 b           0 b           0 b           0 b            30  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us      62.456ms         7.81%      62.456ms       2.082ms           0 b           0 b           0 b           0 b            30  \n",
            "fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyT...         0.00%       0.000us         0.00%       0.000us       0.000us      34.138ms         4.27%      34.138ms     948.286us           0 b           0 b           0 b           0 b            36  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.06%     635.035us         0.71%       7.147ms     297.811us       0.000us         0.00%      25.261ms       1.053ms        -384 b        -384 b      -1.15 Gb      -2.84 Gb            24  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.03%     277.414us         0.64%       6.512ms     271.351us       0.000us         0.00%      25.261ms       1.053ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.07%     707.454us         0.62%       6.235ms     259.792us       0.000us         0.00%      25.261ms       1.053ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.013s\n",
            "Self CUDA time total: 799.295ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                            aten::empty         0.58%       5.909ms         0.58%       5.909ms       5.981us       0.000us         0.00%       0.000us       0.000us     384.51 Kb     384.51 Kb       6.84 Gb       6.84 Gb           988  \n",
            "                                               aten::mm         0.71%       7.182ms         1.01%      10.274ms      34.711us     316.457ms        39.59%     316.457ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                            aten::addmm         0.68%       6.855ms         1.00%      10.160ms      68.646us     160.426ms        20.07%     160.426ms       1.084ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "                                    aten::empty_strided         0.33%       3.336ms         0.33%       3.336ms       6.441us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       2.30 Gb       2.30 Gb           518  \n",
            "                                             aten::gelu         0.06%     558.362us         0.08%     830.268us      34.595us       3.413ms         0.43%       3.413ms     142.211us           0 b           0 b       2.25 Gb       2.25 Gb            24  \n",
            "                                    aten::gelu_backward         0.04%     392.365us         0.06%     635.896us      26.496us       5.109ms         0.64%       5.109ms     212.888us           0 b           0 b       2.25 Gb       2.25 Gb            24  \n",
            "                                              aten::add         0.10%       1.024ms         0.15%       1.491ms      29.822us       2.797ms         0.35%       2.797ms      55.942us           0 b           0 b       1.17 Gb       1.17 Gb            50  \n",
            "                                              aten::mul         0.03%     346.148us         0.06%     649.655us      27.069us       1.130ms         0.14%       1.130ms      47.087us           0 b           0 b     576.00 Mb     576.00 Mb            24  \n",
            "                                          aten::resize_         0.01%      65.934us         0.01%      65.934us       5.494us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      97.75 Mb      97.75 Mb            12  \n",
            "                                              aten::sub         0.00%      45.634us         0.01%      71.072us      35.536us      13.280us         0.00%      13.280us       6.640us           0 b           0 b      16.00 Mb      16.00 Mb             2  \n",
            "                                              aten::sum         0.44%       4.435ms         0.69%       6.940ms      39.886us       7.331ms         0.92%       7.331ms      42.130us           0 b           0 b      11.14 Mb      11.14 Mb           174  \n",
            "                                             aten::tanh         0.01%      55.804us         0.01%      77.717us      38.859us       5.023us         0.00%       5.023us       2.512us           0 b           0 b     192.00 Kb     192.00 Kb             2  \n",
            "                                    aten::tanh_backward         0.00%      34.700us         0.01%      54.857us      27.429us       4.096us         0.00%       4.096us       2.048us           0 b           0 b     192.00 Kb     192.00 Kb             2  \n",
            "                                               aten::eq         0.01%      71.332us         0.01%      96.568us      48.284us       5.536us         0.00%       5.536us       2.768us           0 b           0 b      16.00 Kb      16.00 Kb             2  \n",
            "                                     aten::_log_softmax         0.01%      59.947us         0.01%      89.213us      44.606us       4.800us         0.00%       4.800us       2.400us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                aten::nll_loss_backward         0.01%      67.719us         0.02%     173.840us      86.920us       4.640us         0.00%       8.160us       4.080us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                       aten::_log_softmax_backward_data         0.00%      36.495us         0.01%      57.411us      28.705us       4.640us         0.00%       4.640us       2.320us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                 aten::nll_loss_forward         0.01%      53.344us         0.01%      73.816us      36.908us       5.247us         0.00%       5.247us       2.624us           0 b           0 b       2.00 Kb       2.00 Kb             2  \n",
            "                                              aten::all         0.01%      59.178us         0.01%      97.777us      48.889us      10.432us         0.00%      10.432us       5.216us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
            "                                             aten::item         0.10%       1.037ms        44.19%     447.613ms     552.609us       0.000us         0.00%      12.033us       0.015us           0 b           0 b           0 b           0 b           810  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.013s\n",
            "Self CUDA time total: 799.295ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.50%       5.075ms        73.03%     739.654ms     369.827ms       0.000us         0.00%     196.537ms      98.268ms     128.25 Kb    -128.25 Kb           0 b    -257.00 Kb             2  \n",
            "                                             aten::item         0.10%       1.037ms        44.19%     447.613ms     552.609us       0.000us         0.00%      12.033us       0.015us           0 b           0 b           0 b           0 b           810  \n",
            "                              aten::_local_scalar_dense         0.04%     390.363us        44.09%     446.577ms     551.329us      12.033us         0.00%      12.033us       0.015us           0 b           0 b           0 b           0 b           810  \n",
            "                                  cudaStreamSynchronize        44.05%     446.118ms        44.05%     446.118ms      37.176ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            12  \n",
            "                                  cudaDeviceSynchronize        21.01%     212.765ms        21.01%     212.765ms     212.765ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        13.38%     135.488ms        13.71%     138.907ms      69.454ms       0.000us         0.00%       0.000us       0.000us     256.50 Kb    -384.50 Kb           0 b           0 b             2  \n",
            "                                          backward_pass         7.60%      76.987ms         9.78%      99.031ms      49.516ms       0.000us         0.00%      13.838ms       6.919ms        -384 b        -384 b      -8.58 Gb      -8.58 Gb             2  \n",
            "                                           forward_pass         1.76%      17.807ms         4.77%      48.344ms      24.172ms       0.000us         0.00%     182.660ms      91.330ms         384 b           0 b       9.42 Gb      -2.43 Gb             2  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.32%       3.274ms         2.54%      25.715ms     173.748us       0.000us         0.00%     322.750ms       2.181ms           0 b           0 b      -2.77 Gb      -8.48 Gb           148  \n",
            "                              Optimizer.step#AdamW.step         1.14%      11.581ms         2.15%      21.739ms      10.870ms       0.000us         0.00%      13.835ms       6.918ms           0 b          -8 b           0 b    -837.02 Mb             2  \n",
            "                                         AddmmBackward0         0.22%       2.278ms         1.56%      15.819ms     106.885us       0.000us         0.00%     316.457ms       2.138ms           0 b           0 b       5.72 Gb           0 b           148  \n",
            "                                           aten::linear         0.16%       1.602ms         1.49%      15.057ms     101.738us       0.000us         0.00%     160.426ms       1.084ms           0 b           0 b       5.06 Gb           0 b           148  \n",
            "                                       cudaLaunchKernel         1.32%      13.385ms         1.32%      13.385ms       9.426us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1420  \n",
            "                                               aten::mm         0.71%       7.182ms         1.01%      10.274ms      34.711us     316.457ms        39.59%     316.457ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                            aten::addmm         0.68%       6.855ms         1.00%      10.160ms      68.646us     160.426ms        20.07%     160.426ms       1.084ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "     autograd::engine::evaluate_function: ViewBackward0         0.30%       3.028ms         0.76%       7.668ms      19.969us       0.000us         0.00%       4.271ms      11.123us           0 b           0 b      -2.25 Gb      -2.25 Gb           384  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.06%     635.035us         0.71%       7.147ms     297.811us       0.000us         0.00%      25.261ms       1.053ms        -384 b        -384 b      -1.15 Gb      -2.84 Gb            24  \n",
            "                                              aten::sum         0.44%       4.435ms         0.69%       6.940ms      39.886us       7.331ms         0.92%       7.331ms      42.130us           0 b           0 b      11.14 Mb      11.14 Mb           174  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.03%     277.414us         0.64%       6.512ms     271.351us       0.000us         0.00%      25.261ms       1.053ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.07%     707.454us         0.62%       6.235ms     259.792us       0.000us         0.00%      25.261ms       1.053ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.013s\n",
            "Self CUDA time total: 799.295ms\n",
            "\n",
            "Average training loss: 0.1663\n",
            "Validation Accuracy: 0.7125\n",
            "Macro F1: 0.6247\n",
            "Weighted F1: 0.7098\n",
            "Epoch 8/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch : 100%|██████████| 5022/5022 [26:29<00:00,  3.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.33%       3.387ms         2.53%      26.049ms     176.005us       0.000us         0.00%     322.775ms       2.181ms           0 b           0 b      -2.77 Gb      -8.48 Gb           148  \n",
            "                                         AddmmBackward0         0.22%       2.271ms         1.55%      15.946ms     107.747us       0.000us         0.00%     316.480ms       2.138ms           0 b           0 b       5.72 Gb           0 b           148  \n",
            "                                               aten::mm         0.70%       7.217ms         1.01%      10.390ms      35.101us     316.480ms        39.59%     316.480ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                          ProfilerStep*         0.47%       4.850ms        73.43%     756.400ms     378.200ms       0.000us         0.00%     196.531ms      98.265ms     128.25 Kb    -128.25 Kb           0 b    -257.00 Kb             2  \n",
            "                                           forward_pass         0.00%       0.000us         0.00%       0.000us       0.000us     185.313ms        23.18%     185.313ms      92.656ms           0 b           0 b           0 b           0 b             2  \n",
            "                                           forward_pass         1.88%      19.407ms         4.87%      50.205ms      25.102ms       0.000us         0.00%     182.642ms      91.321ms         384 b           0 b       9.42 Gb      -2.43 Gb             2  \n",
            "                        ampere_sgemm_64x32_sliced1x4_nt         0.00%       0.000us         0.00%       0.000us       0.000us     168.291ms        21.05%     168.291ms     934.948us           0 b           0 b           0 b           0 b           180  \n",
            "                                           aten::linear         0.16%       1.614ms         1.48%      15.224ms     102.866us       0.000us         0.00%     160.405ms       1.084ms           0 b           0 b       5.06 Gb           0 b           148  \n",
            "                                            aten::addmm         0.67%       6.897ms         1.00%      10.296ms      69.566us     160.405ms        20.07%     160.405ms       1.084ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us     160.254ms        20.05%     160.254ms      80.127ms           0 b           0 b           0 b           0 b             2  \n",
            "                                 ampere_sgemm_128x32_nn         0.00%       0.000us         0.00%       0.000us       0.000us     158.885ms        19.88%     158.885ms     882.695us           0 b           0 b           0 b           0 b           180  \n",
            "                                 ampere_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us      74.568ms         9.33%      74.568ms       2.071ms           0 b           0 b           0 b           0 b            36  \n",
            "                                ampere_sgemm_128x128_nt         0.00%       0.000us         0.00%       0.000us       0.000us      72.825ms         9.11%      72.825ms       2.023ms           0 b           0 b           0 b           0 b            36  \n",
            "                                 ampere_sgemm_128x32_tn         0.00%       0.000us         0.00%       0.000us       0.000us      69.445ms         8.69%      69.445ms     578.707us           0 b           0 b           0 b           0 b           120  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us      68.474ms         8.57%      68.474ms       2.282ms           0 b           0 b           0 b           0 b            30  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us      62.463ms         7.81%      62.463ms       2.082ms           0 b           0 b           0 b           0 b            30  \n",
            "fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyT...         0.00%       0.000us         0.00%       0.000us       0.000us      34.156ms         4.27%      34.156ms     948.785us           0 b           0 b           0 b           0 b            36  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.06%     620.096us         0.69%       7.068ms     294.493us       0.000us         0.00%      25.272ms       1.053ms        -384 b        -384 b      -1.15 Gb      -2.84 Gb            24  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.03%     262.682us         0.63%       6.448ms     268.656us       0.000us         0.00%      25.272ms       1.053ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.07%     686.905us         0.60%       6.185ms     257.711us       0.000us         0.00%      25.272ms       1.053ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.030s\n",
            "Self CUDA time total: 799.370ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                            aten::empty         0.58%       5.989ms         0.58%       5.989ms       6.061us       0.000us         0.00%       0.000us       0.000us     384.51 Kb     384.51 Kb       6.84 Gb       6.84 Gb           988  \n",
            "                                               aten::mm         0.70%       7.217ms         1.01%      10.390ms      35.101us     316.480ms        39.59%     316.480ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                            aten::addmm         0.67%       6.897ms         1.00%      10.296ms      69.566us     160.405ms        20.07%     160.405ms       1.084ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "                                    aten::empty_strided         0.31%       3.220ms         0.31%       3.220ms       6.216us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       2.30 Gb       2.30 Gb           518  \n",
            "                                             aten::gelu         0.05%     540.075us         0.08%     810.876us      33.786us       3.411ms         0.43%       3.411ms     142.104us           0 b           0 b       2.25 Gb       2.25 Gb            24  \n",
            "                                    aten::gelu_backward         0.04%     411.553us         0.07%     686.109us      28.588us       5.108ms         0.64%       5.108ms     212.829us           0 b           0 b       2.25 Gb       2.25 Gb            24  \n",
            "                                              aten::add         0.10%       1.023ms         0.15%       1.498ms      29.966us       2.797ms         0.35%       2.797ms      55.932us           0 b           0 b       1.17 Gb       1.17 Gb            50  \n",
            "                                              aten::mul         0.03%     333.621us         0.06%     641.640us      26.735us       1.129ms         0.14%       1.129ms      47.044us           0 b           0 b     576.00 Mb     576.00 Mb            24  \n",
            "                                          aten::resize_         0.01%      78.224us         0.01%      78.224us       6.519us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      97.75 Mb      97.75 Mb            12  \n",
            "                                              aten::sub         0.00%      42.767us         0.01%      65.079us      32.540us      13.120us         0.00%      13.120us       6.560us           0 b           0 b      16.00 Mb      16.00 Mb             2  \n",
            "                                              aten::sum         0.44%       4.517ms         0.68%       7.050ms      40.515us       7.332ms         0.92%       7.332ms      42.139us           0 b           0 b      11.14 Mb      11.14 Mb           174  \n",
            "                                             aten::tanh         0.01%      53.157us         0.01%      74.311us      37.155us       5.024us         0.00%       5.024us       2.512us           0 b           0 b     192.00 Kb     192.00 Kb             2  \n",
            "                                    aten::tanh_backward         0.00%      35.933us         0.01%      54.552us      27.276us       4.096us         0.00%       4.096us       2.048us           0 b           0 b     192.00 Kb     192.00 Kb             2  \n",
            "                                               aten::eq         0.01%      70.955us         0.01%      95.359us      47.679us       5.440us         0.00%       5.440us       2.720us           0 b           0 b      16.00 Kb      16.00 Kb             2  \n",
            "                                     aten::_log_softmax         0.01%      55.706us         0.01%      83.889us      41.944us       4.801us         0.00%       4.801us       2.400us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                aten::nll_loss_backward         0.01%      67.499us         0.02%     174.086us      87.043us       4.672us         0.00%       8.192us       4.096us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                       aten::_log_softmax_backward_data         0.00%      40.815us         0.01%      60.435us      30.217us       4.608us         0.00%       4.608us       2.304us           0 b           0 b      10.00 Kb      10.00 Kb             2  \n",
            "                                 aten::nll_loss_forward         0.01%      53.868us         0.01%      75.236us      37.618us       5.120us         0.00%       5.120us       2.560us           0 b           0 b       2.00 Kb       2.00 Kb             2  \n",
            "                                              aten::all         0.01%      61.787us         0.01%     108.352us      54.176us      10.432us         0.00%      10.432us       5.216us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
            "                                             aten::item         0.10%       1.008ms        43.31%     446.175ms     550.833us       0.000us         0.00%      12.095us       0.015us           0 b           0 b           0 b           0 b           810  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.030s\n",
            "Self CUDA time total: 799.370ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.47%       4.850ms        73.43%     756.400ms     378.200ms       0.000us         0.00%     196.531ms      98.265ms     128.25 Kb    -128.25 Kb           0 b    -257.00 Kb             2  \n",
            "                                             aten::item         0.10%       1.008ms        43.31%     446.175ms     550.833us       0.000us         0.00%      12.095us       0.015us           0 b           0 b           0 b           0 b           810  \n",
            "                              aten::_local_scalar_dense         0.04%     382.144us        43.22%     445.166ms     549.588us      12.095us         0.00%      12.095us       0.015us           0 b           0 b           0 b           0 b           810  \n",
            "                                  cudaStreamSynchronize        43.17%     444.719ms        43.17%     444.719ms      37.060ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            12  \n",
            "                                  cudaDeviceSynchronize        20.64%     212.615ms        20.64%     212.615ms     212.615ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        14.72%     151.620ms        15.06%     155.118ms      77.559ms       0.000us         0.00%       0.000us       0.000us     256.50 Kb    -384.50 Kb           0 b           0 b             2  \n",
            "                                          backward_pass         7.56%      77.843ms         9.64%      99.295ms      49.647ms       0.000us         0.00%      13.849ms       6.924ms        -384 b        -384 b      -8.58 Gb      -8.58 Gb             2  \n",
            "                                           forward_pass         1.88%      19.407ms         4.87%      50.205ms      25.102ms       0.000us         0.00%     182.642ms      91.321ms         384 b           0 b       9.42 Gb      -2.43 Gb             2  \n",
            "    autograd::engine::evaluate_function: AddmmBackward0         0.33%       3.387ms         2.53%      26.049ms     176.005us       0.000us         0.00%     322.775ms       2.181ms           0 b           0 b      -2.77 Gb      -8.48 Gb           148  \n",
            "                              Optimizer.step#AdamW.step         1.08%      11.176ms         2.06%      21.265ms      10.632ms       0.000us         0.00%      13.846ms       6.923ms           0 b          -8 b           0 b    -837.02 Mb             2  \n",
            "                                         AddmmBackward0         0.22%       2.271ms         1.55%      15.946ms     107.747us       0.000us         0.00%     316.480ms       2.138ms           0 b           0 b       5.72 Gb           0 b           148  \n",
            "                                           aten::linear         0.16%       1.614ms         1.48%      15.224ms     102.866us       0.000us         0.00%     160.405ms       1.084ms           0 b           0 b       5.06 Gb           0 b           148  \n",
            "                                       cudaLaunchKernel         1.32%      13.598ms         1.32%      13.598ms       9.576us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1420  \n",
            "                                               aten::mm         0.70%       7.217ms         1.01%      10.390ms      35.101us     316.480ms        39.59%     316.480ms       1.069ms           0 b           0 b       5.72 Gb       5.72 Gb           296  \n",
            "                                            aten::addmm         0.67%       6.897ms         1.00%      10.296ms      69.566us     160.405ms        20.07%     160.405ms       1.084ms           0 b           0 b       5.06 Gb       4.92 Gb           148  \n",
            "     autograd::engine::evaluate_function: ViewBackward0         0.29%       3.012ms         0.75%       7.767ms      20.226us       0.000us         0.00%       4.272ms      11.125us           0 b           0 b      -2.25 Gb      -2.25 Gb           384  \n",
            "autograd::engine::evaluate_function: ScaledDotProduc...         0.06%     620.096us         0.69%       7.068ms     294.493us       0.000us         0.00%      25.272ms       1.053ms        -384 b        -384 b      -1.15 Gb      -2.84 Gb            24  \n",
            "                                              aten::sum         0.44%       4.517ms         0.68%       7.050ms      40.515us       7.332ms         0.92%       7.332ms      42.139us           0 b           0 b      11.14 Mb      11.14 Mb           174  \n",
            "            ScaledDotProductEfficientAttentionBackward0         0.03%     262.682us         0.63%       6.448ms     268.656us       0.000us         0.00%      25.272ms       1.053ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "aten::_scaled_dot_product_efficient_attention_backwa...         0.07%     686.905us         0.60%       6.185ms     257.711us       0.000us         0.00%      25.272ms       1.053ms           0 b           0 b       1.69 Gb           0 b            24  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.030s\n",
            "Self CUDA time total: 799.370ms\n",
            "\n",
            "Average training loss: 0.1288\n",
            "Validation Accuracy: 0.7125\n",
            "Macro F1: 0.6239\n",
            "Weighted F1: 0.7093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cs4-8so_K8xM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"bert_classifier.pth\")"
      ],
      "metadata": {
        "id": "xafaZKrkzyqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts, labels, label_classes = load_news_data(\"/content/drive/MyDrive/News_Category_Dataset_v2.json\")\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.classes_ = np.array(label_classes)\n",
        "\n",
        "test_text = \"NASA launches new space telescope to explore exoplanets.\"\n",
        "predicted_category = predict_news_category(test_text, model, tokenizer, device, encoder)\n",
        "\n",
        "print(f\"Headline: {test_text}\")\n",
        "print(f\"Predicted Category: {predicted_category}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu-ZX1FUf5_0",
        "outputId": "5767d3a9-fd11-441c-91f2-4ea44fea5f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset contains 40 unique categories.\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.42%     389.949us        99.99%      92.103ms      18.421ms       0.000us         0.00%      21.438ms       4.288ms           0 b           0 b           0 b           0 b             5  \n",
            "                                      model_inference_2         0.00%       0.000us         0.00%       0.000us       0.000us      19.819ms        92.45%      19.819ms      19.819ms           0 b           0 b           0 b           0 b             1  \n",
            "                                      model_inference_3         0.00%       0.000us         0.00%       0.000us       0.000us      18.177ms        84.79%      18.177ms      18.177ms           0 b           0 b           0 b           0 b             1  \n",
            "                                           aten::linear         4.45%       4.096ms        33.91%      31.237ms      84.424us       0.000us         0.00%      17.741ms      47.948us           0 b           0 b     202.52 Mb           0 b           370  \n",
            "                                            aten::addmm        15.01%      13.828ms        23.26%      21.422ms      57.896us      17.741ms        82.75%      17.741ms      47.948us           0 b           0 b     202.52 Mb    -167.48 Mb           370  \n",
            "                                      model_inference_4         0.00%       0.000us         0.00%       0.000us       0.000us      17.738ms        82.74%      17.738ms      17.738ms           0 b           0 b           0 b           0 b             1  \n",
            "                                      model_inference_5         0.00%       0.000us         0.00%       0.000us       0.000us      17.304ms        80.71%      17.304ms      17.304ms           0 b           0 b           0 b           0 b             1  \n",
            "                                      model_inference_6         0.00%       0.000us         0.00%       0.000us       0.000us      17.036ms        79.47%      17.036ms      17.036ms           0 b           0 b           0 b           0 b             1  \n",
            "                        ampere_sgemm_32x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us       8.941ms        41.70%       8.941ms      37.253us           0 b           0 b           0 b           0 b           240  \n",
            "                        ampere_sgemm_64x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us       4.905ms        22.88%       4.905ms      81.752us           0 b           0 b           0 b           0 b            60  \n",
            "                                      model_inference_6         7.03%       6.476ms        18.79%      17.311ms      17.311ms       0.000us         0.00%       4.295ms       4.295ms           0 b           0 b           0 b     -83.09 Mb             1  \n",
            "                                      model_inference_3         7.58%       6.981ms        20.09%      18.502ms      18.502ms       0.000us         0.00%       4.287ms       4.287ms           0 b           0 b           0 b     -83.09 Mb             1  \n",
            "                                      model_inference_4         7.45%       6.863ms        19.56%      18.021ms      18.021ms       0.000us         0.00%       4.287ms       4.287ms           0 b           0 b           0 b     -83.09 Mb             1  \n",
            "                                      model_inference_2         9.43%       8.688ms        22.04%      20.299ms      20.299ms       0.000us         0.00%       4.285ms       4.285ms           0 b           0 b           0 b     -83.09 Mb             1  \n",
            "                                      model_inference_5         7.28%       6.708ms        19.09%      17.580ms      17.580ms       0.000us         0.00%       4.285ms       4.285ms           0 b           0 b           0 b     -83.09 Mb             1  \n",
            "                       ampere_sgemm_128x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us       3.726ms        17.38%       3.726ms      62.097us           0 b           0 b           0 b           0 b            60  \n",
            "                     aten::scaled_dot_product_attention         1.05%     963.879us         6.64%       6.114ms     101.902us       0.000us         0.00%       1.849ms      30.817us           0 b        -960 b      22.50 Mb           0 b            60  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.84%     770.450us         5.17%       4.762ms      79.369us       0.000us         0.00%       1.849ms      30.817us         960 b           0 b      22.50 Mb           0 b            60  \n",
            "                     aten::_efficient_attention_forward         1.33%       1.224ms         3.41%       3.142ms      52.364us       1.849ms         8.62%       1.849ms      30.817us         960 b           0 b      22.50 Mb           0 b            60  \n",
            "fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEf...         0.00%       0.000us         0.00%       0.000us       0.000us       1.849ms         8.62%       1.849ms      30.817us           0 b           0 b           0 b           0 b            60  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 92.116ms\n",
            "Self CUDA time total: 21.438ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                            aten::empty         6.68%       6.153ms         6.68%       6.153ms       6.123us       0.000us         0.00%       0.000us       0.000us         960 b         960 b     439.81 Mb     439.81 Mb          1005  \n",
            "                                             aten::gelu         1.24%       1.140ms         1.95%       1.792ms      29.865us     262.145us         1.22%     262.145us       4.369us           0 b           0 b      90.00 Mb      90.00 Mb            60  \n",
            "                                              aten::add         2.59%       2.389ms         4.07%       3.745ms      29.962us     402.085us         1.88%     402.085us       3.217us           0 b           0 b      46.88 Mb      46.88 Mb           125  \n",
            "                                          aten::resize_         0.10%      90.311us         0.10%      90.311us       6.021us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       5.62 Mb       5.62 Mb            15  \n",
            "                                    aten::empty_strided         0.09%      82.382us         0.09%      82.382us       8.238us       0.000us         0.00%       0.000us       0.000us           0 b           0 b     400.00 Kb     400.00 Kb            10  \n",
            "                                              aten::sub         0.09%      82.268us         0.14%     125.137us      25.027us      12.832us         0.06%      12.832us       2.566us           0 b           0 b     320.00 Kb     320.00 Kb             5  \n",
            "                                             aten::tanh         0.10%      88.918us         0.15%     139.917us      27.983us      14.975us         0.07%      14.975us       2.995us           0 b           0 b      15.00 Kb      15.00 Kb             5  \n",
            "                                              aten::max         0.18%     163.160us         0.24%     224.839us      44.968us      30.528us         0.14%      30.528us       6.106us           0 b           0 b       5.00 Kb       5.00 Kb             5  \n",
            "                                               aten::eq         0.15%     140.044us         0.22%     198.126us      39.625us      12.032us         0.06%      12.032us       2.406us           0 b           0 b       2.50 Kb       2.50 Kb             5  \n",
            "                                              aten::all         0.13%     123.026us         0.19%     173.182us      34.636us      24.898us         0.12%      24.898us       4.980us           0 b           0 b       2.50 Kb       2.50 Kb             5  \n",
            "                                          ProfilerStep*         0.42%     389.949us        99.99%      92.103ms      18.421ms       0.000us         0.00%      21.438ms       4.288ms           0 b           0 b           0 b           0 b             5  \n",
            "                                            aten::slice         0.27%     244.692us         0.31%     284.966us       8.142us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            35  \n",
            "                                       aten::as_strided         1.28%       1.183ms         1.28%       1.183ms       1.201us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           985  \n",
            "                                           aten::expand         0.41%     379.798us         0.49%     451.581us       6.451us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            70  \n",
            "                                        aten::embedding         0.14%     132.957us         0.94%     868.923us      57.928us       0.000us         0.00%      83.903us       5.594us           0 b           0 b       5.62 Mb           0 b            15  \n",
            "                                          aten::reshape         1.12%       1.033ms         2.30%       2.114ms       4.860us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           435  \n",
            "                                             aten::view         2.75%       2.532ms         2.75%       2.532ms       2.042us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1240  \n",
            "                                     aten::index_select         0.27%     252.776us         0.72%     664.308us      44.287us      83.903us         0.39%      83.903us       5.594us           0 b           0 b       5.62 Mb           0 b            15  \n",
            "                                       cudaLaunchKernel         9.71%       8.942ms         9.71%       8.942ms      11.108us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           805  \n",
            "                                      model_inference_2         0.00%       0.000us         0.00%       0.000us       0.000us      19.819ms        92.45%      19.819ms      19.819ms           0 b           0 b           0 b           0 b             1  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 92.116ms\n",
            "Self CUDA time total: 21.438ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.42%     389.949us        99.99%      92.103ms      18.421ms       0.000us         0.00%      21.438ms       4.288ms           0 b           0 b           0 b           0 b             5  \n",
            "                                           aten::linear         4.45%       4.096ms        33.91%      31.237ms      84.424us       0.000us         0.00%      17.741ms      47.948us           0 b           0 b     202.52 Mb           0 b           370  \n",
            "                                            aten::addmm        15.01%      13.828ms        23.26%      21.422ms      57.896us      17.741ms        82.75%      17.741ms      47.948us           0 b           0 b     202.52 Mb    -167.48 Mb           370  \n",
            "                                      model_inference_2         9.43%       8.688ms        22.04%      20.299ms      20.299ms       0.000us         0.00%       4.285ms       4.285ms           0 b           0 b           0 b     -83.09 Mb             1  \n",
            "                                      model_inference_3         7.58%       6.981ms        20.09%      18.502ms      18.502ms       0.000us         0.00%       4.287ms       4.287ms           0 b           0 b           0 b     -83.09 Mb             1  \n",
            "                                      model_inference_4         7.45%       6.863ms        19.56%      18.021ms      18.021ms       0.000us         0.00%       4.287ms       4.287ms           0 b           0 b           0 b     -83.09 Mb             1  \n",
            "                                      model_inference_5         7.28%       6.708ms        19.09%      17.580ms      17.580ms       0.000us         0.00%       4.285ms       4.285ms           0 b           0 b           0 b     -83.09 Mb             1  \n",
            "                                      model_inference_6         7.03%       6.476ms        18.79%      17.311ms      17.311ms       0.000us         0.00%       4.295ms       4.295ms           0 b           0 b           0 b     -83.09 Mb             1  \n",
            "                                       cudaLaunchKernel         9.71%       8.942ms         9.71%       8.942ms      11.108us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           805  \n",
            "                                       aten::layer_norm         0.78%     716.515us         8.36%       7.704ms      61.636us       0.000us         0.00%     894.884us       7.159us           0 b           0 b      46.88 Mb    -123.00 Kb           125  \n",
            "                                aten::native_layer_norm         3.25%       2.990ms         7.59%       6.988ms      55.904us     894.884us         4.17%     894.884us       7.159us           0 b           0 b      47.00 Mb           0 b           125  \n",
            "                                            aten::empty         6.68%       6.153ms         6.68%       6.153ms       6.123us       0.000us         0.00%       0.000us       0.000us         960 b         960 b     439.81 Mb     439.81 Mb          1005  \n",
            "                     aten::scaled_dot_product_attention         1.05%     963.879us         6.64%       6.114ms     101.902us       0.000us         0.00%       1.849ms      30.817us           0 b        -960 b      22.50 Mb           0 b            60  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.84%     770.450us         5.17%       4.762ms      79.369us       0.000us         0.00%       1.849ms      30.817us         960 b           0 b      22.50 Mb           0 b            60  \n",
            "                                              aten::add         2.59%       2.389ms         4.07%       3.745ms      29.962us     402.085us         1.88%     402.085us       3.217us           0 b           0 b      46.88 Mb      46.88 Mb           125  \n",
            "                                                aten::t         1.43%       1.314ms         3.42%       3.152ms       8.519us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           370  \n",
            "                     aten::_efficient_attention_forward         1.33%       1.224ms         3.41%       3.142ms      52.364us       1.849ms         8.62%       1.849ms      30.817us         960 b           0 b      22.50 Mb           0 b            60  \n",
            "                                        aten::transpose         2.36%       2.173ms         3.22%       2.962ms       4.420us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           670  \n",
            "                                             aten::view         2.75%       2.532ms         2.75%       2.532ms       2.042us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1240  \n",
            "                                          aten::reshape         1.12%       1.033ms         2.30%       2.114ms       4.860us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           435  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 92.116ms\n",
            "Self CUDA time total: 21.438ms\n",
            "\n",
            "✅ Warmup profiling done. Use TensorBoard:\n",
            "\n",
            "  %tensorboard --logdir=./log_predict_base_warmup\n",
            "Headline: NASA launches new space telescope to explore exoplanets.\n",
            "Predicted Category: SCIENCE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f9JHNiEW59m_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}