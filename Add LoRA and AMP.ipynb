{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f473a14147e34a8f9f1990245744f3ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a58a48976cab417cb2a40c2d7aaaaadd",
              "IPY_MODEL_48018e91458442bdb3b6b13c158ae535",
              "IPY_MODEL_574de5bd969346e083e1c5c08027c712"
            ],
            "layout": "IPY_MODEL_6fa8d724ef4f4cc49bf13d517a98169d"
          }
        },
        "a58a48976cab417cb2a40c2d7aaaaadd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07e39c7c8021408bba9cd9b31eca2fde",
            "placeholder": "​",
            "style": "IPY_MODEL_9eeba7fedb1942c298adade8710aa9c8",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "48018e91458442bdb3b6b13c158ae535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e1df5b5be234746a0d845faeb58f335",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9e1a3d5d38943f999764ea28c3721b5",
            "value": 48
          }
        },
        "574de5bd969346e083e1c5c08027c712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_353991ffbe7d4b54bf1b0c6317738c49",
            "placeholder": "​",
            "style": "IPY_MODEL_741e5eeed18b43a4b39afd6994f96e17",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.02kB/s]"
          }
        },
        "6fa8d724ef4f4cc49bf13d517a98169d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07e39c7c8021408bba9cd9b31eca2fde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9eeba7fedb1942c298adade8710aa9c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e1df5b5be234746a0d845faeb58f335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9e1a3d5d38943f999764ea28c3721b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "353991ffbe7d4b54bf1b0c6317738c49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "741e5eeed18b43a4b39afd6994f96e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d2bc78b2d23462ab404c744c42b91d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f286ab6ceb5f48f1a9c76a4bff49e199",
              "IPY_MODEL_d0093dfd225947f89702b9a5aedefd7f",
              "IPY_MODEL_b6401a52430c417093ad62f4a94a3e82"
            ],
            "layout": "IPY_MODEL_37b622c31720473bbd3bded7eed38a9f"
          }
        },
        "f286ab6ceb5f48f1a9c76a4bff49e199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_896d02dd03cb4fb9a1427c178c53f3b3",
            "placeholder": "​",
            "style": "IPY_MODEL_c9faefaaad634dba9900d8683796e803",
            "value": "vocab.txt: 100%"
          }
        },
        "d0093dfd225947f89702b9a5aedefd7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3430847defd747adacfd9b246742f299",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ab8315b4efe449497d9ee4c2fa9790f",
            "value": 231508
          }
        },
        "b6401a52430c417093ad62f4a94a3e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_184d27ca3fc3408f880c9af0798a677d",
            "placeholder": "​",
            "style": "IPY_MODEL_b4e3e4fef1844c5cbdb64fafb0cfd3a4",
            "value": " 232k/232k [00:00&lt;00:00, 2.30MB/s]"
          }
        },
        "37b622c31720473bbd3bded7eed38a9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "896d02dd03cb4fb9a1427c178c53f3b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9faefaaad634dba9900d8683796e803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3430847defd747adacfd9b246742f299": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ab8315b4efe449497d9ee4c2fa9790f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "184d27ca3fc3408f880c9af0798a677d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4e3e4fef1844c5cbdb64fafb0cfd3a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "937537a8cb65460dbb7f60bbed015ebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3eaf18e87f6945a4ab2a0ecb097b2968",
              "IPY_MODEL_7357d5494a2a42618171f688679ee643",
              "IPY_MODEL_40cef2e517b148479afb265fb4fce736"
            ],
            "layout": "IPY_MODEL_71fdc89eeee1457588795f5c8d685045"
          }
        },
        "3eaf18e87f6945a4ab2a0ecb097b2968": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_746468e741c44ab2a99524b5fbc4305b",
            "placeholder": "​",
            "style": "IPY_MODEL_9030b6378ec44099b46ecada46dc2170",
            "value": "tokenizer.json: 100%"
          }
        },
        "7357d5494a2a42618171f688679ee643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fec8eb545f54ae6a080278ab1429873",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe6c2a386dc44a26b16de64b21bde6e8",
            "value": 466062
          }
        },
        "40cef2e517b148479afb265fb4fce736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_688b2cf4e3ce44d9b9240e869f72f620",
            "placeholder": "​",
            "style": "IPY_MODEL_0158c98bf7a24eceb51e86dbdf0cfa6f",
            "value": " 466k/466k [00:00&lt;00:00, 10.9MB/s]"
          }
        },
        "71fdc89eeee1457588795f5c8d685045": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "746468e741c44ab2a99524b5fbc4305b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9030b6378ec44099b46ecada46dc2170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fec8eb545f54ae6a080278ab1429873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe6c2a386dc44a26b16de64b21bde6e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "688b2cf4e3ce44d9b9240e869f72f620": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0158c98bf7a24eceb51e86dbdf0cfa6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fe7ea5560694c10a0aeff95d860feed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b02d8dd80a3e49e1bf940845bee4ed63",
              "IPY_MODEL_0a6f60decea741b890c3d164707eab85",
              "IPY_MODEL_0bfbd6f590d1414ea74a19e92e576ad6"
            ],
            "layout": "IPY_MODEL_558b6011bc514b32b79d501ff54f7943"
          }
        },
        "b02d8dd80a3e49e1bf940845bee4ed63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f7c6858e2644a09b9c5dd3914ad81e6",
            "placeholder": "​",
            "style": "IPY_MODEL_5153db88ff3b4daf8962603e46f81ab2",
            "value": "config.json: 100%"
          }
        },
        "0a6f60decea741b890c3d164707eab85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1e1571d00bd4c50a0ee2b49d1a5217f",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51c8ad76e71d460cb5014b5b76407f09",
            "value": 570
          }
        },
        "0bfbd6f590d1414ea74a19e92e576ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13e67c4a15da498b820d1f1f1fcb8acc",
            "placeholder": "​",
            "style": "IPY_MODEL_74ffff7ecf004933a03149644080ad4e",
            "value": " 570/570 [00:00&lt;00:00, 74.2kB/s]"
          }
        },
        "558b6011bc514b32b79d501ff54f7943": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f7c6858e2644a09b9c5dd3914ad81e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5153db88ff3b4daf8962603e46f81ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1e1571d00bd4c50a0ee2b49d1a5217f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51c8ad76e71d460cb5014b5b76407f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13e67c4a15da498b820d1f1f1fcb8acc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74ffff7ecf004933a03149644080ad4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdfc7b7a1ec248a89ed855d2f33fe163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60a9a3d73e4e4e09a98cd1c1ffb0a34f",
              "IPY_MODEL_625942d3ff9c409483574c82cccb628d",
              "IPY_MODEL_12367b2300b944818b690914aa8e1dc6"
            ],
            "layout": "IPY_MODEL_c47f35faf0284cd480abba816d0df3a0"
          }
        },
        "60a9a3d73e4e4e09a98cd1c1ffb0a34f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ccaeb847f2d43c4839a5c6a190f8b9e",
            "placeholder": "​",
            "style": "IPY_MODEL_4e40e303bc9f4de482ff95a5c0ea51dc",
            "value": "model.safetensors: 100%"
          }
        },
        "625942d3ff9c409483574c82cccb628d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e410e26c0654b5ea71b7b80158f370b",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9fc663df05341d0a81d51946fb841a6",
            "value": 440449768
          }
        },
        "12367b2300b944818b690914aa8e1dc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_910bfb3e1c9f48068aababcfbaa944b2",
            "placeholder": "​",
            "style": "IPY_MODEL_009f92706c1640ffa4d6c0ef0532f098",
            "value": " 440M/440M [00:02&lt;00:00, 171MB/s]"
          }
        },
        "c47f35faf0284cd480abba816d0df3a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ccaeb847f2d43c4839a5c6a190f8b9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e40e303bc9f4de482ff95a5c0ea51dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e410e26c0654b5ea71b7b80158f370b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9fc663df05341d0a81d51946fb841a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "910bfb3e1c9f48068aababcfbaa944b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "009f92706c1640ffa4d6c0ef0532f098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlbyRTh3KhDm",
        "outputId": "41d9c660-ab6b-4dd5-cc84-a5bd82682e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
        "from torch.ao.quantization.qconfig import float_qparams_weight_only_qconfig\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import pandas as pd\n",
        "from torch.optim import AdamW\n",
        "from torchinfo import summary\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "import wandb\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch.quantization as quantization\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "4J7kuUsqKkun",
        "outputId": "6e09d165-da8b-4968-d93f-59317c98126e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhl6151\u001b[0m (\u001b[33mhl6151-new-york-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing for the raw data\n",
        "def load_news_data(data_file):\n",
        "\n",
        "    df = pd.read_json(data_file, lines=True)\n",
        "    df.head()\n",
        "\n",
        "    df['category'] = df['category'].map(lambda x: \"WORLDPOST\" if x == \"THE WORLDPOST\" else x)\n",
        "\n",
        "    df['headline'] = df['headline'].apply(lambda x: str(x).lower())\n",
        "    df['short_description'] = df['short_description'].apply(lambda x: str(x).lower())\n",
        "\n",
        "    df['text'] = df['headline'] + \" \" + df['short_description']\n",
        "    encoder = LabelEncoder()\n",
        "    df['label'] = encoder.fit_transform(df['category'])\n",
        "    print(f\"The dataset contains {df['category'].nunique()} unique categories.\")\n",
        "\n",
        "    return df['text'].tolist(), df['label'].tolist(), encoder.classes_.tolist()"
      ],
      "metadata": {
        "id": "xD6aRdGgK2xS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3U5Lvv6LjSM",
        "outputId": "af03d269-8199-4ac4-dc81-940d6edfcde8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = \"/content/drive/MyDrive/News_Category_Dataset_v2.json\"\n",
        "texts, labels, label_names = load_news_data(data_file)\n",
        "\n",
        "# The relationship between the actual label and their number label\n",
        "for idx, name in enumerate(label_names):\n",
        "    print(f\"{idx} → {name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_69ZnT9LmzF",
        "outputId": "68323c57-46fe-4f6b-c708-7b2ac6ea6abc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset contains 40 unique categories.\n",
            "0 → ARTS\n",
            "1 → ARTS & CULTURE\n",
            "2 → BLACK VOICES\n",
            "3 → BUSINESS\n",
            "4 → COLLEGE\n",
            "5 → COMEDY\n",
            "6 → CRIME\n",
            "7 → CULTURE & ARTS\n",
            "8 → DIVORCE\n",
            "9 → EDUCATION\n",
            "10 → ENTERTAINMENT\n",
            "11 → ENVIRONMENT\n",
            "12 → FIFTY\n",
            "13 → FOOD & DRINK\n",
            "14 → GOOD NEWS\n",
            "15 → GREEN\n",
            "16 → HEALTHY LIVING\n",
            "17 → HOME & LIVING\n",
            "18 → IMPACT\n",
            "19 → LATINO VOICES\n",
            "20 → MEDIA\n",
            "21 → MONEY\n",
            "22 → PARENTING\n",
            "23 → PARENTS\n",
            "24 → POLITICS\n",
            "25 → QUEER VOICES\n",
            "26 → RELIGION\n",
            "27 → SCIENCE\n",
            "28 → SPORTS\n",
            "29 → STYLE\n",
            "30 → STYLE & BEAUTY\n",
            "31 → TASTE\n",
            "32 → TECH\n",
            "33 → TRAVEL\n",
            "34 → WEDDINGS\n",
            "35 → WEIRD NEWS\n",
            "36 → WELLNESS\n",
            "37 → WOMEN\n",
            "38 → WORLD NEWS\n",
            "39 → WORLDPOST\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select parameters and model for model training\n",
        "bert_model_name = 'bert-base-uncased'\n",
        "num_classes = len(label_names)\n",
        "max_length = 256\n",
        "batch_size = 32\n",
        "num_epochs = 1\n",
        "learning_rate = 2e-5"
      ],
      "metadata": {
        "id": "w2oS76z7Lsnc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb initialization\n",
        "wandb.init(project=\"News classification\", name=\"v3\", config={\n",
        "    \"Model_name\": bert_model_name,\n",
        "    \"Epoch\": num_epochs,\n",
        "    \"Batch_size\": batch_size,\n",
        "    \"Learning_rate\": learning_rate,\n",
        "    \"Max_length\": max_length\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "SpfEG6RIL63q",
        "outputId": "d13be1c3-83e6-4c58-8e2c-ca5733a0926f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250504_211719-rcyzfrvm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/hl6151-new-york-university/News%20classification/runs/rcyzfrvm' target=\"_blank\">v3</a></strong> to <a href='https://wandb.ai/hl6151-new-york-university/News%20classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/hl6151-new-york-university/News%20classification' target=\"_blank\">https://wandb.ai/hl6151-new-york-university/News%20classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/hl6151-new-york-university/News%20classification/runs/rcyzfrvm' target=\"_blank\">https://wandb.ai/hl6151-new-york-university/News%20classification/runs/rcyzfrvm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/hl6151-new-york-university/News%20classification/runs/rcyzfrvm?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7bd273f20b10>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        \"\"\"\n",
        "        Dataset for text classification tasks.\n",
        "\n",
        "        Args:\n",
        "            texts (List[str]): List of input texts.\n",
        "            labels (List[int]): List of corresponding labels.\n",
        "            tokenizer: Tokenizer instance (e.g., from HuggingFace Transformers).\n",
        "            max_length (int): Maximum sequence length after tokenization.\n",
        "        \"\"\"\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            int: Total number of samples in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Retrieves the tokenized representation and label for a given index.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the sample.\n",
        "\n",
        "        Returns:\n",
        "            dict: Dictionary with 'input_ids', 'attention_mask', and 'label'.\n",
        "        \"\"\"\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Tokenize the text with padding and truncation\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            return_tensors='pt',\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),           # Token IDs (1D tensor)\n",
        "            'attention_mask': encoding['attention_mask'].flatten(), # Attention mask (1D tensor)\n",
        "            'label': torch.tensor(label)                            # Target label (scalar tensor)\n",
        "        }"
      ],
      "metadata": {
        "id": "3lEpNMhNL9Bs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Without mixed precision\n",
        "# 都加了wandb来记录训练过程，最后跑一次10epoch的\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "def train_original(model, dataloader, optimizer, scheduler, device, epoch=None):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    with profile(\n",
        "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA] if device.type == \"cuda\" else [ProfilerActivity.CPU],\n",
        "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=2, repeat=1),\n",
        "        on_trace_ready=torch.profiler.tensorboard_trace_handler(f\"./log_train_profiler\"),\n",
        "        record_shapes=True,\n",
        "        profile_memory=True,\n",
        "        with_stack=True\n",
        "    ) as profiler:\n",
        "\n",
        "        for step, batch in enumerate(tqdm(dataloader, desc=f\"Training Epoch {epoch if epoch is not None else ''}\")):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with record_function(\"forward_pass\"):\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.logits\n",
        "                loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "\n",
        "            with record_function(\"backward_pass\"):\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            scheduler.step()\n",
        "            profiler.step()  # ✅ 每个 step 结束标记\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            wandb.log({\"train/loss_batch\": loss.item()})\n",
        "\n",
        "    print(profiler.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"cpu_time_total\", row_limit=20))\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"Average training loss: {avg_loss:.4f}\")\n",
        "    wandb.log({\"train/loss_epoch\": avg_loss})\n"
      ],
      "metadata": {
        "id": "n3dDQWjtL_Af"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use Mixed Precision\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "from torch.cuda.amp import GradScaler\n",
        "\n",
        "scaler = torch.amp.GradScaler('cuda')\n",
        "\n",
        "def train(model, dataloader, optimizer, scheduler, device, epoch=None):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    with profile(\n",
        "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA] if device.type == \"cuda\" else [ProfilerActivity.CPU],\n",
        "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=2, repeat=1),\n",
        "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./log'),\n",
        "        record_shapes=True,\n",
        "        profile_memory=True,\n",
        "        with_stack=True\n",
        "    ) as profiler:\n",
        "\n",
        "        for step, batch in enumerate(tqdm(dataloader, desc=f\"Training Epoch {epoch if epoch is not None else ''}\")):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                with record_function(\"forward_pass\"):\n",
        "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                    logits = outputs.logits\n",
        "                    loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "\n",
        "            with record_function(\"backward_pass\"):\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "\n",
        "            scheduler.step()\n",
        "            profiler.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            wandb.log({\"train/loss_batch\": loss.item()})\n",
        "\n",
        "    print(profiler.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"cpu_time_total\", row_limit=20))\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"Average training loss: {avg_loss:.4f}\")\n",
        "    wandb.log({\"train/loss_epoch\": avg_loss})\n"
      ],
      "metadata": {
        "id": "w8rl5vMzMBd-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add wandb to track loss and metrics for evaluation function\n",
        "def evaluate(model, data_loader, device, epoch=None):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the validation or test set and log metrics using Weights & Biases (wandb).\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): Trained model to evaluate.\n",
        "        data_loader (DataLoader): DataLoader for validation/test dataset.\n",
        "        device (torch.device): Device to run evaluation on ('cuda' or 'cpu').\n",
        "        epoch (int, optional): Current epoch number (optional for logging).\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float, float]: accuracy, macro F1 score, weighted F1 score\n",
        "    \"\"\"\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    predictions = []\n",
        "    actual_labels = []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
        "        for batch in data_loader:\n",
        "            # Move batch to device\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Get predicted class by choosing the max logit\n",
        "            _, preds = torch.max(logits, dim=1)\n",
        "\n",
        "            # Store predictions and true labels for metric computation\n",
        "            predictions.extend(preds.cpu().tolist())\n",
        "            actual_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "    # Compute evaluation metrics\n",
        "    acc = accuracy_score(actual_labels, predictions)\n",
        "    macro_f1 = f1_score(actual_labels, predictions, average='macro')\n",
        "    weighted_f1 = f1_score(actual_labels, predictions, average='weighted')\n",
        "\n",
        "    # Log metrics to Weights & Biases\n",
        "    wandb.log({\n",
        "        \"eval/accuracy\": acc,\n",
        "        \"eval/macro_f1\": macro_f1,\n",
        "        \"eval/weighted_f1\": weighted_f1\n",
        "    })\n",
        "\n",
        "    return acc, macro_f1, weighted_f1\n"
      ],
      "metadata": {
        "id": "rlqTEFuOMDyr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.profiler import profile, record_function, ProfilerActivity, schedule, tensorboard_trace_handler\n",
        "import time\n",
        "def predict_news_category(text, model, tokenizer, device, encoder, max_length=128):\n",
        "    model.eval()\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=max_length\n",
        "    )\n",
        "    input_ids = inputs[\"input_ids\"].to(device)\n",
        "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
        "\n",
        "    with profile(\n",
        "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA] if device.type == \"cuda\" else [ProfilerActivity.CPU],\n",
        "        schedule=schedule(wait=1, warmup=1, active=5, repeat=1),  # 跳过第 1 次，记录后 5 次\n",
        "        record_shapes=True,\n",
        "        profile_memory=True,\n",
        "        with_stack=True,\n",
        "        on_trace_ready=tensorboard_trace_handler(\"./log_predict_base_warmup\")\n",
        "    ) as profiler:\n",
        "        for i in range(7):  # 总共运行 7 次\n",
        "            with torch.no_grad():\n",
        "                with record_function(f\"model_inference_{i}\"):\n",
        "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                    logits = outputs.logits\n",
        "                    _, predicted_label = torch.max(logits, dim=1)\n",
        "            profiler.step()\n",
        "\n",
        "    print(profiler.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"cpu_time_total\", row_limit=20))\n",
        "\n",
        "    predicted_category = encoder.inverse_transform(predicted_label.cpu().numpy())[0]\n",
        "    print(f\"✅ Warmup profiling done. Use TensorBoard:\\n\\n  %tensorboard --logdir=./log_predict_base_warmup\")\n",
        "    return predicted_category"
      ],
      "metadata": {
        "id": "biA-5HzsMISO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.amp import autocast\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "def predict_news_category_amp(text, model, tokenizer, device, encoder, max_length=128):\n",
        "    \"\"\"\n",
        "    Predict news category using AMP with torch.profiler to measure performance.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=max_length\n",
        "    )\n",
        "    input_ids = inputs[\"input_ids\"].to(device)\n",
        "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
        "\n",
        "    with profile(\n",
        "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA] if device.type == \"cuda\" else [ProfilerActivity.CPU],\n",
        "        schedule=schedule(wait=1, warmup=1, active=5, repeat=1),\n",
        "        record_shapes=True,\n",
        "        profile_memory=True,\n",
        "        with_stack=True,\n",
        "        on_trace_ready=torch.profiler.tensorboard_trace_handler(\"./log_amp_predict\")\n",
        "    ) as profiler:\n",
        "        for i in range(7):\n",
        "            with torch.no_grad():\n",
        "                with record_function(\"inference\"):\n",
        "                    with torch.amp.autocast('cuda'):\n",
        "                        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                        logits = outputs.logits\n",
        "                        _, predicted_label = torch.max(logits, dim=1)\n",
        "            profiler.step()\n",
        "\n",
        "    print(profiler.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=20))\n",
        "    print(profiler.key_averages().table(sort_by=\"cpu_time_total\", row_limit=20))\n",
        "    predicted_category = encoder.inverse_transform(predicted_label.cpu().numpy())[0]\n",
        "    print(\"✅ Profiling complete. Run: tensorboard --logdir=./log_amp_predict\")\n",
        "    return predicted_category"
      ],
      "metadata": {
        "id": "2H6-J_GhMKEI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zMFNDupwML8Y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained tokenizer for BERT\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
        "\n",
        "# Create datasheet\n",
        "train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n",
        "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
        "\n",
        "# Wrap training dataset in a DataLoader for batching and shuffling\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "xvHlFRmOMO3w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256,
          "referenced_widgets": [
            "f473a14147e34a8f9f1990245744f3ed",
            "a58a48976cab417cb2a40c2d7aaaaadd",
            "48018e91458442bdb3b6b13c158ae535",
            "574de5bd969346e083e1c5c08027c712",
            "6fa8d724ef4f4cc49bf13d517a98169d",
            "07e39c7c8021408bba9cd9b31eca2fde",
            "9eeba7fedb1942c298adade8710aa9c8",
            "9e1df5b5be234746a0d845faeb58f335",
            "a9e1a3d5d38943f999764ea28c3721b5",
            "353991ffbe7d4b54bf1b0c6317738c49",
            "741e5eeed18b43a4b39afd6994f96e17",
            "0d2bc78b2d23462ab404c744c42b91d2",
            "f286ab6ceb5f48f1a9c76a4bff49e199",
            "d0093dfd225947f89702b9a5aedefd7f",
            "b6401a52430c417093ad62f4a94a3e82",
            "37b622c31720473bbd3bded7eed38a9f",
            "896d02dd03cb4fb9a1427c178c53f3b3",
            "c9faefaaad634dba9900d8683796e803",
            "3430847defd747adacfd9b246742f299",
            "3ab8315b4efe449497d9ee4c2fa9790f",
            "184d27ca3fc3408f880c9af0798a677d",
            "b4e3e4fef1844c5cbdb64fafb0cfd3a4",
            "937537a8cb65460dbb7f60bbed015ebe",
            "3eaf18e87f6945a4ab2a0ecb097b2968",
            "7357d5494a2a42618171f688679ee643",
            "40cef2e517b148479afb265fb4fce736",
            "71fdc89eeee1457588795f5c8d685045",
            "746468e741c44ab2a99524b5fbc4305b",
            "9030b6378ec44099b46ecada46dc2170",
            "9fec8eb545f54ae6a080278ab1429873",
            "fe6c2a386dc44a26b16de64b21bde6e8",
            "688b2cf4e3ce44d9b9240e869f72f620",
            "0158c98bf7a24eceb51e86dbdf0cfa6f",
            "8fe7ea5560694c10a0aeff95d860feed",
            "b02d8dd80a3e49e1bf940845bee4ed63",
            "0a6f60decea741b890c3d164707eab85",
            "0bfbd6f590d1414ea74a19e92e576ad6",
            "558b6011bc514b32b79d501ff54f7943",
            "8f7c6858e2644a09b9c5dd3914ad81e6",
            "5153db88ff3b4daf8962603e46f81ab2",
            "f1e1571d00bd4c50a0ee2b49d1a5217f",
            "51c8ad76e71d460cb5014b5b76407f09",
            "13e67c4a15da498b820d1f1f1fcb8acc",
            "74ffff7ecf004933a03149644080ad4e"
          ]
        },
        "outputId": "2efe5fd2-dd7b-4d91-b633-49a822b88fac"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f473a14147e34a8f9f1990245744f3ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d2bc78b2d23462ab404c744c42b91d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "937537a8cb65460dbb7f60bbed015ebe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fe7ea5560694c10a0aeff95d860feed"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the available device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pre-trained model from hugging face\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    bert_model_name,\n",
        "    num_labels=num_classes\n",
        ")\n",
        "\n",
        "# LoRA configuration, only train part of parameters\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    r=8,                          # percentage of parameter compress\n",
        "    lora_alpha=32,                # scale factor, control update speed\n",
        "    lora_dropout=0.0,             # dropout\n",
        "    bias=\"lora_only\"              # only trains the bias for LoRA layer\n",
        ")\n",
        "\n",
        "model = get_peft_model(base_model, lora_config).to(device)\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161,
          "referenced_widgets": [
            "fdfc7b7a1ec248a89ed855d2f33fe163",
            "60a9a3d73e4e4e09a98cd1c1ffb0a34f",
            "625942d3ff9c409483574c82cccb628d",
            "12367b2300b944818b690914aa8e1dc6",
            "c47f35faf0284cd480abba816d0df3a0",
            "0ccaeb847f2d43c4839a5c6a190f8b9e",
            "4e40e303bc9f4de482ff95a5c0ea51dc",
            "8e410e26c0654b5ea71b7b80158f370b",
            "f9fc663df05341d0a81d51946fb841a6",
            "910bfb3e1c9f48068aababcfbaa944b2",
            "009f92706c1640ffa4d6c0ef0532f098"
          ]
        },
        "id": "P1yFYL1QMQm1",
        "outputId": "781a4c58-7687-4839-aa77-015147ed359a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdfc7b7a1ec248a89ed855d2f33fe163"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "total_steps = len(train_dataloader) * num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
      ],
      "metadata": {
        "id": "5qXUWSU8MS0M"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 128\n",
        "\n",
        "input_data = {\n",
        "    \"input_ids\": torch.zeros((batch_size, seq_len), dtype=torch.long).to(device),\n",
        "    \"attention_mask\": torch.ones((batch_size, seq_len), dtype=torch.long).to(device)\n",
        "}\n",
        "\n",
        "summary(model, input_data=input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdaklfn2MWHe",
        "outputId": "2000d782-6ab1-4b24-9883-71edea5fe796"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=============================================================================================================================\n",
              "Layer (type:depth-idx)                                                      Output Shape              Param #\n",
              "=============================================================================================================================\n",
              "PeftModelForSequenceClassification                                          [32, 40]                  --\n",
              "├─LoraModel: 1-1                                                            [32, 40]                  --\n",
              "│    └─BertForSequenceClassification: 2-1                                   --                        --\n",
              "│    │    └─BertModel: 3-1                                                  [32, 768]                 109,777,152\n",
              "│    │    └─Dropout: 3-2                                                    [32, 768]                 --\n",
              "│    │    └─ModulesToSaveWrapper: 3-3                                       [32, 40]                  61,520\n",
              "=============================================================================================================================\n",
              "Total params: 109,838,672\n",
              "Trainable params: 344,104\n",
              "Non-trainable params: 109,494,568\n",
              "Total mult-adds (Units.GIGABYTES): 3.50\n",
              "=============================================================================================================================\n",
              "Input size (MB): 0.07\n",
              "Forward/backward pass size (MB): 4008.65\n",
              "Params size (MB): 439.23\n",
              "Estimated Total Size (MB): 4447.95\n",
              "============================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "print(batch.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vC_3yJwMXmv",
        "outputId": "d236e366-ba2a-4158-c538-6cb1b02f6c20"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'attention_mask', 'label'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if \"bias\" in name:\n",
        "        print(f\"{name}: requires_grad={param.requires_grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WDxjketMZFq",
        "outputId": "12324469-91f7-497a-d9fc-7f3acafb8d62"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base_model.model.bert.embeddings.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.0.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.0.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.0.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.0.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.0.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.0.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.0.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.0.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.1.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.1.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.1.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.1.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.1.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.1.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.1.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.1.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.2.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.2.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.2.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.2.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.2.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.2.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.2.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.2.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.3.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.3.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.3.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.3.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.3.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.3.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.3.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.3.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.4.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.4.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.4.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.4.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.4.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.4.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.4.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.4.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.5.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.5.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.5.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.5.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.5.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.5.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.5.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.5.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.6.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.6.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.6.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.6.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.6.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.6.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.6.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.6.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.7.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.7.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.7.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.7.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.7.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.7.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.7.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.7.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.8.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.8.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.8.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.8.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.8.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.8.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.8.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.8.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.9.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.9.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.9.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.9.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.9.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.9.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.9.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.9.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.10.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.10.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.10.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.10.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.10.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.10.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.10.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.10.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.11.attention.self.query.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.11.attention.self.key.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.11.attention.self.value.base_layer.bias: requires_grad=True\n",
            "base_model.model.bert.encoder.layer.11.attention.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.11.attention.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.11.intermediate.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.11.output.dense.bias: requires_grad=False\n",
            "base_model.model.bert.encoder.layer.11.output.LayerNorm.bias: requires_grad=False\n",
            "base_model.model.bert.pooler.dense.bias: requires_grad=False\n",
            "base_model.model.classifier.original_module.bias: requires_grad=False\n",
            "base_model.model.classifier.modules_to_save.default.bias: requires_grad=True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LoRA and Mixed Precision，训练结束后会打印出来表格\n",
        "for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "        train(model, train_dataloader, optimizer, scheduler, device)\n",
        "        accuracy, macro_f1, weighted_f1 = evaluate(model, val_dataloader, device)\n",
        "        print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Macro F1: {macro_f1:.4f}\")\n",
        "        print(f\"Weighted F1: {weighted_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "1GSYMk2cMbwL",
        "outputId": "c9585910-d628-4133-87bb-b827ce26bd1e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch :   8%|▊         | 386/5022 [00:38<07:41, 10.05it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-4efa5dfb39ce>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch + 1}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmacro_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation Accuracy: {accuracy:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-1bf9dd62cf42>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, scheduler, device, epoch)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"backward_pass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Only LoRA，训练结束后会打印出来表格\n",
        "for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "        train_original(model, train_dataloader, optimizer, scheduler, device)\n",
        "        accuracy, macro_f1, weighted_f1 = evaluate(model, val_dataloader, device)\n",
        "        print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Macro F1: {macro_f1:.4f}\")\n",
        "        print(f\"Weighted F1: {weighted_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "KKhLCo4lfEJI",
        "outputId": "1486afe7-11dc-4efa-e00d-2f8d2d8fe13d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch :   1%|          | 41/5022 [00:13<26:49,  3.10it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-c77a76a372aa>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch + 1}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtrain_original\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmacro_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation Accuracy: {accuracy:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-a1dae2a0d885>\u001b[0m in \u001b[0;36mtrain_original\u001b[0;34m(model, dataloader, optimizer, scheduler, device, epoch)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ✅ 每个 step 结束标记\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"train/loss_batch\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.base_model.model.save_pretrained(\"bert-base-checkpoint\")\n",
        "model.save_pretrained(\"lora-adapter-checkpoint\")"
      ],
      "metadata": {
        "id": "DUY6NVa2IneB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 从训练模型的大小证明LoRA好处：\n",
        "def get_dir_size(path):\n",
        "    return sum(os.path.getsize(os.path.join(dp, f)) for dp, _, fn in os.walk(path) for f in fn)\n",
        "\n",
        "print(f\"Base size: {get_dir_size('bert-base-checkpoint') / 1024**2:.2f} MB\")\n",
        "print(f\"LoRA size: {get_dir_size('lora-adapter-checkpoint') / 1024**2:.2f} MB\")"
      ],
      "metadata": {
        "id": "JOFKA63gIn6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation时间 对于LoRA Only\n",
        "texts, labels, label_classes = load_news_data(\"/content/drive/MyDrive/News_Category_Dataset_v2.json\")\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.classes_ = np.array(label_classes)\n",
        "\n",
        "test_text = \"NASA launches new space telescope to explore exoplanets.\"\n",
        "predicted_category = predict_news_category(test_text, base_model, tokenizer, device, encoder)\n",
        "\n",
        "print(f\"Headline: {test_text}\")\n",
        "print(f\"Predicted Category: {predicted_category}\")"
      ],
      "metadata": {
        "id": "bIzSRTMzZxgq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20dbc980-f15e-4bb5-9c8a-f7835e4f1b17"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset contains 40 unique categories.\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                      model_inference_5         0.00%       0.000us         0.00%       0.000us       0.000us      29.234ms       111.79%      29.234ms      29.234ms           0 b           0 b           0 b           0 b             1  \n",
            "                                      model_inference_2         0.00%       0.000us         0.00%       0.000us       0.000us      26.526ms       101.43%      26.526ms      26.526ms           0 b           0 b           0 b           0 b             1  \n",
            "                                          ProfilerStep*         0.34%     456.784us        99.99%     134.080ms      26.816ms       0.000us         0.00%      26.152ms       5.230ms           0 b           0 b       2.25 Mb           0 b             5  \n",
            "                                      model_inference_6         0.00%       0.000us         0.00%       0.000us       0.000us      25.407ms        97.15%      25.407ms      25.407ms           0 b           0 b           0 b           0 b             1  \n",
            "                                      model_inference_3         0.00%       0.000us         0.00%       0.000us       0.000us      25.358ms        96.96%      25.358ms      25.358ms           0 b           0 b           0 b           0 b             1  \n",
            "                                      model_inference_4         0.00%       0.000us         0.00%       0.000us       0.000us      25.200ms        96.36%      25.200ms      25.200ms           0 b           0 b           0 b           0 b             1  \n",
            "                                           aten::linear         3.68%       4.937ms        34.60%      46.395ms      76.057us       0.000us         0.00%      21.740ms      35.639us           0 b           0 b     277.99 Mb           0 b           610  \n",
            "                                            aten::addmm        10.83%      14.529ms        16.62%      22.292ms      60.250us      17.814ms        68.12%      17.814ms      48.146us           0 b           0 b     232.52 Mb    -137.48 Mb           370  \n",
            "                        ampere_sgemm_32x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us      12.201ms        46.66%      12.201ms      33.893us           0 b           0 b           0 b           0 b           360  \n",
            "                                      model_inference_3         7.48%      10.025ms        19.19%      25.731ms      25.731ms       0.000us         0.00%       5.234ms       5.234ms           0 b           0 b           0 b    -122.18 Mb             1  \n",
            "                                      model_inference_6         7.97%      10.693ms        19.19%      25.739ms      25.739ms       0.000us         0.00%       5.233ms       5.233ms           0 b           0 b           0 b    -122.18 Mb             1  \n",
            "                                      model_inference_2         8.52%      11.423ms        20.13%      26.992ms      26.992ms       0.000us         0.00%       5.232ms       5.232ms           0 b           0 b           0 b    -122.18 Mb             1  \n",
            "                                      model_inference_4         7.40%       9.921ms        19.05%      25.549ms      25.549ms       0.000us         0.00%       5.226ms       5.226ms           0 b           0 b           0 b    -122.18 Mb             1  \n",
            "                                      model_inference_5        10.60%      14.215ms        22.08%      29.613ms      29.613ms       0.000us         0.00%       5.226ms       5.226ms           0 b           0 b       2.25 Mb    -119.93 Mb             1  \n",
            "                        ampere_sgemm_64x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us       4.943ms        18.90%       4.943ms      82.390us           0 b           0 b           0 b           0 b            60  \n",
            "                                           aten::matmul         1.55%       2.077ms         8.79%      11.792ms      49.131us       0.000us         0.00%       3.926ms      16.358us           0 b           0 b      45.47 Mb           0 b           240  \n",
            "                                               aten::mm         4.35%       5.831ms         6.32%       8.476ms      35.316us       3.926ms        15.01%       3.926ms      16.358us           0 b           0 b      45.47 Mb      45.47 Mb           240  \n",
            "                       ampere_sgemm_128x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us       3.707ms        14.17%       3.707ms      61.778us           0 b           0 b           0 b           0 b            60  \n",
            "                     aten::scaled_dot_product_attention         0.79%       1.059ms         4.41%       5.909ms      98.484us       0.000us         0.00%       1.841ms      30.683us           0 b        -960 b      22.50 Mb           0 b            60  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.61%     811.934us         3.35%       4.489ms      74.811us       0.000us         0.00%       1.841ms      30.683us         960 b           0 b      22.50 Mb           0 b            60  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 134.097ms\n",
            "Self CUDA time total: 26.152ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                            aten::empty         4.30%       5.766ms         4.30%       5.766ms       5.737us       0.000us         0.00%       0.000us       0.000us         960 b         960 b     439.81 Mb     439.81 Mb          1005  \n",
            "                                             aten::gelu         0.89%       1.188ms         1.39%       1.869ms      31.151us     259.138us         0.99%     259.138us       4.319us           0 b           0 b     120.00 Mb     120.00 Mb            60  \n",
            "                                              aten::add         2.90%       3.882ms         4.57%       6.123ms      24.991us     765.977us         2.93%     765.977us       3.126us           0 b           0 b      91.88 Mb      91.88 Mb           245  \n",
            "                                               aten::mm         4.35%       5.831ms         6.32%       8.476ms      35.316us       3.926ms        15.01%       3.926ms      16.358us           0 b           0 b      45.47 Mb      45.47 Mb           240  \n",
            "                                              aten::mul         1.77%       2.378ms         2.67%       3.587ms      29.890us     359.931us         1.38%     359.931us       2.999us           0 b           0 b      45.00 Mb      45.00 Mb           120  \n",
            "                                          aten::resize_         0.07%      99.363us         0.07%      99.363us       6.624us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       5.62 Mb       5.62 Mb            15  \n",
            "                                    aten::empty_strided         0.07%      97.164us         0.07%      97.164us       9.716us       0.000us         0.00%       0.000us       0.000us           0 b           0 b     400.00 Kb     400.00 Kb            10  \n",
            "                                              aten::sub         0.07%      97.803us         0.11%     151.806us      30.361us      12.832us         0.05%      12.832us       2.566us           0 b           0 b     320.00 Kb     320.00 Kb             5  \n",
            "                                             aten::tanh         0.08%     101.608us         0.12%     158.917us      31.783us      14.592us         0.06%      14.592us       2.918us           0 b           0 b      15.00 Kb      15.00 Kb             5  \n",
            "                                              aten::max         0.15%     207.718us         0.21%     285.926us      57.185us      32.192us         0.12%      32.192us       6.438us           0 b           0 b       5.00 Kb       5.00 Kb             5  \n",
            "                                               aten::eq         0.11%     148.174us         0.17%     229.649us      45.930us      11.521us         0.04%      11.521us       2.304us           0 b           0 b       2.50 Kb       2.50 Kb             5  \n",
            "                                              aten::all         0.10%     135.680us         0.15%     196.400us      39.280us      24.321us         0.09%      24.321us       4.864us           0 b           0 b       2.50 Kb       2.50 Kb             5  \n",
            "                                          ProfilerStep*         0.34%     456.784us        99.99%     134.080ms      26.816ms       0.000us         0.00%      26.152ms       5.230ms           0 b           0 b       2.25 Mb           0 b             5  \n",
            "                                            aten::slice         0.18%     248.045us         0.21%     287.143us       8.204us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            35  \n",
            "                                       aten::as_strided         1.03%       1.387ms         1.03%       1.387ms       1.132us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1225  \n",
            "                                           aten::expand         0.26%     352.576us         0.31%     420.168us       6.002us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            70  \n",
            "                                        aten::embedding         0.10%     136.570us         0.65%     869.560us      57.971us       0.000us         0.00%      82.846us       5.523us           0 b           0 b       5.62 Mb           0 b            15  \n",
            "                                          aten::reshape         1.05%       1.407ms         2.13%       2.851ms       4.224us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           675  \n",
            "                                             aten::view         2.26%       3.035ms         2.26%       3.035ms       2.051us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1480  \n",
            "                                     aten::index_select         0.21%     281.647us         0.50%     673.265us      44.884us      82.846us         0.32%      82.846us       5.523us           0 b           0 b       5.62 Mb           0 b            15  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 134.097ms\n",
            "Self CUDA time total: 26.152ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.34%     456.784us        99.99%     134.080ms      26.816ms       0.000us         0.00%      26.152ms       5.230ms           0 b           0 b       2.25 Mb           0 b             5  \n",
            "                                           aten::linear         3.68%       4.937ms        34.60%      46.395ms      76.057us       0.000us         0.00%      21.740ms      35.639us           0 b           0 b     277.99 Mb           0 b           610  \n",
            "                                      model_inference_5        10.60%      14.215ms        22.08%      29.613ms      29.613ms       0.000us         0.00%       5.226ms       5.226ms           0 b           0 b       2.25 Mb    -119.93 Mb             1  \n",
            "                                      model_inference_2         8.52%      11.423ms        20.13%      26.992ms      26.992ms       0.000us         0.00%       5.232ms       5.232ms           0 b           0 b           0 b    -122.18 Mb             1  \n",
            "                                      model_inference_6         7.97%      10.693ms        19.19%      25.739ms      25.739ms       0.000us         0.00%       5.233ms       5.233ms           0 b           0 b           0 b    -122.18 Mb             1  \n",
            "                                      model_inference_3         7.48%      10.025ms        19.19%      25.731ms      25.731ms       0.000us         0.00%       5.234ms       5.234ms           0 b           0 b           0 b    -122.18 Mb             1  \n",
            "                                      model_inference_4         7.40%       9.921ms        19.05%      25.549ms      25.549ms       0.000us         0.00%       5.226ms       5.226ms           0 b           0 b           0 b    -122.18 Mb             1  \n",
            "                                            aten::addmm        10.83%      14.529ms        16.62%      22.292ms      60.250us      17.814ms        68.12%      17.814ms      48.146us           0 b           0 b     232.52 Mb    -137.48 Mb           370  \n",
            "                                       cudaLaunchKernel        10.21%      13.695ms        10.21%      13.695ms      10.657us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1285  \n",
            "                                           aten::matmul         1.55%       2.077ms         8.79%      11.792ms      49.131us       0.000us         0.00%       3.926ms      16.358us           0 b           0 b      45.47 Mb           0 b           240  \n",
            "                                               aten::mm         4.35%       5.831ms         6.32%       8.476ms      35.316us       3.926ms        15.01%       3.926ms      16.358us           0 b           0 b      45.47 Mb      45.47 Mb           240  \n",
            "                                       aten::layer_norm         0.48%     648.160us         5.42%       7.268ms      58.141us       0.000us         0.00%     897.173us       7.177us           0 b           0 b      46.88 Mb    -124.00 Kb           125  \n",
            "                                aten::native_layer_norm         2.20%       2.955ms         4.94%       6.619ms      52.955us     897.173us         3.43%     897.173us       7.177us           0 b           0 b      47.00 Mb           0 b           125  \n",
            "                                              aten::add         2.90%       3.882ms         4.57%       6.123ms      24.991us     765.977us         2.93%     765.977us       3.126us           0 b           0 b      91.88 Mb      91.88 Mb           245  \n",
            "                     aten::scaled_dot_product_attention         0.79%       1.059ms         4.41%       5.909ms      98.484us       0.000us         0.00%       1.841ms      30.683us           0 b        -960 b      22.50 Mb           0 b            60  \n",
            "                                            aten::empty         4.30%       5.766ms         4.30%       5.766ms       5.737us       0.000us         0.00%       0.000us       0.000us         960 b         960 b     439.81 Mb     439.81 Mb          1005  \n",
            "                                                aten::t         1.63%       2.183ms         3.63%       4.872ms       7.987us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           610  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.61%     811.934us         3.35%       4.489ms      74.811us       0.000us         0.00%       1.841ms      30.683us         960 b           0 b      22.50 Mb           0 b            60  \n",
            "                                        aten::transpose         2.01%       2.693ms         2.74%       3.675ms       4.039us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           910  \n",
            "                                              aten::mul         1.77%       2.378ms         2.67%       3.587ms      29.890us     359.931us         1.38%     359.931us       2.999us           0 b           0 b      45.00 Mb      45.00 Mb           120  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 134.097ms\n",
            "Self CUDA time total: 26.152ms\n",
            "\n",
            "✅ Warmup profiling done. Use TensorBoard:\n",
            "\n",
            "  %tensorboard --logdir=./log_predict_base_warmup\n",
            "Headline: NASA launches new space telescope to explore exoplanets.\n",
            "Predicted Category: DIVORCE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation时间 对于LoRA+Mixed Precision\n",
        "texts, labels, label_classes = load_news_data(\"/content/drive/MyDrive/News_Category_Dataset_v2.json\")\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.classes_ = np.array(label_classes)\n",
        "\n",
        "test_text = \"NASA launches new space telescope to explore exoplanets.\"\n",
        "predicted_category = predict_news_category_amp(test_text, model, tokenizer, device, encoder)\n",
        "\n",
        "print(f\"Headline: {test_text}\")\n",
        "print(f\"Predicted Category: {predicted_category}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1vi66xdIiLk",
        "outputId": "ebb99d4e-17ea-45e1-9dde-5feda10976dd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset contains 40 unique categories.\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                              inference         0.00%       0.000us         0.00%       0.000us       0.000us     205.025ms      1389.35%     205.025ms      41.005ms           0 b           0 b           0 b           0 b             5  \n",
            "                                           aten::linear         5.31%      11.088ms        74.24%     154.995ms     127.045us       0.000us         0.00%      15.860ms      13.000us           0 b           0 b     255.30 Mb      -1.07 Gb          1220  \n",
            "                                          ProfilerStep*         0.23%     474.517us        99.99%     208.758ms      41.752ms       0.000us         0.00%      14.757ms       2.951ms           0 b           0 b           0 b           0 b             5  \n",
            "                                              inference        33.50%      69.947ms        99.76%     208.283ms      41.657ms       0.000us         0.00%      14.757ms       2.951ms           0 b           0 b           0 b    -332.96 Mb             5  \n",
            "                                            aten::copy_         5.80%      12.114ms        11.88%      24.808ms      17.471us       5.564ms        37.70%       5.564ms       3.918us           0 b           0 b           0 b           0 b          1420  \n",
            "                                               aten::to         1.20%       2.501ms        23.09%      48.202ms      31.402us       0.000us         0.00%       5.551ms       3.616us           0 b           0 b       1.08 Gb           0 b          1535  \n",
            "                                         aten::_to_copy         4.53%       9.459ms        21.89%      45.701ms      32.298us       0.000us         0.00%       5.551ms       3.923us           0 b           0 b       1.08 Gb           0 b          1415  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.492ms        37.21%       5.492ms       3.909us           0 b           0 b           0 b           0 b          1405  \n",
            "                                            aten::addmm         8.46%      17.667ms        11.56%      24.137ms      65.236us       3.952ms        26.78%       3.952ms      10.682us           0 b           0 b     101.26 Mb    -268.74 Mb           370  \n",
            "sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize32x32x...         0.00%       0.000us         0.00%       0.000us       0.000us       2.763ms        18.73%       2.763ms       7.676us           0 b           0 b           0 b           0 b           360  \n",
            "                     aten::scaled_dot_product_attention         0.68%       1.422ms         7.19%      15.002ms     125.020us       0.000us         0.00%       2.286ms      19.048us           0 b        -960 b      22.50 Mb      -1.88 Mb           120  \n",
            "                                           aten::matmul         1.06%       2.220ms         7.04%      14.698ms      61.240us       0.000us         0.00%       1.319ms       5.498us           0 b           0 b      22.73 Mb           0 b           240  \n",
            "                                               aten::mm         4.23%       8.826ms         5.27%      11.010ms      45.873us       1.319ms         8.94%       1.319ms       5.498us           0 b           0 b      22.73 Mb      22.73 Mb           240  \n",
            "                                              aten::add         1.95%       4.068ms         3.04%       6.346ms      25.904us       1.143ms         7.75%       1.143ms       4.667us           0 b           0 b      69.38 Mb      69.38 Mb           245  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.39%     807.915us         2.20%       4.600ms      76.671us       0.000us         0.00%       1.055ms      17.586us         960 b           0 b      11.25 Mb           0 b            60  \n",
            "                     aten::_efficient_attention_forward         0.62%       1.289ms         1.45%       3.027ms      50.446us       1.055ms         7.15%       1.055ms      17.586us         960 b           0 b      11.25 Mb           0 b            60  \n",
            "fmha_cutlassF_f16_aligned_64x64_rf_sm80(PyTorchMemEf...         0.00%       0.000us         0.00%       0.000us       0.000us       1.055ms         7.15%       1.055ms      17.586us           0 b           0 b           0 b           0 b            60  \n",
            "                                       aten::layer_norm         0.52%       1.087ms         3.86%       8.052ms      64.418us       0.000us         0.00%     904.389us       7.235us           0 b           0 b      46.88 Mb    -125.00 Kb           125  \n",
            "                                aten::native_layer_norm         1.50%       3.141ms         3.34%       6.965ms      55.720us     904.389us         6.13%     904.389us       7.235us           0 b           0 b      47.00 Mb           0 b           125  \n",
            "void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us     904.389us         6.13%     904.389us       7.235us           0 b           0 b           0 b           0 b           125  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 208.774ms\n",
            "Self CUDA time total: 14.757ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                    aten::empty_strided         5.54%      11.576ms         5.54%      11.576ms       8.181us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       1.08 Gb       1.08 Gb          1415  \n",
            "                                            aten::empty         2.97%       6.204ms         2.97%       6.204ms       6.173us       0.000us         0.00%       0.000us       0.000us         960 b         960 b     428.56 Mb     428.56 Mb          1005  \n",
            "                                              aten::add         1.95%       4.068ms         3.04%       6.346ms      25.904us       1.143ms         7.75%       1.143ms       4.667us           0 b           0 b      69.38 Mb      69.38 Mb           245  \n",
            "                                             aten::gelu         0.82%       1.717ms         1.10%       2.300ms      38.328us     242.239us         1.64%     242.239us       4.037us           0 b           0 b      45.00 Mb      45.00 Mb            60  \n",
            "                                               aten::mm         4.23%       8.826ms         5.27%      11.010ms      45.873us       1.319ms         8.94%       1.319ms       5.498us           0 b           0 b      22.73 Mb      22.73 Mb           240  \n",
            "                                              aten::mul         1.08%       2.257ms         1.60%       3.336ms      27.796us     350.333us         2.37%     350.333us       2.919us           0 b           0 b      22.50 Mb      22.50 Mb           120  \n",
            "                                          aten::resize_         0.04%      92.889us         0.04%      92.889us       6.193us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       5.62 Mb       5.62 Mb            15  \n",
            "                                              aten::sub         0.05%      95.459us         0.07%     144.352us      28.870us      12.961us         0.09%      12.961us       2.592us           0 b           0 b     320.00 Kb     320.00 Kb             5  \n",
            "                                             aten::tanh         0.05%      99.301us         0.07%     152.065us      30.413us      15.073us         0.10%      15.073us       3.015us           0 b           0 b       7.50 Kb       7.50 Kb             5  \n",
            "                                              aten::max         0.09%     197.000us         0.13%     271.101us      54.220us      37.985us         0.26%      37.985us       7.597us           0 b           0 b       5.00 Kb       5.00 Kb             5  \n",
            "                                               aten::eq         0.07%     156.221us         0.11%     226.306us      45.261us      11.776us         0.08%      11.776us       2.355us           0 b           0 b       2.50 Kb       2.50 Kb             5  \n",
            "                                              aten::all         0.07%     148.587us         0.11%     221.440us      44.288us      24.512us         0.17%      24.512us       4.902us           0 b           0 b       2.50 Kb       2.50 Kb             5  \n",
            "                                           Buffer Flush         0.04%      77.477us         0.04%      77.477us      77.477us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       1.50 Kb       1.50 Kb             1  \n",
            "                                          ProfilerStep*         0.23%     474.517us        99.99%     208.758ms      41.752ms       0.000us         0.00%      14.757ms       2.951ms           0 b           0 b           0 b           0 b             5  \n",
            "                                            aten::slice         0.12%     260.892us         0.14%     300.732us       8.592us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            35  \n",
            "                                       aten::as_strided         0.77%       1.611ms         0.77%       1.611ms       1.315us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1225  \n",
            "                                           aten::expand         0.20%     419.511us         0.25%     522.296us       7.461us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            70  \n",
            "                                        aten::embedding         0.07%     141.202us         0.43%     889.408us      59.294us       0.000us         0.00%      82.973us       5.532us           0 b           0 b       5.62 Mb           0 b            15  \n",
            "                                          aten::reshape         0.66%       1.380ms         1.55%       3.231ms       4.787us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           675  \n",
            "                                             aten::view         1.71%       3.574ms         1.71%       3.574ms       2.415us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1480  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 208.774ms\n",
            "Self CUDA time total: 14.757ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*         0.23%     474.517us        99.99%     208.758ms      41.752ms       0.000us         0.00%      14.757ms       2.951ms           0 b           0 b           0 b           0 b             5  \n",
            "                                              inference        33.50%      69.947ms        99.76%     208.283ms      41.657ms       0.000us         0.00%      14.757ms       2.951ms           0 b           0 b           0 b    -332.96 Mb             5  \n",
            "                                           aten::linear         5.31%      11.088ms        74.24%     154.995ms     127.045us       0.000us         0.00%      15.860ms      13.000us           0 b           0 b     255.30 Mb      -1.07 Gb          1220  \n",
            "                                               aten::to         1.20%       2.501ms        23.09%      48.202ms      31.402us       0.000us         0.00%       5.551ms       3.616us           0 b           0 b       1.08 Gb           0 b          1535  \n",
            "                                         aten::_to_copy         4.53%       9.459ms        21.89%      45.701ms      32.298us       0.000us         0.00%       5.551ms       3.923us           0 b           0 b       1.08 Gb           0 b          1415  \n",
            "                                            aten::copy_         5.80%      12.114ms        11.88%      24.808ms      17.471us       5.564ms        37.70%       5.564ms       3.918us           0 b           0 b           0 b           0 b          1420  \n",
            "                                            aten::addmm         8.46%      17.667ms        11.56%      24.137ms      65.236us       3.952ms        26.78%       3.952ms      10.682us           0 b           0 b     101.26 Mb    -268.74 Mb           370  \n",
            "                                       cudaLaunchKernel        11.11%      23.189ms        11.11%      23.189ms       9.041us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          2565  \n",
            "                     aten::scaled_dot_product_attention         0.68%       1.422ms         7.19%      15.002ms     125.020us       0.000us         0.00%       2.286ms      19.048us           0 b        -960 b      22.50 Mb      -1.88 Mb           120  \n",
            "                                           aten::matmul         1.06%       2.220ms         7.04%      14.698ms      61.240us       0.000us         0.00%       1.319ms       5.498us           0 b           0 b      22.73 Mb           0 b           240  \n",
            "                                    aten::empty_strided         5.54%      11.576ms         5.54%      11.576ms       8.181us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       1.08 Gb       1.08 Gb          1415  \n",
            "                                               aten::mm         4.23%       8.826ms         5.27%      11.010ms      45.873us       1.319ms         8.94%       1.319ms       5.498us           0 b           0 b      22.73 Mb      22.73 Mb           240  \n",
            "                                       aten::layer_norm         0.52%       1.087ms         3.86%       8.052ms      64.418us       0.000us         0.00%     904.389us       7.235us           0 b           0 b      46.88 Mb    -125.00 Kb           125  \n",
            "                                aten::native_layer_norm         1.50%       3.141ms         3.34%       6.965ms      55.720us     904.389us         6.13%     904.389us       7.235us           0 b           0 b      47.00 Mb           0 b           125  \n",
            "                                              aten::add         1.95%       4.068ms         3.04%       6.346ms      25.904us       1.143ms         7.75%       1.143ms       4.667us           0 b           0 b      69.38 Mb      69.38 Mb           245  \n",
            "                                            aten::empty         2.97%       6.204ms         2.97%       6.204ms       6.173us       0.000us         0.00%       0.000us       0.000us         960 b         960 b     428.56 Mb     428.56 Mb          1005  \n",
            "                                                aten::t         1.00%       2.087ms         2.43%       5.076ms       8.322us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           610  \n",
            "          aten::_scaled_dot_product_efficient_attention         0.39%     807.915us         2.20%       4.600ms      76.671us       0.000us         0.00%       1.055ms      17.586us         960 b           0 b      11.25 Mb           0 b            60  \n",
            "                                        aten::transpose         1.39%       2.903ms         1.94%       4.043ms       4.443us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           910  \n",
            "                                             aten::view         1.71%       3.574ms         1.71%       3.574ms       2.415us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1480  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 208.774ms\n",
            "Self CUDA time total: 14.757ms\n",
            "\n",
            "✅ Profiling complete. Run: tensorboard --logdir=./log_amp_predict\n",
            "Headline: NASA launches new space telescope to explore exoplanets.\n",
            "Predicted Category: DIVORCE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vbgo_uWrKaGb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}